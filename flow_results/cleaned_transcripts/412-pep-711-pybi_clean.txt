What if we distributed CPython, the runtime, in the same way we distribute Python packages, as pre-built binary wheels that only need to be downloaded and unzipped to run? For starters, that'd mean we could ship and deploy Python apps without worrying whether Python itself is available or up-to-date on the platform. Nathaniel Smith has just proposed a PEP to do just that, PEP 7.11, We'll dive into it with him next. This is Talk Python Me, episode 412, recorded April 18th, 2023.
Follow me on Mastodon, where I'm @mkennedy and follow the podcast using @talkpython, both on fosstodon.org. Be careful with impersonating accounts on other instances, there are many. Keep up with the show and listen to over seven years of past episodes at talkpython.fm.
We've started streaming most of our episodes live on YouTube. Subscribe to our YouTube channel over at talkpython.fm/youtube to get notified about upcoming shows and be part of that episode.
This episode is brought to you by Sentry and us over at Talk Python Training. Please check out what we're both offering during our segments. It really helps support the show. Nathaniel, welcome back to Talk Python to me. How's it going? It's going real well. It's going real well. We're on the eve of the eve of PyCon. How about that? Eve square. Okay. Yeah. I don't know how many eve maybe it's a third that eve to the third, but we're very near PyCon. I'm pretty excited.
Yeah.
Anti-penulti-pe-eve?
I don't know.
Penultimate eve, perhaps?
Yeah, exactly.
I suspect a lot of people will be listening to this show on their way to PyCon.
So if you are, awesome.
Come say hello to me.
I'm going to be doing some live shows, some Ask Me Anything, some various other things.
Are you going to be at PyCon this year?
I'm not.
I'm not, unfortunately.
So they're going to have to just shoot you a message on Twitter or on Macedon or something like that, right?
Yeah.
I'm easy to find.
GitHub, email, whatever.
Yeah.
Cool.
Well, everyone going to PyCon, hope you have a great time and do come say hi.
And with that, we're going to be talking about this project, this new pep about distributing Python itself, kind of like you distribute Python packages, but a little bit more.
Why not?
I mean, it seems pretty reasonable to me and I'm super, super excited to see work in this area because Python is so strong in so many areas And there's just a couple of really big gaps that other technologies have nailed so well.
Two of them that I see that are super significant is like, hey, Michael, I want to build a mobile app.
How do I do that in Python?
Or I want to build a desktop app.
How do I do that in Python?
I'm not sure.
I'm not sure you should even think about doing--
desktop, maybe.
Mobile.
I mean, Kibbe is great, but it's not a general purpose UI toolkit.
And so that's the one.
The other is, hey, I have an application.
I want to give it to someone who is not a developer and have them run it.
And there are some tools that address that.
But one of them is just like, how do they get Python at all?
And your project, your pep, and some of the ideas relate specifically to how do we make it easier to get a pre-built non-admin, not installed for the whole system, Python for somebody so they can run an app or even for developers, right?
Yeah, I mean, in fact, I mean, I'm a developer.
So that's kind of in some ways the original use case, you know, scratch your head.
Of course. Right. Yeah.
But yeah, I mean, it's just it's a very general capability, I think, once you have it.
So, yeah, I mean, the motivation there is basically like, you know, there are lots and lots of ways to get Python right.
You can get it from the Windows store.
It comes with preinstalled on your Mac, but not a very good one.
Yeah, not quite. Sort of.
you know, but there's also homebrew or Pyenv or your Linux distro has it.
And you can, you know, get it through Conda.
And if you download Blender, oh, there's secretly a Python inside.
You know, like it's just, you know, there's just so many different ways to do it.
And that's great. You know, like it's good to have all these options.
They also are different use cases.
But it's sort of silly that, you know, it's obviously it's, you know, it's flexible.
There's lots of ways to do it.
But there's no way to just be like, OK, I just want a zip file that has Python in it.
And it's like a standard way that's supported and we all use so we can all share benefits and improvements and all of that.
So that's kind of the key.
The PEP is not that innovative in terms of what it's actually doing.
It's a zip file with Python in it.
But it's just trying to do the logistics of, OK, but let's all agree on how we're going to put it on PyPI.
Let's have tags and stuff so tools can figure out what they're looking at and do stuff automatically.
And I think that unlocks a lot of use cases, just that one simple change.
- I think it does as well.
I mean, your abstract is one of the more concise ones, I would say.
- Sure, yeah.
- Tell people about the abstract here.
- Yeah, the abstract on the PEP is, it's quote, "Like wheels, but instead of a prebuilt Python package, it's a prebuilt Python interpreter." That is the full abstract.
I figured that basically, you know, tells people what they need to know.
- Yeah, so the idea is kind of like you would say pip install request, you might say pip install Python 3.11.
Except for that you can't use the word pip because pip is built on Python and so you need Python to run.
I mean, it's a little bit circular there.
So you kind of need something outside of Python.
But conceptually, it's I have these things I need to run my app.
I need requests, SQLAlchemy, and Beautiful Soup.
I also need Python 3.11.
So those are my dependencies.
Give me that, right?
- And I mean, you could even imagine potentially pip install Python 3.11 working, I suppose.
Like you would need a Python, some Python to run pip, but once you have that, then it's probably still convenient to be able to say, okay, actually, shoot.
So I got this bug report saying in 3.11.2 specifically, there's some issue and I'm not sure if I can reproduce it.
Like being able to just grab that in one command, pretty useful.
But that said, you know, yeah, it's not necessarily, pip isn't necessarily the target.
I've been working on some stuff there as well.
I don't know if you want to get into that.
- Yeah, we'll definitely get into it.
I think, you know, you need something a little bit on the outside, and I think ideally doesn't depend on Python being on the system, because that, it would be perfectly useful for it to depend on Python.
And this gives you a different version.
This gives you a way to quickly toggle between these versions and these different setups.
But if you could omit that dependency on Python, then all of a sudden you give away to, give it to people who are not developers and use cases where it's not just I already have Python and I need to do it. Maybe you're a developer, but you're not a Python developer. Should you have to manage your own Python installation so that you can use some thing that needs Python to run against your source code? Right? That is not Python. So there's a lot of scenarios where I think it gets unlocked if you use a different foundation.
Yeah, some of the one of the audiences definitely have in mind here is like, you know, people with like taking their very first ever programming course on the first day of class. Like right now, it's pretty awkward that you're like, Okay, well, first, you have to go to python.org and then click through here and click there and download that. Oh, wait, no, not that version.
Did you forget to check to put in your path? Oh, dear. Hold on.
Yeah. And oh, no, do you use the pi launcher? You on Windows? Are you like, it was just it's this extra fiddliness. And it's funny, we've spent all this effort in the last few years kind of getting wheels to the point where they can just work, right? You can just pip install Dumpy and it works everywhere, stuff like that. But Python itself isn't there yet.
Another use case, sort of maybe my primary use case, sort of audience I have in mind is, right, I develop Python packages and as open source and distributed on PyPI, stuff like Trio.
And so I have the problem of I want to be welcoming to new contributors. I want to bring them in, get them started first, quickly. They're volunteers, so I don't want them faffing around and struggling and getting stuck trying to just run the tests or anything like that.
Both that's just a waste of their time. It's kind of rude and inconsiderate. And it's also, you know, there's likely they'll just give up if it's just a casual, like, they aren't really invested yet. It's just something they're doing for fun or out of interest.
I really want to make that easy for them.
And so part of the vision here is like being able to say, oh, yeah, so you check out Trio.
You type this git clone command.
And then you have some kind of Python management tool installed.
You type that tool, run tests, and it makes sure you get the right version of Python and set up the environment correctly.
And then it executes it for you.
And it knows what tests are, how to run the tests in this project, because it looks at, pyproject.toml or whatever.
Right.
And so just sort of capturing all, you know, we have all those pieces.
We don't really have anything that kind of brings them all together into that, like, just type one thing.
That's it.
It's going, you know, and it just works.
We honestly don't have many tools that are outside looking in in Python.
So much of our tooling and our infrastructure is you have Python, now, now you have the tools, now you install it, now you install Black or Rough or other, Yeah, there's just this kind of very old assumption, which I mean, it made sense, like 10, 15, 20 years ago, where sort of everything was sort of installed manually. And of course, you have, you're going to go through some work to like get set up with Python, it's the foundation of your whole environment. And then you to kind of we add stuff to make it easier on top of that, but kind of, I think it's time to kind of go back and re reevaluate that sort of foundational assumption.
Yeah, absolutely. So you mentioned trio, I know, before we dive too much further, and I'm gonna give you a chance to kind of Let the folks know what you're up to.
We'll talk about Trio at the end if we got time.
But what have you been up to since June 29th, 2018?
Five years ago, roughly.
Right, last time I was on the podcast.
Yeah, last time you were on the show.
Yeah.
Wow, that was really early in Trio's life, I guess, actually.
So, I mean, I've had a lot of just real life has happened.
been, I was, you know, sick for a while and trying to kind of get back on my feet, did some consulting, just started a new job. So it's kind of, you know, a lot of distractions. But also, you know, yeah, I think Trio is still, you know, I still like it a lot. It's definitely had more influence. Actually, had I even published the Structured Concurrency blog post then? I don't remember.
I feel like it sounds familiar to me, even though it's been five years, it does sound familiar. So I do think so. But what has happened since then certainly is Python has seen some of these ideas and adopted them, right? Like 311s, concurrency stuff. Yeah. So there's been a, like sort of the influence has gone a lot further than I ever expected, both actually in other languages. So Yeah, like Swift and Kotlin and, you know, have all kind of adopted ideas from here.
Java apparently is making some big changes coming up soon with a whole new concurrency setup. And they're like saying, like, yeah, we're basing it on that Nathaniel Smith's random blog post.
Okay. Yeah. Okay. You know, it's very flattering. But yeah. And yes, also, In the Python itself, it's sort of complicated because it's sort of this awkward situation where there's async.io that's in the standard library, and then there's my sort of competing thing, Trio, which, yeah, I guess we should say Trio is an async library for Python that's portable. It's sort of an alternative to async.io. There are some tools to kind of let you use both at once, but it's not a library for async.io. It's its own thing. And so, obviously, we all wish there was just one obvious choice. I kind of looked, you know, but async/a was also in this very difficult position being in the standard library and being sort of built up over time, and a lot of it was designed before we even had stuff like async/await. So there's just a lot of machinery in there that's kind of already committed to other ways of doing things, and it's very hard to change. And Trio was sort of like, well, look, we have all these modern things and some new ideas coming in like structured concurrency as a better way to kind of write your concurrent programs. And it was able to set up a clean slate to like, really, you know, do that all from the start and be much simpler. So that was important, you know, to have it be its own thing, just so we could, you know, work that stuff out. Then there's a question of, okay, now what do we all switch to Trio? Do we move it back into async I/O? Do they both continue?
That's been a debate for some really popular things, I think that is interesting. A lot of people say, well, why is library X, which everyone uses? Why is that not built into Python? Why do I need to pip install it? And a lot of times the answer is because making a part of Python will harm its ability to innovate and change, right? It'll slow it way down.
Yeah. Like there was a whole debate some years ago about like, you know, like we all know the HTTP client and Python, you're a lib or whatever. It's just really bad. You should just never use it. And it's broken a lot of ways. Like it's just, you just don't use it.
But we still ship it because it would be too disruptive to take it out.
That's also why we can't change it.
There's just too much code out there depending on all the weird quirks.
And we don't want to ship something else because then it'll end up being like URLlib five years later.
So it was a question, like, should we put requests in the standard library or URLlib 3 or one of these?
And it's just, you know, then you can't ship security fixes, you can't improve your API, you can't, you know.
So as we've gotten better at packaging also, it's taken some of the pressure off the standard library to be all things to all people.
This portion of talk Python me is brought to you by CodeCov from Sentry.
Have you heard about CodeCov?
They are the leading code coverage tool on the market.
And they just joined Sentry the error tracking and performance monitoring company that you know and love.
CodeCov is the all in one code coverage reporting solution for any test suite, giving developers actionable insights to deploy reliable code with confidence.
CodeCov is easy to set up.
If you are already both a CodeCov and Sentry user, GitHub integration is even enabled automatically for you.
You'll get coverage insights directly in your workflows.
Code coverage pull request comments allow you to quickly analyze your PR's coverage and risk without leaving your workflow.
It'll reduce the guesswork.
You set up customizable quality gates and let your continuous integration do the rest.
CodeCov identifies where tests can help you avoid errors in production through their Sentry integration.
If an error does occur, you'll even see code coverage details directly in your stack traces.
So you can see the untested, partially or fully covered code that may be causing errors to help you fix your tests to avoid similar errors happening in the future.
Get started for free or take advantage of Sentry's promo pricing where with a Sentry team or business plan, you can get your first five pro CodeCov seats for just $29 a month.
That's a 40% savings. Visit talkpython.fm/sentry to get started. Remember to use the code talkpython to let them know you came from us. It really does help support the show. That's talkpython.fm/sentry and the code talkpython. Thank you to Sentry and CodeCov for supporting the show.
when the standard library first came into existence, there was no PyPI and there was no package. It had to come with it because how else are you going to get it? Hunt it down on Usenet and on base64 and code it, but what are you going to do?
Yeah. Or I mean, maybe you find it, you download, I don't know, Twisted or something like from an FTP site.
Yeah. Yeah. Or an FTP site or something.
You'd have to unpack it and have to put it in your pipe. It was all totally, yeah, knocking rocks together.
(laughing)
- Sharpen sticks.
- You hope it's Flint and it creates a spark.
- Yeah, yeah.
- So I think the motivations and the decisions, the way you might lean in making the decisions are really different now.
Like I would, even though we're already far down the road and making changes is breaking and doesn't make sense, it might make sense to ship less in the standard library, quite a bit less, and just say, oh, you're going to pip install some meta package that explodes out some section.
to pip install the collections area. Boom. And now I got a bunch more potentially.
One thing I'd really like to see as a possible sort of future there is moving some of the standard library into wheels that are installed by default.
Exactly.
So you get, so, you know, that's sort of, it's sort of this halfway house, right? Where, you know, it's still the case you download Python, install it, they're there. So we don't just like break everyone in the world who just assumes they're there. But then it kind of gives us that both in the long term, if it's like we want to get rid of it, it kind of gives us or push it out to PyPI or just remove it entirely, then it gives us kind of a way to do that more gradually. But also for libraries like AsyncIO that are big and complex and really would benefit from being able to have their own release cadence and bug fixes and deprecation cycles and all of that, then it's like, yeah, it still ships with Python, but then you can pip upgrade it. You're you're not stuck with that exact version that could only change when a whole new Python release comes out.
And you have to take all those changes together at once.
Yeah, I've absolutely had this thought.
I think it's a really elegant solution.
Because on one hand, it lets the core developers focus more on the true essence of Python.
And it lets it be used in more locations, right?
Think PyScript, for example, or MicroPython, right?
It might be that you should create a central core that is exactly the same on all of these.
You don't have to consider, of course, this is what runs, it runs everywhere.
But you still get that backwards compatibility and you get the ability to say, actually, I want the newest version of AsyncIO because I want this more high-performance background worker or something.
Yeah, or even just, I mean, for smaller, like, you know, I don't want the newest version of AsyncIO because, like, I don't know if it works, but I want to install in a scratch environment this, like, development version so I can try it out and give them feedback before they, you know, make the release and set the API in stone.
And again, like right now, like, you'd have to go build your own Python. And it's like, it's just kind of a whole thing, right? You can't just do install dash dash pre.
Right, exactly. It's definitely a more of a barrier for people who are just casually wanting to test stuff out. You got to be pretty committed to getting Python 312, alpha six or whatever we're at. Right? I don't know. Yeah, yeah, yeah, indeed. Okay. Very cool. Maybe we'll come back and dive into Tree a little bit more. But yeah, and what are you doing these days? You talked about doing a little consulting and... Well, yeah, so I just started at a new job, just like last week, week before, I guess. Yeah, it's been less than two weeks. Exciting. Yeah, I'm working at Anthropic, which I don't know if anyone's heard of. It's still somewhat stealthy, but it's sort of...
Yeah, I mean, quickly changing. I don't know the exact status currently. But yeah, so my My understanding of the background here is that there's actually the team at OpenAI who trained GPT-3, just sort of sat down together and decided they really wanted to do more of a pure focus on interpretability and safety.
How do you know what these models are actually going to do?
And how do you get them to do what you want instead of stuff like making things up?
all kind of got the scene now how these large language models can go just all over the place, do all kinds of strange things. And so, and they decided to-
There's even one of them being sued for slander, I believe.
Yes. Yeah.
Somebody in the UK, I think.
Yeah. Well, yeah, there's definitely, there's one that just like, if you ask the model, like, you know, can you give me some advantages of like, you know, problems with sexual harassment in law schools? And it just picks like five real law professors and makes up stuff like it's really, really bad. Yeah. And it like site sources that are all made up like it's, you know, like that, you know, they're just, they're very powerful, but also not well understood or how to like kind of make them useful and safe.
Just a little bit of devil's advocate, though, they are incredibly powerful, and they are incredibly capable. And that's, I think, part of the dangers, you're like, Oh, my God, it knows this, oh my gosh, it understood all of that.
And I ask it, so the fifth thing it says, you're like, well, at this point I'm convinced that it really is on.
And then maybe that's the made up one.
And I think that's the dangers, 'cause it's actually, it's almost an uncanny valley.
It's close enough to right that you're like, okay, this thing's right, it knows.
- Yeah, so yeah, so personally, like I'm still kind of up in the air on how impactful it'll be, where the impact will be.
Like I think it's just a lot of open questions.
You haven't bought a farm, like a goat farm in the woods, because you just give them technologies like blow rod now?
OK, all right, super good.
But I guess I do have stock options now, apparently.
Or I will at some point if they vest.
So I guess that's the other route.
But no, but anyway, so I was just saying, so yeah, so Anthropics, just interesting company where you actually get to play with some of those big models internally, they're kind of working on releasing products now.
But it's also been kind of just a really interesting to kind of get the sense internally of like, it's really kind of this like research culture, which is appealing to me. I'm sort of coming out of academia, have a lot of like numerics background. And what's also interesting is that part of the reason we kind of connected is that apparently it turns out a ton of their internal infrastructure runs on Trio. So they're, you know, partly hired me to support that, and are actually giving me time to work on open source paid time. So actually, they are funding this PEP 711, you know, Python binary stuff, though they don't know it yet.
Now they do.
Yeah, yeah.
If they listen to the podcast, they'll learn.
That's great. That's really, that's really cool. It looks like an interesting area to be working. I agree that the research oriented places, they are fun area to work, right?
Yeah, and there's just a lot of flexibility kind of, you know, like, it's clear this stuff is gonna have effects.
Which effects and how big and all that, I don't know, but, you know, being at ground zero is, you know, - It's exciting. - It's really exciting, yeah.
- And a lot of chance to maybe have some impact, so. - Cool.
Alright, let's dive into the pip. The pip, the pep.
- The pep, okay. - It's not quite pip, but it's kind of like pip, okay.
Yeah, okay.
So, we talked a little bit about the motivation.
We talked a little bit about what it is.
Maybe tell us a bit about the spec.
Like, what does the pep actually say?
What is it actually trying to deliver?
And we can talk about the use cases and some of the tools for it and so on later.
I mean, so, like I said, the abstract deal is like wheels, but it's an interpreter instead of a package.
That's partly just sort of a tagline of how you use it, but it's actually also a lot about how the actual spec is written.
It's just sort of like, well, we've done a ton of work over the last five, ten years.
A lot of people have put a lot of work into making wheels work, right?
In terms of like, figure out, okay, how do we have metadata that's usable to keep track of which packages are installed and their versions and which ones are compatible?
And for a binary build, which systems can you put this on?
And all the many Linux work and just all of that stuff.
And it's just like, well, you know, so we have wheels, we don't need to reinvent the wheel again. So I'm just sort of taking all of that. So it's just like, okay, it's mostly it's just a delta against the wheel spec. It's like, okay, and the wheel spec, you have, you know, this directory for metadata, I have, you know, that same directory, but I call this calling these Python binaries, PyBys, just to have sort of a short name, you can stick in a prefix, or sorry, Sorry, in a file extension.
- Yeah, pybi.pybi.
I like it.
- Yeah, the PyPy, the interpreter, and PyPI, the package repository, we're confusing it up.
So I thought I'd add another near homonym to the--
(laughing)
- PyPy, it's PyBuy.
- Yeah, yeah, you know.
Anyway, but so yeah, so like, but they look like, you know, the file names look like wheels.
Like, you know, something like, you know, cpython-version-manylinux217.pybi.
The context looks like Wheels.
They're basically just zip files.
There's some, you know, instead of a .distinfo directory, you have a pybinfo directory, and it has a metadata file that's in the same format as Wheel metadata files for the name and version and, you know, description, all that stuff.
There are a few tweaks, basically just what, you know, you need specifically for interpreters.
So, okay, so like one thing that makes it a lot simpler is that there's only one interpreter in a Python environment, right? Whereas wheels are kind of designed to be flexible and be installed into different kinds of Python environments with different layouts. A PyBy is just like, it's just a raw set of files. You unzip it, that's it, you're done. Where wheels, there's like, well, okay, if you want to put this in site packages, so you have to go find that. Whereas this goes in the bin directory. So you have to go find that and do the special, you know, so that part's just, you know, not relevant. Leave that out. There's some slight, you know, we have to support symlinks, which wheels don't, mostly just because there's never been a big compelling reason.
What's that?
The Windows folks out there, maybe, and others who are just like, what the heck are symlinks?
Yeah, okay. Well, so yeah, symlink is a classic Unix concept. Though Windows does have them too I guess, where it's like a special magic file that instead of having like its actual contents, it just lists says, go look at this other location on the file system for my content.
- Right. It's like an app shortcut, but for programs, not for UI.
- Yeah, well, like built into the file system.
- Yes, exactly. So you try to open it, it goes to the other one.
- Yeah, the operating system automatically opens that other file for you. But you could also look at, you know, if you can like say, like, can you show me the same link and like, it'll tell you about it, if you ask, but if you don't, then it just, you know, magically works. And it's mostly, it's just it turns out that traditionally, Unix Pythons tend to use these, both for things like you'll, you know, in the your bin directory, you'll have the Python executable. And then you'll also have Python three as a similar to Python and Python 3.11 is a similar to Python three. And so you know, one to preserve that. And also, it turns out on on Mac OS, they have this very specific kind of layout they want with like framework.
Like, I don't really understand it in detail, but like there's sort of like a how a Mac OS app is supposed to be structured and that it turns out to involve symlinks.
So we just, you know, we just have to support that said, I mean, the way we support them is like, it turns out there's a standard way to put them in zips.
So I say, let's do that.
You know, like, again, really trying to keep this as boring as possible.
You know, I did know.
And then the last thing, that's crazy.
Yeah, it's an extension from the InfoZip folks, but then it's become... I don't know.
Zip's a strange format. It's kind of like an oral tradition as much as an actual specified format.
There's an entire documentary on Zip.
And I believe the guy who came up with it.
It's even controversial in its early days. It's nuts.
But yes, it's even won the compression de facto standard these days for the most part.
Yeah, it's definitely got trade-offs, but it's just in terms of, it's just really useful just to think that everything could understand.
It's just so compatible.
And it's also convenient that you can do random access, unlike some of the alternatives.
You can pull out one file from the middle if you want to.
The fact that anyone can open it is so much better than it might save one more percent. Yeah, for sure.
- Yeah. - Cool.
Okay, so we've got these...
Basically, the pyby file is the zip file. Is that basically the entire interpreter just kind of bundled into a zip file? Like, what's the deal there?
Yeah. I mean, it's just literally like, you know, you install Python into a certain directory, and then you take that directory, you put it in a zip file.
There's a little bit of tweaking to like, make sure it's self contained, and you can move it in a portable, portable relocatable, I guess is a better word.
Yeah. So sometimes if you just install Python regularly, it's kind of, well, I've hard-coded, I know that I'm at this particular position on the file system. And so I need to make sure we don't do that. And also to make it self-contained, it's like, same thing we do with wheels. Like, you have to vendor some libraries, right? If it wants to use readline as a library to, for like in the REPL to be able to like edit your line as you're typing it, then, you know, we can't just assume it's on the system. We have to include that inside the PyBuy.
So and but again, like this is stuff we've all already dealt with with wheels, there's tools for doing it, we understand how to do it. And I'm just reusing those tools.
So if I were to run a Python application delivered by one of these PyBys, does it have to unzip the contents into a location and then run it there? Or can it just run it straight out of memory? Or what?
How does that work?
Well, so by itself, the format, I mean, it's just a zip file, right?
So you can do with it what you can do with a zip file, which, I mean, is not much on its own.
You need some software to work with it, right?
Now, that said, I think--
so yeah, so like if you just were starting with nothing and you're like, I just I have a URL to some PyBuy and I want to use it, then you'd have to download it, run a numzip tool, and then you'd have a-- you could go into that directory.
It's a Python environment.
You could run pip in there or whatever.
That said, I think this is a really useful building block for tools that want to go beyond that.
So things like delivering a pre-built application that you can just run without unpacking.
Like there are various tools to do that, like PyOxidizer, Py2App.
I don't know, there's a ton of them, actually.
I'm probably forgetting like 10 more.
Yeah, the ones that come to mind for me are Py2Amp, PyInstaller, and PyOxidizer for sure.
PyOxidizer being the newest of them.
Yes. Oxidizer because it involves Rust somehow.
- All the new things involve Rust. - Yes.
So, but yeah, so those tools that it's really useful to be able to say, "Okay, like, I'm going to do some clever thing to like set up, I don't know, a self-extracting executable or whatever it is they do for their distribution mechanism.
I'm going to create an installer program, I'm going to..." whatever it is, but you still need an actual Python to put into that, right?
And so having a straightforward way where it's like, that's not their problem anymore to figure out how to find a Python and get it built and working for the target system. They can just say, okay, I can just like grab, you know, okay, yeah, you want to target, you know, many Linux, cool. I'll just go grab the right Python. It's already there. I know it works. And now I can take the files out of this PyBI and do whatever I want with them. I can pack them into my installer or do clever things to make them usable out of memory or whatever. And they can focus on that part instead of just the like, how do you even get a a Python.
Yeah. Or how do you once find yourself in the wrong Python, get the right Python?
Yeah.
Yeah. That's a, I don't know if that's trickier or less tricky, right? It's one thing to say, dear user, go get Python. You need that. It's another thing to say, go upgrade your Python and hope you don't break something. You know, I think.
Yeah. Well, but also that's part of the point of these being self-contained is, so I mean, this is one of the more trivial use cases, right? But right now we all use virtual ends And mostly that's fine. But also sometimes, you know, they can get, you know, janking stuff could happen. Like, you know, you're on Linux, you do an app to upgrade, and now your system pythons change and all the virtual ends that were based on are broken now. Because it like had some kind of dependence on that exact binary. Now, I won't say you would always want to do this, but at least it's nice to have the option, you could say, okay, instead of making virtual ends, I'm just going to make real ends. They're all just going to be I'm just going to drop a new copy of Python in each environment. And that way, I just just totally self contained, I know exactly what I have it upgrades when I decide to upgrade And it's just, you know, it's a nice option, right, sometimes to have that.
And also, you know, it gives you that total isolation, right?
So you're then, we were just saying about that issue of like, "Oh, I wanted to use this, so I went and installed, upgraded my Python, but now that other thing I was already using broke because they're using the same Python." It's like very easy to say, "No, just give them different Pythons." You know.
There's not that much that changes over time.
That's a backwards breaking sort of thing.
I mean, two to three, but I think that's kind of...
Yeah.
Let's put that in the past.
But I did...
Well, but I did recently, I was working with MongoDB using Beanie, which was using Motor, which was using the @async or @coroutine decorator, which was just moved in 3.11 or 3.10, one of those recent upgrades.
And it had been deprecated forever.
The people at MongoDB said, "We don't care, we're just going to leave it.
Who wants to put the word async in front of my method? That's tricky." I mean, they just probably weren't paying attention.
And my code wouldn't work. I'm like, "Why doesn't this work? Oh, the thing I depend on, which the thing it depends on, that thing needed less than 310 or whatever, 310 or 311, whatever." - Yeah, and now we're back to the ICKO struggles to adapt without breaking it.
- Yeah, stuff like this would...
- Stuff that does happen, you know.
- And this kind of isolation gives you 100% confidence to say, "I'm going to make this new app. We're going to try running this app on this in production, and it's not going to hurt anything, and I don't need Docker." And you can say, or you could use, say, I'm going to, you know, use this exact point version in development. And then I'm going to take that and build it, create my, use that to create my Docker image. Like, I don't need the like prebuilt Docker stuff. I could just grab Python from PyPI. And I know it's the exact same version everyone else is using, built by the Python.org folks. Hopefully, you know, we're not there yet. But like, that's kind of the way we're trying to get a pep and not something on GitHub, right?
- Yeah, sure.
Well, it has been on GitHub for a while, but I have time to kind of move it more.
- Yeah, yeah, so maybe it's worth jumping over that, but before we do, two questions, maybe.
- Yeah, sure.
- Two top-level questions anyway.
So this is about the concept of kind of like pip install Python 3.11, or 10 beta 2, or whatever.
- Whatever it is, yeah.
- Yeah, does that, is there a way to say, and these three packages off of PyPI?
Can I take and kind of bring a virtual environment effectively along with me with what you're doing so far?
So PyBI is, again, by themselves, I mean, it's just an archive format, right, a package format. It doesn't do anything.
That said, obviously, yeah, part of what we want is for these to be useful for things like, you know, building environments that have other packages in them and stuff.
So that's the one other thing I didn't, I forgot to mention about defining the format.
Probably the most interesting part, actually, is that we do add some new static metadata that we put into the package. And kind of the motivation there is that I try to figure out, okay, what do I need to know in order to install wheels into this Python without running it? Right? Because right now, right, like pip assumes that it's running on the Python it's installing into. So anytime it wonders, like, you know, okay, like, what ABI's does this Python support? And what version is it? What platform am I on? It can just ask the interpreter it's running on, right? And it's like, okay, well, it would be really nice if you didn't have to do that both for like efficiency, like you want to be able to, you know, figure out which, you know, have your like installer, your resolver, figure out which versions of everything it wants, without having to like download and run multiple versions of Python and stuff like, you really like to avoid that. It's also things like I want to build a cross, I want to build, release distributions for Mac OS, but I'm on Windows or vice versa.
Or I just want to, you know, I'm developing my package like Trio on Linux personally, but I would like it that when I lock my version, so I know all my collaborators are using the same versions, that we figure out locks that also work on Windows and Mac OS.
And I can't just trivial run all those Pythons from one resolver because it's not running on all three at once. And Python packaging does have the ability to have different dependencies on different OSs. It can get very complicated to figure out which packages do I need where. And so, I wanted to put a bunch of metadata into the PyBI, all the stuff you need to solve those problems. So, yeah. So, the PyBI itself, I think normally they won't ship with any packages. Maybe, again, callback. Maybe in the future we'll start moving some of the standard library into wheels that are pre-installed, you can do that. But I'm guessing like, you know, for now, it'll mostly just be, you know, a plain vanilla Python install. But then you could take that, you could take some wheels, bundle them all together into a new archive if you want. Or, again, whatever you want to do with it, stick it in a Docker image, whatever. It's a step towards but not necessarily trying to propose an entire solution of here is the interpreter and all the dependencies and the code and just run it as if it was, it had no dependency on your system. Just treat it as like a .exe or a .app. I can just double click.
I mean, it makes that a lot easier than it is right now. First step is just to figure out, like, how do I even build a Python that'll work like that? And that is like some arcane, dark knowledge written on a tome in black ink on black paper and a black tomb. You have to go find or something like, you know, it's just, yeah, it's not easy. And so just having the ability to say like, yeah, just grab this file, unzip it, drop some wheels in it, zip it up again. Now that's a package you can drop, you can hand to someone and it'll work on their system. You know, like that's, that makes it a lot more accessible. It's not the thing I most personally like, I'm not immediately going to go build that one last extra tool, but I bet someone will.
Yeah, I can imagine someone will for sure.
This portion of Talk Python Me is brought to you by us over at Talk Python Training with our courses.
And I want to tell you about a brand new one that I'm super excited about.
Python web apps that fly with CDNs.
If you have a Python web app, you want it to go super fast.
Static resources turn out to be a huge portion of that equation.
Leveraging a CDN could save you up to 75% of your server load and make your app way faster for users.
And this course is a step-by-step guide on how to do it.
And using the CDN to make your Python apps faster is way easier than you think.
So if you've got a Python web app and you would like to have it scaled out globally, if you'd like to have your users have a much better experience, and maybe even save some money on server hosting and bandwidth, check out this course over at talkpython.fm/courses.
It'll be right up there at the top.
And of course, the link will be in your show notes.
Thank you to everyone who's taken one of our courses. It really helps support the podcast.
And back to the show.
Our next question is not what our shared screen here but is what impact do you think this would have on PyPI? First of all, do you see PyPI the way the CDN that delivers packages like trio and wheels like trio? Do you see that as the same channel through which CPython 3.11 is delivered?
Yeah, I mean, so I would like these to literally be like you go to PyPI slash project slash CPython. It says like, here's the latest release and you click on downloads and it shows you the, yeah, I'd like it to just literally be stuff you upload to PyPI.
Right. And when you pip and solve from there, it figures out the platform to pick from and it downloads that wheel and off it goes. Right. Do you think that that would add like a huge burden to the amount of traffic or do you think?
- No. I mean, largely we'll have to see and adapt, but Python itself, it's like, shoot, it's tens of megabytes.
- Okay, cool.
So plenty of other packages.
- There are a lot of much bigger, like go look at TensorFlow or something.
There are hundreds of megabyte packages on Python that are very popular.
Also, I mean, Python.org downloads go through the same CDN anyway.
It's just sort of different infrastructure on the backend, but it's still fastly serving it and donating the bandwidth.
So in that regard, I wouldn't expect much change.
And also just people tend to install wheels more often than they install Python.
Again, it's hard to know the second order effects.
Maybe virtual ends will be less popular in favor of full ends if this takes off.
And then people will start installing Python more than they do now.
But nonetheless, I don't think it's a huge--
I wouldn't anticipate it being a huge change.
And if it turns out to be a problem, then we can kind of address it then.
Well, you could also do, to a large degree, you could do things like pip does already that caches.
You could just cache the CPython wheel, the PyBI, into the user profile, and the second, third, fourth time you get it, it's really the CI systems and all the dockers and all that stuff that don't understand what a cache is or any of those things.
Yeah, but then, you know, so like if it becomes a real problem, then you go to GitHub and you're like, "Hey, can we work something out so that you stick a cache in front of PyPI?" Stuff like that. It's not trivial, but you could talk to people and solve problems. Certainly, I don't think we should hold back the entire design of how we distribute Python and make it available because, "Oh, maybe it'll be too easy and people will use it too much." That's a good problem to have, right?
- Yes, exactly. Look, they're using it. This is terrible.
- Yeah, like first, you know, make it easy and then figure out how to solve any problems that cause it.
- Yeah, I think we've more than once solved the problem of, "Oh my gosh, they're using it." Like Google, Netflix, you name it, you know.
Think of the benefit that you'll be doing for all the developers, especially those who have Python skills and are looking for a job.
I mean, if the popularity of Python by downloads is one thing, if you could like 4X that, we'd all be more demand.
and like, really, really downloaded now.
- Right, yeah, just go out there and just download it five times in every CI job.
Just, you know.
- Exactly.
- Just throw a form away, but you know.
- Just do it a couple of times, just show.
- Right, yeah.
- Awesome.
The question that you put into the PEP here on the screen though, is why not just Conda?
And I, not being a particularly data focused person, I definitely prefer using pip over Conda because especially it seems like a lot of the web packages are not as close to update up to date.
You know, there's a latency before it hits conda and it's like immediately on pip.
That said, there's a bunch of people who are like, I kind of use conda for this.
Yeah, and right. If you're just like, look, I don't really care about all this.
Like, I just, you know, want to run my Jupyter notebooks and I, you know, just need a Python that can do that.
And maybe, you know, some NumPy or whatever.
Conda solves that really well.
And this thing could, you know, I'm working on could also potentially solve that really well. And so it feels duplicative to those people.
And to them it is. You know, it doesn't really -- they're both two solutions that work, but there isn't necessarily a reason for them to choose one or the other.
>> But this could also be a foundation for the way that Conda provides Python to itself.
>> Maybe. I don't know. Like, there's a whole other question about how, like, we could bring Conda and PyPI, PIP, that kind of world closer together and interoperate better. But that's a whole can of worms, lots of complicated stuff. I don't think this PEP itself is going to be the thing that makes a big difference there.
Okay. But it's not an anti-Conda type of thing.
No. No. Yeah. Well, and so, right. And so, I mean, you can also get to see a version of this in the PEP. But basically, the way I think about it is that the key reason why we just like why PyPI is a critical piece of infrastructure that, you know, cannot be replaced by anything else is not because it's of its use for end users. I mean, it's great that end users use it and find it helpful and all that, but like that isn't the people who absolutely need it and could not have any replacement. The reason why we just absolutely need it is for package developers because the way, again, you're talking about all those different ways you can get Python, And there's all these different ways Python packages get distributed.
You can brew install Python packages.
There's versions, you know, NumPy, a patched version of NumPy used to be part of the standard Mac OS install.
Maybe it still is, I don't know.
You know, like when you install Blender, there are Python packages in there.
Install some game using, was it RenPy?
It's going to have Python packages in there.
Or just, you know, there's just like, there's so many different ways that Python code goes out in the world and gets used in all these different contexts.
And if you're developing some upstream library, like, you know, Trio again, or, but, you know, or requests or NumPy or anything, then what you absolutely don't want to do is have to maintain a separate distribution for all of those different things. You don't want to have to upload your package to CondaForge and also to Debian and also to Fedora and also to BlenderForge, like, you just, like, that's not, that doesn't make any sense. And then having every different package maintainer do that, like that just would be terrible. It just would be unworkable. So the critical role that PyPI serves that just nothing else can, is it's this intermediation point between package uploaders and package users, including package redistributors. And so I make a release of my package, I upload to PyPI. And then that's where Conda forward gets, that's where Debian gets it, that's where the end users get it if they're pulling straight from PyPI. It fans out from there.
And the key difference in terms of design between pip and Conda is that PIP's metadata formats and wheels and the metadata and sourced disks and all that are designed around this abstraction of you have some kind of Python environment, but it could be any of those. It could be on different OSs, it could be different, you know, ways of building it, different layout, different pieces could be missing, like, whatever, you could be laid out in all kinds of different ways. I just know that there is some kind of Python environment. And I have the metadata to like figure out how to adapt to how this particular Python environment is put together. And conda, on the other hand, is one of these sort of downstream systems. It's it can the reason people like love it and like data science, right, is because it's a full-fledged, like, arbitrary application distribution thing, right?
You can install random, you know, C libraries and, you know, you can install R and R packages, like, it's just, it's got, you know, compilers that are all there in the one thing. But because of that, it doesn't have this abstraction of, "Oh, I can handle any Python environment." A conda package of a Python package is set up to install in a conda Python that's laid out in a, the way a conda environment is laid out in the way of using the libraries a conda library has, right? And so it doesn't have that flexibility. If you just release something for conda, then it's great for conda, but it's not usable to Debian and Homebrew and all of those other folks.
And so that's the key thing that PyPI does, right? It has that abstraction that lets you have the Python packaging ecosystem of all those packages and they're dependent on each other.
and then you kind of project it down into each of these more specific, specialized packaging systems.
And then also, because, you know, as a...
That's the other thing as a package maintainer, I don't just write my package and upload it.
Like I'm also using all the other open source maintainers work as I do it.
We're all working together, right?
And I'm depending on their work and they're depending on mine.
And so I need to be able to say, like, okay, you know, my package needs those three other packages, and here are the versions.
and I need to be able to create an environment with those versions and test it before I upload my package to PyPI. And so, again, all that work has to happen at that higher abstraction level. You can't just say, "I'm going to take the latest version from Conda and test against it," because that's not necessarily the version that other people will get. Where you take the versions from PyPI, those are like the original ones. I can get exactly...
I have access to anything anyone has ever uploaded as soon as they upload it, and I can test them all together. And then, you know, if condo wants to take some curated subset of those or whatever, that's great. That's a really valuable service. But you know, they kind of need that underlying set of packages to curate. And that's why. Yeah.
PyPI is kind of the definitive source of truth as the package creator intended it to be.
Yeah. And then so right. And then of course, yeah, for a lot of end users, it turns out they're just going straight to that without any intermediary.
works great for them. And that's really cool. But also, you know, it's not like I don't have anything against people who prefer to go through Debian or Conda or whatever. I think that's also great, you know, if that works better for you. But for the folks who are, you know, developing, you know, packages to upload, or who just, you know, would rather just, you know, get stuff straight from the source, the PyBI's, I think, can solve a lot of problems that Conda, you know, just, it just doesn't address those. It has a different focus.
Trying to make it a swap over to do that might kill a little bit of what it's good for, you know?
Yeah. All right. Let's see. So let's move on to your announcement here. I think...
Okay. Right. Yeah.
So over on discuss.python.org, when was this? This was January 21st.
That's a few months ago.
Yeah. A few months ago, you announced PyBI and Posi.
Yes.
And Posey is, we talked about this mythical pip that could pip install C Python 3.11.
Posey is that mythical pip, right?
Yeah. So yeah, the pip 7.11, the PyBI stuff is just the one brick in my master plan.
So, right. Because yeah, because sort of this vision I had in mind, I kind of alluded to earlier talking about like, you know, okay, if somebody does, you know, Git clone my project, I want them to, you'll just run the tests and know that they have the right version of Python and the right version of the dependencies and just kind of, you know, and they know how to run the, you know, just do it, right? Encode all that information somewhere. And Posey is sort of my experimental, it's not ready to use, but it does have a lot of stuff working, is my attempt to solve that part of the problem. So the vision is Posey is a, it is a full reimplementation of PIP, you know, the metadata parsers and dependency resolvers and archive installers and all of that, except I rewrote it all in Rust, as is the style. But it's all built around PyBIs. So it doesn't...
Maybe at some point we'll also start supporting VNs or user-installed Pythons. But for now, sort of for the MVP, it just says, like, okay, yeah, you have a PyBuy, I will grab that, I will grab packages that are compatible with it, I will arrange them all to run together based on, you know, you just say what you need, I turn that into, like, a lock file, I fetch those packages, I run, you know, your test script or whatever. And yeah, I mean, that is the core idea.
And one advantage of being in Rust is that it's, you know, just because just so obviously, you know, if you want to hack on it, then you need like a Rust compiler and stuff. But if you just want to use it, then we can just take a button, we can compile it down to a single binary that you just, you know, upload to wherever, install it from wherever, and you just you drop it on your system, you run it, and it's self-contained, it can handle everything from there. So again, thinking of that target audience of like beginners, right, you say, okay, install this one program, And now you type, you know, Posey run. And oh, look, you're in a rebel. And it's like, and I would totally, of course, I had to go find the latest version of Python and grab it and figure out which build is right for your system and do that. But like, but you know, you don't have to think about that. You just hit enter and it happens. And there's your rebel. Or they say, you know, Posey add requests and then Posey add Jupyter and then Posey run notebook, you know, like, and it kind of is handling the environments behind the scenes.
Yeah, we did a panel discussion with a bunch of core developers around packaging recently.
And a lot of them were saying things like, I don't really want to put words in mouth, but kind of getting the sense that like, okay, so we have a bunch of tools that are really neat, that live within Python, you know, I'm thinking Hatch, Poetry, those that category of tools, pip itself even. And some of the challenges or problems that they would like to solve, they could unlock a simpler API if it was turned inside out, right?
If the tool itself controlled Python, it didn't depend on Python to get started.
They mentioned RustUp as a way to get started, which is a way to kind of install a version of Rust and get started, right? And it feels to me like this is pretty close to that.
Yeah, there's a lot of overlap, for sure, in terms of sort of goals and approach and all of that.
- One challenge I see is, so like for example, to run the application for the, with the Python that's bundled up inside of one of these PyBIs is you would say, Posey run or Posey some kind of file or something like that, right?
- Sure, yeah, whatever.
- Could, could, yeah, yeah, yeah.
Whatever the CLI that's yet to be fully spec'd out comes out to be.
But, you know, could you do things like, could you create, you know, speaking of symlinks and other types of stuff, Could you create just in the same folder where that app lives, a Python that actually just calls Posey, the Python inside instead of Python itself, and pip that says, you know, Posey run pip inside this Python to kind of bridge, to unify the API from where people are coming from, to kind of expose the same tools that are inside a little bit?
You know what I mean?
Well, so, yes. I mean, so, the way I am currently sort of in my current prototype, basically. It doesn't work like that just because it felt sort of more complicated to then like try to expose those things. So, sort of the sense is like, you know, let's see how far we can get with treating sort of the UI paradigm of like Posi is just your front end to Python. Like you don't, you just, you start your command with Posi and that's, that's the only command you need to know, kind of. And so, and that also allows some interesting things. So like the way Posey does environments right now is it doesn't, you can have multiple environments within a project. Like if you need to test against multiple Python versions or you need different installs for, I don't know, tests and for building your docs and whatever. But it doesn't actually materialize all those as separate independent virtual environments. Instead what it does is it, for like each unique wheel or PyBi that it needs, it unpacks that into its own directory. And then on the fly, it assembles environments by setting up environment variables so that it can launch a Python in such a way that it picks the right Python and launches in such a way that it sees the right packages it's supposed to see. But there's only one copy of those packages on disk, if you have multiple environments.
If you want to try out different versions or whatever, it can just do that without having to go rearrange everything on disk.
And that's just, you know, it's convenient.
It's just a really nice way to work with sort of having declarative Python environments.
So you never update an environment in place.
There is no environment in place. It's just on each command you run, it sort of knows declaratively, "Okay, these are which packages are supposed to be there.
I'll give you those packages." So there isn't even a concept exactly of like pip upgrade or pip install.
You can just say that next time I invoke environment, I'm going to give you a different specification for which versions I want.
and it'll make sure that happens.
It feels a little like Docker, right?
Like, if you create a Docker image and you run a container, you want to make changes to it, you don't log into the container typically and mess with it.
I see what that says, right.
You would just say, "Okay, well, we changed the Dockerfile, we shut it down and we start it back up with the new, better version of itself, right?" That's like Docker.
Yeah, a big difference would be that in Docker, when you build it, like, the actual Dockerfile is this big old imperative, imperative, go scribble here and then delete that and then put something else, you know, that kind of thing. It's not just like, here's the list of things you need.
Well, it feels to me like maybe a better solution than what Docker is giving you. If what you really just want to do is run a Python and isolated Python thing repeatedly, because with Docker, the idea is like, well, you want it, you want it isolated. So let's do this. Let me give you an entire separate copy of Linux.
I know what you're running in like not a full VM way, and it's not as heavy as a VM, but it's still, you're configuring a Linux computer inside of this container in the way that, whereas this is just like, I just want Python configured, not everything.
Well, and even more like in Docker, if you want to make sure that you run Docker build twice and get the same package versions, like you have to do that yourself.
You have to come up, you have to use, I don't know, pip compile or something like create a lock file and then install from that instead of your original requirements.
It's a whole thing. There's lots of ways to get it wrong.
Whereas in Posi, the way I've written it currently, it's just like there is, you know, there's one operation, one internal function that takes a set of like, "Okay, these are the packages I want." And it like renders that down into a block file of like, "Here's the exact set of packages you need, including all the dependencies and all their versions." And then that's the thing that you hand to the run-me-in environment.
So like you have to go through that step.
It's just built in. And so we can like, you know, so and of course, you know, as we build up the, you know, CLI and stuff, ideally that that will be then, you know, written to disk, similar to a cargo dot lock or poetry dot lock or whatever.
And so you just automatically get that reproducibility, which, you know, you don't get that automatically from Docker, right?
This is a thing that people could go get.
On your GitHub profile, they could check this out and they could try it, right?
So, yeah. Let's see. So, yeah, so obviously, there's a lot of moving parts here.
Folks want to help with the PyBI part, that PEP 7.11.
There's lots of stuff you could use help with.
But it is also, there's a draft pop-up, and I have built lots of PyBI packages for lots of different versions of Python.
For Mac, Windows, Linux, they're up on a CDN.
So, you know, that uses the same API as PyPI, so you could pip install from there if you had a pip that did it.
So it is stuff you could try out right now, experiment with at least.
And then, yeah, as for the POSI part, Again, like I said, it's mostly the backend stuff, but it is a pretty complete implementation of all the packaging stuff.
It can actually do that demo I was just saying of like, I need these three packages in this version of Python, and it can do the dependency resolution for a named specific operating system, which may not be the one you're running on, and then generate that environment and actually invoke it.
Well, you can only invoke it if it's for the operating system you're running on, of course.
But it can do all that stuff. There isn't really a UI in front of it yet.
But so it's not like something I'm suggesting you go start, you know, rolling out to your company.
I really want to adopt it. Yeah, it's a good story.
If this is like an exciting project for you, then you could check it out, see where it's at, join in, whatever.
There's definitely tons and tons of stuff to do, but it's, you know, there's a good solid start.
And I think it's at this point, I'm pretty confident like everything could work, right, you know, kind of the proving it out part.
is pretty much there, done.
Question from Marwan in the audience.
Hypothetically speaking, does a posy.lock work as is on different platforms?
Right, yes. So cross-platform support is a huge issue with locking.
I don't know if anyone's ever tried to do this with pip compile.
It just doesn't work.
If you have anything complicated, like multiple Python versions, it just doesn't work.
They tried hard, but yeah.
So what I'm doing right now in Posi is I've tried to kind of keep it simple.
I just say, like, you know, tell me which platforms you care about.
You know, like, you know, ResaDish Linux and Windows 64 and Mac OS ARM and Intel or something. You'll give me like a list.
And then it will, it can go through just like loop through that.
And for each one, find the right PyBI, look up the metadata to figure out which kinds of packages are appropriate to install there and generate a lock file for each of those.
And then, you know, you can somehow like merge the common parts and write them to a file.
So the individual things that like, you know, resolve this set of versions, or set of package requests into an exact set of versions, that only runs for one specific platform at a time.
But, you know, you can run it multiple times.
There are-- it might be possible to do something smarter.
So I know Poetry has some algorithm that I don't really understand very well, where they try to simultaneously resolve all the platforms into their lock file.
And then the way the lock file works is then you actually--
it's only mostly resolved.
And then when you actually go to install, it does that last step to try to narrow it down to the exact platform you're on.
And I just-- I don't quite--
no one's been able to explain to me how exactly that algorithm works or even like I'm not 100% sure it's even like if it's fully correct or if it's heuristics based or what. So I don't know but like you know we can change you know there's lots of options right you know we can change the code if there's a better way to do it just that's where I'm at so far. So there's something people can play with but it's early days and you wouldn't mind having help if people wanted to jump in. No for sure if you want if if you've been looking for an excuse to learn Rust, if you want to play around with cool--
I mean, there's interesting problems in terms of things like how you efficiently resolve do package resolution.
It's like this whole messy logic programming problem.
It's NP-complete.
There's just interesting system engineering problems of, OK, if we're going to really make this a really nice to use, Like, how do you unpack 20 wheels as fast as possible?
You get to use threads and concurrency and all kinds of stuff.
Yeah, there's lots of cool technical bits, too.
And of course, just making something that's a joy to use, fits nicely in your hand.
Lots of fun user interface problems.
Yeah, I'm excited about it, as you can probably tell.
Like, I just love these kinds of problems.
- Yeah, absolutely.
So this announcement was on discuss.python.org, And I thought, okay, well, it says there's 72 responses.
Let me flip down and see how this landed with people, right?
- Okay, yeah.
- Okay?
- You know, a wide variety of responses, yeah.
- Yeah, well, but I mean, I would say that at least the top batch, the first bunch of people, Paul Moore, deeply involved with Pip, jumps in and says, "This is beyond awesome.
"I had realized you were working actively on this.
"I'll take a look.
"I'd love to help out too." Talks about Rust a little.
Frederick says, "Really nice to see this.
This is a great direction.
Janice says, well, certainly blew my mind.
Count me in on how we could explore how this might work for Conda and so on.
And just, I thought it was really, really quite positive.
How many, you know, next person this checks many of the boxes, what I have in mind.
So I, it seems like it's landing well with the community.
I hope that I hope that it continues to make good progress.
Yeah.
I think the biggest thing is like, there were definitely some folks going like, okay, but why are you writing everything at rust?
Like, especially it's like, you know, we've spent a lot of effort not just making standards for Python packaging, but also like implementing those.
So like you can pip install packaging and like right now and that is a library that could do things like unpack wheels and access the PyPI.
Or I forget exactly which set, but like a lot of the tricky stuff, you know, parse Python metadata formats and you know, just all these different tricky things.
And it's like, why are you re-implementing this?
And also, does it like send the wrong message that like, you know, when we wanted to do something complicated, we thought Python wasn't good enough, we needed to switch to Rust.
And I get where they're coming from.
But, well, I mean, there's a few things.
So one is just that I thought writing in Rust would be fun, you know, I'm not telling you you can't use Python for anything.
Sure, I mean, let's take a step back and say, how would you propose writing that in Python?
Well, so, exactly.
No, it's possible, right? So like, so conda is written in Python, right? But, and the way, so it makes the distribution a little complicated because like when you, you get your conda.sh or mini conda, you know, like the installer, it has a Python package inside it, which it unpacks. So that uses it to run conda to install like another, another Python or whatever it is that you want to install with conda. But it sort of has one built in and you could do the same thing for something like Posey.
use something like PyInstaller to build an executable.
Exactly, yeah. But then up for PyInstaller effectively, right?
Just kind of recursively do that. It's totally something one could do.
So yeah, but the main reasons I'm not to go that way is one is, like I said, it just was more interesting to me. It's one thing. There's also, like, you know, every language has trade-offs, right? And the exact set of things you want from a package installer are kind of right in Rust's sweet spot and not Python's. So there's sort of four things that are really important for a tool like Posey. So there's the initial install. There's how quickly it starts up, because this is in between you and invoking Python or whatever it is you actually want to do. There's how quickly you can resolve packages and how quickly can it unpack packages. Those are the things that you care about. Those are the big load-bearing pieces.
And those are kind of four of Python's weakest spots, honestly. So we just talked about the deployment part. You can make it work, but it's not as straightforward as some things. There'd be more possible moving parts, things that could go wrong. It's not the strongest argument, but it is there. For startup speed, just notoriously one of Python's weak spots because it has to do all those imports from scratch every time. Something tools like Mercurial have struggled with a lot.
Lots of Python applications, doesn't matter. But for this particular one, that would be a challenge.
And then resolving is big, heavy, like that MP complete, like just really gnarly, burning as as many CPUs as you can on complicated logical operations.
Again, not Python's strongest point.
It's not something you could use NumPy for, and it's not I/O bound or anything.
>> Yeah. You could use something like Cython potentially, using no-gill operation.
>> Yeah.
>> But at the same time, then you're pretty far.
>> You'd basically be writing it in C at that point.
>> Yeah. You're pretty far from core Python.
>> Yeah. Then finally, they just unpacking files is totally I/O bound and so simple, that it's actually a big advantage to be able to like, like, like, I always so fast these days, with like SSDs and everything, and VME drives, that like almost any overhead in the unpacking path actually is pretty substantial as a relative proportion. So like you add like one Python operation per, you know, you know, 100 kilobytes written, and that might suddenly be like a 2x slowdown, just because everything else is so fast that even that small amount of Python overhead could be large. And you know, in a tool like this, like people are really sensitive, like they really care if it takes 10 seconds versus one second to unpack those, the environment, like that's just a huge difference in usability. So I think it's just it's kind of really, like it just happens to be an exact combination of things that makes Rust pretty compelling, but you could do it the other way too. You know, I'm not making a, it isn't meant as a political point. Yeah, okay, got it.
Yeah, Python is written in C. Yeah, sure. So it's a pipeline. But I mean, the core, you know, the core bit of it is written in C, right?
No, but yeah, Pi Pi is written in Python, right? Hence the name.
Yeah, that's true.
Yeah, yeah. C, Python written in C. It says it right there.
Yeah, exactly. Okay, interesting.
I think we're probably out of time to dive much further in this, but...
Sure. Yeah, I think we covered a lot.
- I think we covered a lot. - I think we covered a lot.
- I guess... - Anything else you want to add?
Give me your thoughts on the future. Like, what do you think?
Is the PEP gaining traction? Right?
This is in draft mode. I don't know how much I emphasized at the beginning, but it is not an accepted thing yet, right?
Yes, that is important to be clear on, though. Yeah.
- Yeah? Where is it? - I wrote it.
I posted it for feedback. That's as far as it's gotten.
You know, there's no commitment on anyone's part to, like, that this is what's actually going to happen.
That said, I'm pretty optimistic.
Like I said, I got a little bit of pushback on the Posi part because of the rust and whatever.
But I don't think I've gotten -- I can't think of really any pushback on the PEP 7.11, the actual PyBI part.
Except people are like, well, why aren't you using Conda or something?
Which fair question, but there's an answer.
I don't think anyone -- it's not something that the people that you need -- whose agreement you need to get this accepted are the PyPI maintainers and Python packaging maintainers.
And they are totally okay with like, "Conda's not the solution to everything," obviously.
Right, sure.
Well, how complicated would it be to fit Conda into this particular use case, right?
Yeah, I mean, there's definitely room to collaborate better there.
And I would love to see that in the future.
But yeah, but my sense is that there's just really hasn't been a lot of like, people just seem pretty much like, "Yeah, this is cool." I guess actually, the biggest thing is that there's been some feedback from folks like the PyOxidizer folks saying, "Hey, we would like a bit more metadata so we can fully dissolve some of our other things we want to do." We want to be able to cross-compile for a given Python and we need to know a bit more about the target Python in order to do that. So that's just a very technical, it's like, "Yeah, okay, more stuff we should add and tweak." It's not against the idea.
But the core idea...
Evolving it, yeah.
Yeah, I think the basic idea, generally people seem to be on board. I'm not going to make a commitment to what like Python.org and PyPI and all they're actually going to do. But I'm pretty hopeful. I think that there are definitely some of the folks involved in building the Python.org downloads right now are like, "Oh yeah, I'd build one of these if that was standard, sure." Sure.
So it isn't all signed off on, but there seems to be a pretty reasonable consensus that this is a good direction that we're interested in moving in.
Well, it sure caught my attention when I saw it. So I'm excited to see what it looks like.
- Thank you for having me on to talk about it.
- Yeah, you bet.
No, let me just ask you real quick the final two questions.
Since it has been five years since I asked them of you.
- Okay.
- Do you write some Python code?
Do you work on this?
What editor are you using these days?
- I am using Emacs, same as I've been since I was 13.
So that's not a political position.
That's just, I'm stuck.
- Like all your commands are coming in chords, right?
Okay, got it.
- You know, like that's it.
- Excellent.
And then notable PyPI package?
Just some random PyPI package?
Yeah, something you ran across, that's awesome.
People should know about this.
Could be very popular or not popular at all.
Oh, man, shoot, I did not prepare for this.
Should have.
I mean, I don't-- like, there's some obvious--
like, obviously, I like-- you know, Trio's been thinking about it a lot, but that's not an interesting answer for this.
You mentioned Ruff earlier.
I think you mentioned Ruff, but Ruff is pretty cool.
Maybe I didn't mention Ruff, yeah, okay.
Ruff is very awesome. If anyone doesn't know, Ruff is sort of, you know, Flake 8 and such re-implemented in Rust. So it's like a hundred times faster. Like you just like instantaneously lint all your code, which is very sweet.
Is a selling point for Rust integrated with Python, right? Like another use case that looks pretty neat.
Yeah. And I, you know, sort of as I'm digging into it, I'm really impressed at how they, those two, how well they fit together. People put a lot of work into like making that really smooth and having them collaborate well. Actually, something I've just been working on at work is we've been having trouble with -- so in an async library like Trio, you have lots of tasks running concurrently, but the scheduler only gets to switch from one task to another when one task explicitly lets go, like says, okay, I can stop here. We're using an await statement. So it's possible to write code where you accidentally don't do that for a long time and that task will just like hog all the runtime and block other tasks from running.
And it'd be nice, it's hard to kind of tell when that's happening. And a similar thing could happen with the gill. So if you have like an extension library like, you know, PyTorch or something, and they forget to drop the gill before doing some big heavyweight operation, then it could just block any other threads from running. That's really awkward. We've been having trouble with that. And, but well, you know, like PySpy, that's another really cool package if anyone's seen it, is a Rust profiler for Python that can just sit outside your process and can tell you what it's doing. But also, it being in Rust and it's up on crates.io, I could just write a little program that imports PySpy and uses it as a library and tweak it so that instead of looking for where's code spending time, it detects, "Okay, is something hogging the gill or the run loop?" And give me the trace back, show me which code is doing that.
And it's, again, really neat to be able to get that really deep insight into this Python stuff that we're still using it. It's still Python, but the Rust really is a great flavor that goes with it. Cool. PySpy. All right, people can check that out. That's sampling profiler for Python programs.
Yes. Yeah. PySpy is really cool. Indeed. All right. Well...
Okay, cool. Thanks for being here. If people are interested in the PEP, What should they do? I mean, I guess the post on discuss.python.org is the best place for feedback.
It's also where I posted about Posey. So if you want to see the discussion or join in, that's a good place. If you want to help, then github.com/njsmith/posey is the repository.
jump in, send PRs, file issues, whatever. Or just send me a, I don't know, what's the toot at me, I guess? The Mastodon version. I'm not really on Twitter these days, but yeah, njs@mastodon.social. And I'll see you. Cool. All right. Well, Nathaniel, thanks for being here.
Thanks for this pep. It looks interesting. Yeah, thanks. It's great being here.
Yeah, you bet. This has been another episode of Talk Python to Me.
Thank you to our sponsors. Be sure to check out what they're offering. It really helps support the show. Take some stress out of your life. Get notified immediately about errors and performance issues in your web or mobile applications with Sentry. Just visit talkpython.fm/sentry and get started for free. And be sure to use the promo code talkpython, all one word.
Want to level up your Python? We have one of the largest catalogs of Python video courses over at at Talk Python. Our content ranges from true beginners to deeply advanced topics like memory and async. And best of all, there's not a subscription in sight. Check it out for yourself at training.talkpython.fm. Be sure to subscribe to the show, open your favorite podcast app, and search for Python. We should be right at the top. You can also find the iTunes feed at /iTunes, the Google Play feed at /play, and the Direct RSS feed at /rss on talkpython.fm.
We're live streaming most of our recordings these days.
If you want to be part of the show and have your comments featured on the air, be sure to subscribe to our YouTube channel at talkpython.fm/youtube.
This is your host, Michael Kennedy.
Thanks so much for listening.
I really appreciate it.
Now get out there and write some Python code.
[MUSIC]
