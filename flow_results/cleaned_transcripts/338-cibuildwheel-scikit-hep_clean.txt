How do you build and maintain a complex suite of Python packages?
Of course you want to put them on PyPI the best format there is as a wheel.
This means that when developers use your code, it comes straight down and requires no local tooling to install and use.
But if you have complex dependencies such as C or Fortran, then you have a big challenge.
How do you automatically compile and test against Linux, macOS, that's intel and Apple Silicon, Windows 32 and 64 bit, and so on.
That's the problem solved by CI Build Wheel.
On this episode, you'll meet Henry Schreiner.
He's developing tools for the next era of the Large Hadron Collider and is an admin of Scikit.
Hep, of course, cibuild wheel is central to that process.
This is Talk Python to Me episode 338, recorded October 14, 2021.
This is your host, Michael Kennedy.
Follow me on Twitter where I'm @mkennedy and keep up with the show and listen to past episodes at 'Talk Python.FM' and follow the show on Twitter via @talkpython.
We started streaming most of our episodes live on YouTube, subscribe to our YouTube channel over at 'TalkPython.FM/youtube' to get notified about upcoming shows and be part of that episode.
Hey there. I have some exciting news to share before we jump into the interview.
We have a new course over at Talk Python.
Htmx Plus Flask modern Python Web apps Hold the JavaScript. HTMX is one of the hottest properties in web development today, and for good reason, you might even remember all the stuff we talked about with Carson Gross back on episode 321 HTMX along with the libraries and techniques we introduced in our new course, will have you writing the best Python Web apps you've ever written, clean, fast and interactive all without that front end overhead.
If you're a Python Web developer that has wanted to build more dynamic interactive apps, but don't want to or can't write a significant portion of your app enriched front end JavaScript frameworks, you'll absolutely love HTMX.
Check it out over at 'Talkbython.FM/htmx or just click the link in your podcast player show notes.
Now let's get onto that interview, Henry, welcome to Talk Python to me.
Thank you.
It's great to have you here.
I'm always fascinated with cutting edge physics with maybe both ends of physics.
I'm really fascinated with astrophysics in the super large and then also the very small, and we're going to probably tend a little bit towards the smaller, high energy things this time around, but so much fun to talk about this stuff and how it intersects Python.
So the smallest things you can measure and some of the largest amounts of data you can get out.
Yeah, the data story is actually really crazy, and we're going to talk a bit about that.
So much stuff like we used to think that atoms were the smallest things to get. Right. I remember learning that in elementary school, like, there are these things called atoms.
They combine to form compounds and stuff. And that's as small as it gets.
Yeah.
Not so much, right?
Yeah. That was sort of what Adam was supposed to mean.
Exactly the smallest bit, but Nope.
But that name got used up. So there we are.
All right.
Well, before we get into all that stuff, though, let's start with your story. How do you get into programming in Python?
I started with a little bit of programming that my dad taught me. He was a physicist, and I remember it was C++ and sort of taught the way you teach Java, all objects and classes just a little bit.
And then when I started at college and I wanted to take classes, and I took a couple of classes again in C++, I just really loved objects and classes.
Unfortunately, the courses didn't actually cover that much, but the book did. So I really got into that.
And then for Python, actually, right when I started College, I started using this program called Blender.
Oh, yeah.
Blender. I've heard of Blender. It's like 3D animation tool, like Maya or something like that. Right.
And it's very Python friendly, right?
Yes.
It has a built in Python interpreter.
So I knew it had this built in language called Python. So that made me really want to learn Python.
And then when I went to research experience for undergraduates at Northwestern University in Chicago, and when I was there, we had this cluster that we were working on, this was in Solid State Physics, material physics.
And we would launch these simulations on the cluster.
And so I started using Python, and I was able to write a program that goes out, and it would create a bunch of threads. And it would watch all of the nodes in the cluster. And as soon as one became available, it would take it. So my simulation could just take the entire cluster. After a few hours, I would have everything.
So at the end of that, everybody hated me, and everybody wanted my scripts.
Exactly.
They're like, this is horrible.
I can't believe you did that to me, but I'll completely forgive you if you just give it to me and only to me because I need that power.
Yeah.
That's fantastic.
I think that is one of the cool things about Python, right? Is that it has this quick, prototyping approachability, like, I'm just going to take over a huge hardware, like a huge cluster of servers.
But it itself doesn't have to be, like, intense programming. It could be like this elegant little bit of code.
Right.
You can sort of do things that normally I think the programming gets in the way more, but Python tends to stay out. It looks more like pseudocode, so you can do more and learn more.
And eventually you can go do it in C++ or something.
Yeah.
Absolutely.
Or maybe not.
Sometimes you do need to go do it in some other language, and sometimes you don't.
I think the stuff at CERN and LHC has an interesting exchange between C++ and maybe some more Python.
And whatnot so that'll be fun to talk about.
Yeah.
We've been C++ originally, but Python is really showing up in a lot more places, and there's been a lot of movement in that direction.
There's been some really interesting things that have come out. A lot of interesting things have come out of the LAC computing wise, as well as awesome.
Yeah.
As a computing bit of infrastructure, there's a ton going on there. And as physics, it's kind of the center of the particle physics world.
Right.
So it's got those two parallel things generating all sorts of cool stuff.
I want to go back to just really quickly.
You talked about your dad teaching a little programming.
If people are out there and they're the dad, they want to teach their kids a little bit of programming. I want to give a shout out to CodeCombat.com
Such a cool place.
My daughter just yesterday was like, hey, dad, I want to do a little Python.
Remember that game that taught me programming like, yeah, sure. So she logged in and started playing and basically solve a dungeon interactively by writing Python. And it's such an approachable way. But it's not the, like, drag and drop a fake stuff. You write real Python, which I think is cool to introduce kids that way. So anyway, shout out to them. I had them on the podcast before, but it's cool to see kids take into it in that way.
Right.
Whereas you say you could write a terminal app, they're like, I don't want to do that, but solve a dungeon.
Yeah.
They could do that.
I actually played with a couple of those. They're actually really fun just to play.
Yeah, they are.
Exactly.
I did, like 40 Dungeons along with my daughter. It was very cool.
How about now? What do you do now?
I work in a lot of different areas, and I jump around a lot.
So I do a mix of coding.
I do some work on websites because they just needed maintenance, and somehow I got volunteered and some writing less coding than I would like. But I definitely do get to do it, which is fun.
Yeah. And this is at CERN or your University or where is this?
So now I'm at Princeton University, and I'm part of a local group of RSEs Research Software Engineers, and I'm also part of Irish, which will talk about a little bit, but that's sort of a very spread out group.
Some of us are at CERN, a few or in some other places.
Fermi lab and physicists are just used to working remote.
The pandemic wasn't that big of a change for us. We were already doing all our meetings remote. We just eventually changed from video to Zoom. But other than that.
Exactly, it was real similar for me as well. That's interesting.
Fermilab that's in Chicago outside Chicago, right?
Yes.
Is that still going? I got the sense of that was shutting down.
They begin neutrino physics.
They do a lot of neutrino things there, and then they're also very active just in the particle physics space. So you may be at Fermilab, but working on CERN data, I see.
Okay.
Interesting.
Yeah. I got most of that place a little bit.
And it's a really neat place.
It is. CERN is a neat place, too.
I would love to tour CERN, but it wasn't 20 minutes down the street from where I happen to be.
I didn't make it there.
Sadly, I hope to get back there someday.
All right.
Well, let's talk about sort of the scikit-HEP side of things and how you got into maintaining all of these packages.
So you found yourself in this place where you're working on tools that help other people build packages for the physicists and data scientists, and so on. Right.
So Where'd that all start?
So with maintenance itself, the first thing I started maintaining was a package called 'Plumbum' back in 2015, and at that point, I was starting to submit some PRS, and the author came to me and said I would like to have somebody do the releases.
I need a release manager.
I don't have enough time, and I'm sure I'd be happy to do it. It was exciting for me because it was the first package or real package I got to join, and I think on the page you might even still have the original news item when it says, welcome to me.
So that was the first thing I started maintaining.
And then I was working on physics tool called Goofy when I became a postdoc, and I worked on sort of really renovating that. It started out as a code written by physicists, and I worked on making it actually installable and packaged nicely and worked with a student to add Python bindings to it, things like that.
And as part of that, I wrote a C++ package, CLI 11 first package I actually wrote and then maintained and section C++, and it was written for good fit, but now it's fairly.
I think it's done pretty well on its own.
Microsoft Terminal use it.
Yeah.
Microsoft Terminal uses it.
Oh, nice.
Yeah. I'm a big fan of Microsoft Terminal.
I've for a while now kind of shied away from working on Windows because the terminal experience has been really crummy.
The CMD Exe command prompt style is just like, oh, why is it so painful?
And people who work in that all day they might not see this painful, but if you get to work in something like a macOS terminal or even to not quite the same degree, but still in like a Linux one.
Then all of a sudden it kind of gets there, but I'm kind of warming up to it again with Windows Terminal.
Yeah.
The Xterm is one of the reasons I really moved to Mac because I loved Xterm, and then Windows Terminal is amazing.
It's a great team working on it, including the fact that they used my Purser, but it's actually quite nice.
The only problem I have in Windows Ten is it's really hard to get the thing to show up instead of seeing CMD prompt.
Yeah.
Windows Eleven.
I definitely think it's included now, which is great.
So CLI 11, this is a C++ 11 command line parser.
Right.
Like click or Arg pars or something like that. But for C++, right?
Yes. It was designed off of the Plumbum command line Parser on sort of a toolkit that has several different things.
I wish those things had been pulled out because I think on their own they might have maybe even been popular on their own.
It has a really nice parser, but it's a designed off of that and off click.
It has some similarities to both of those.
Yeah. I think probably that's a challenge.
We're going to get into site GitHub with a whole bunch of these different packages, but finding the right granularity of what is a self contained unit that you want to share with people or versus things like pulling out a command line Archer rather than some other library. Right.
This is a careful balance.
It's a bit challenging. I think in Python, there's a really strong emphasis to having the individual separate pieces and packages, especially in Python, partially because it has a really good packaging system and being able to take things have just pieces and be able to swap out one that you don't like is really nice.
And that's one of the things we'll talk about the PyPI as well. And that's one of the things that they focus on is small individual packages that each do a job versus all in one poetry.
Yeah.
Well, you'll have to do some checking or some fact checking. Balancing modernizing.
For me. I did professional C++ development for a couple of years, and I really enjoyed it until there were better options.
And then I was like, Why am I still doing this?
I would go work on those.
But one of the things that struck me as a big difference to that world is basically the number of libraries you use.
The granularity of the libraries you use, the relative acceptance of things like Pip and the ease of using another library, right in C++.
You've got the header and you've got the Linked file and you've got the DLL.
There's, like, all sorts of stuff that can get out of sync and go crazy and make weird crashes. Your app just goes away, and that's not great.
Is that still true? I feel like that difference is one of the things that allows for people to make these smaller composable pieces in Python.
I think that has a lot to do with it. What has happened in C++ is there's sort of a rise of a lot of header only libraries, and these libraries are a lot easier to just drop into your project because all you do is you put in the headers and you don't have to deal with a lot of the original issues. So a lot of these small standalone libraries are header only.
And one of the next things that I picked up as a maintainer was Pybind11, and I've sort of been in that space between C++ and Python for quite a bit.
Kind of like being in that area.
Joining the two from listening to the things that you've worked on previously and things like this that you're interested in connecting and enabling piecing together.
Like here's my script that's going to pull together the compute on this cluster or here's this library that pulls together Python and C++ and so on.
Yes, making different things work together and combining things like C++ and Python, or combining different packages in Python and piecing together a solution.
I think that's one of Python strengths versus something like MATLAB. It's been quite a bit of time in MATLAB early on and got to move a lot of stuff over to Python.
That's awesome.
It was really nice that we didn't have to have a license and things like that.
I know it's so expensive, and then you get the what are they called toolkits, the Add on tool kits, and they're like, each tool kit is the price of another $1,000 a year or $2,000 a year. It's ridiculous.
So I know of CFFI, which is a way for Python and C to get clicked together in a simple way.
How's Pybind11 fit into that? This is seamless interoperability between C++11 and Python.
How are they different CFFI?
I teach, like a little short course where I can go through the different sort of different binding tools, and it usually ends with me saying Pybind11 is my favorite.
Yeah. Cool.
Give us an overview of what the options are and stuff is closer to C types. It's more of it's focused on C versus C++, and it's actually the one I've used the least.
I was just helping just talking with the CFFI developer, but I've used it the least of those, but I think it basically parses your C headers and then automates a lot of what you would have to manually do a C type, so you have to specify what symbol you want to call and what the arguments are and what the return type is. And if one of those things is wrong, you get a SEG fault and that sort of thing.
Whereas Pybind11.
This is about building modules, extension modules.
And the interesting thing about this is that it's written in pure C++ the other tools out there so Cython can do this. It's not what it was designed for, but immediately became popular for doing this because Cython turned code.
Python like code is a new language into transported into C or C++ at a toggle. You could change as a toggle. You can change.
And then when you're there, you can now call C or C++, but it's extremely verbose, and you repeat yourself and you have to learn another language.
This weird combined Python thing and just thinking in Cython is difficult because you have to think about, well, am I in Python or am I in Cython that can that's going to be bound to Python or am I in Cython? That's just going straight to C or am I just in C or C++?
But I've actually used it's a lot of layers there.
Yeah.
But Python is just C++, and it's basically the C API for Python, but C++ API, it's quite natural, and you don't have to learn a new language. It uses a fairly advanced C ++, but that's it. You're learning something useful anyway.
Right.
So do you do some sort of like template type thing and then say, I'm going to expose this class to Python or something like that, and then it figures out, does it write the Python code or what is it it's writing the build like so files or what do you do here?
It compiles into the C API calls, and then that would compile into a data cell. So there's no such Python or Swig or these other tools because it's just C++ like you do any other C++, but it's actually internally using the C Python API or PyPI's wrapper for it.
And the language looks a lot like Python. The names are similar.
You just do a def to define a function and give it the name, and then you just pass it the pointer to the underlying thing. You can figure out things like types and stuff like that for you.
Doc string if you want, give the arguments names.
You can make it as Pythonic as you want.
It's verbose, but it's not overly verbose.
Yeah, that's really neat.
And for people who haven't used those kind of outputs, basically, it's just import module name, whether it's a PY file or it's a.
PyTorch. If you've used CyPy used one of those things, you've been importing some Pybind11 code.
So let's talk a little bit about Scikit-HEP.
This is one of the projects that has a lot of these packages inside of it. And your library Cibuild wheel is one of the things that is used to maintain and build all those packages, because I'm sure they have a lot of interesting and oddball dependencies.
Right.
I mean, C++ is kind of standard, but there's probably others as well. Right.
It is.
One thing that is kind of somewhat unique to help is that we are very heavily invested in C++.
It's usually either you're going to see Python or you're going to see some sort of C++ package of some sort.
It could be varies in size there, but it's mostly C ++ or Python. We really haven't used other languages as much for the past 39 years.
Is that inertia or is that by choice?
Why is that?
I think it's partially. The community is a fairly cohesive community.
We're really used to sort of working together. The experiments themselves are often might be 1000 or several thousand visitors working on a single experiment.
And we have been fairly good about sort of meeting together and sort of deciding the direction that we want to go in and sort of sticking to that.
So for C++, it was heavily root, which is a giant C ++ framework, and it's got everything in it.
And that was C++, and that's what everybody used.
Right.
I was going to write code that would run and interact with, like the grid computing or the data access and all that kind of stuff at LHC.
I would use this route library if I was doing that C++, right.
Yes.
You might be using interpreted C++, which is something we invented.
Oh, okay.
This is interesting.
Is this something people can use?
Yes.
We actually CINT was the original interpreter, and then it got replaced by Kleen, which is built on the LLVM.
And I think recently it was merged to mainline LLVM as Clang Ripple. I think it's called, but sort of a lightweight version.
It's a C++ interpreter. You can actually get Zeus Cling, which I think quanstack, but they package it as well. I think it's just Zeus clean.
Okay.
Yeah.
Very interesting.
C++ really wasn't designed for a notebook, though.
It does work, but you can't rerun a cell often because you can't redefine things. Python is just really natural in a notebook. And C++ is not.
Yes.
Especially if you change the type.
You compile it as an Int, and they're like, that should be a string.
Yeah.
That's not going to be a string. It's compiled. Yeah.
Interesting.
So it seems to me like the community at CERN has decided we need some low level stuff and there's some crazy low level things that happened over there. People can check out a video.
Maybe I'll mention a little bit later, but for that use, they've sort of gravitated towards C, and then for the other aspects, it sounds like Python is what everyone agreed to say. Hey, we want to visualize this. We want to do some notebook stuff.
We want to piece things together, something like that. Right.
It's certainly moving that way.
They definitely have sort of agreed that Python should be a first class language.
And join C++. That was decided a few years ago, and I think that's been a great step in the right direction, because what was happening, people are coming in with Python knowledge. They wanted to use Pandas, and I came in that way as well.
Pandas and number. And all these tools were really nice, and we were basically just having to write them all ourselves in C++.
It has a data frame. But why not just use why not just use Python, which is what people know.
Anyway, Panda exists.
There's a ton of people already doing the work maintaining it for us.
Literally has a string class, literally.
They do everything the idea.
And that's the idea behind Scikit-Hep was to build this collection of packages that would just fill in the missing pieces, the things that energy physicists were used to and needed, and some of them are general.
And we're just gaps in the data science ecosystem. And some things are very specific.
High energy physics Scikit-HEP actually sort of originated as a single package.
It sort of looked like root right at first.
And it was invented by someone called it Bartovic Rodriguez, who is actually in my office at CERN and her office mates.
He did something I think really brilliant when he did this. And that is, he created an organization called Scikit-HEP around it.
And then he went out and spoke with people and got some of the other Python packages that existed at the time to join Scikit-HEP moved them over and started building a collection of some of the most popular Python packages at the time.
And I thought that was great.
And I really wanted Scikit-HEP to become a collection of separate tools. And for the second half package to just be sort of a meta package that just grabbed all the rest.
And that's actually kind of where it is now.
Right.
I can Pip install Scikit-HEP. Is that right?
You can. And mostly other than a few little things that are still in there that never got pulled out that will mostly just install our most popular maybe 15 or so packages.
Only 15 of our most popular packages.
Yeah. So it probably doesn't really do anything other than say it depends on those packages or something like that. Right then, by virtue of installing almost entirely.
Yeah.
It's a really cool idea. And I like it. So maybe one of the things I thought would be fun is to go through some of the packages there to give people a sense of what's in here.
Some of these are pretty particular, and I don't think would find broad use outside of CERN, for example, Conda Forge Root.
It sounds like that's about building route, so I can install it as a dependency or something like that. Right?
Yeah.
Building root is horrible.
And you actually now can get it as part of a condo package, which is just way better than anything that was available for attaching to a specific version of Python because it has to compile against a very specific version of Python, but that's what it does. So unless you want something in root, then that's very HEP specific.
Some of the more general ones probably briefly mentioned our very first package that I think was really popular among energy physicists that we actually produced was uproot, which was just a pure Python package. So you didn't have to install it.
That red root files again, very specific for somebody who was in high energy physics, but you could actually read a root file and get your data without installing root. And that was a game changer.
And now you can actually install root slightly easier, but normally it's a multi hour compile, and it's gotten better. But it's still a bit of a beast to compile, especially for Python.
That doesn't sound like a beast.
Oh, my God.
Now you can just read in your files.
Basically, Jim Povarsky basically just taught Python to understand the decompiled root file structure and actually can write right now, too. But originally reading, but that's like.
If I want to create a notebook and maybe visualize some of the data, but I don't really need access to anything else.
I shouldn't depend on this beast of almost its own operating system type of thing.
Yeah.
We are very close to being able to use all the data science tools in Python pandas things like that.
But most data worked fine.
You just had to get the data.
And I've done this too, where I had one special install of Python and root together that had worked several hours on and it sat somewhere, and I would convert data with it. I'd move it to HDfive, and then I would do all the rest of the analysis in Python that didn't have it.
Because then I can do Python libraries that read that HDfive format, right?
Yeah.
Right.
Okay.
The first package we had that was really popular on its own was awkward array.
I heard about this one.
Yeah, that was originally part of upper, sort of grew out of upper.
When you're reading root files, you end up with these jagged arrays so that's an array that is not rectangular, so at least one dimension is jagged. It depends on the data.
And this shows up in all sorts of places and not just particle collisions or obviously shows up lots of places and particle collisions. Like how many hits got triggered in the detector. That's a variable length list.
How many tracks are in an event that's a variable length list and can be a variable length list of structured data.
And to store that compactly the same way you'd use NumPy was one thing, but you can use arrow, and there's some other things that do this.
But Awkward Array also gives you NumPy, like indexing and data manipulation.
And that was the sort of breakthrough thing here the original one was built on top of NumPy.
The new one actually has some Pybind11 compiled bits and pieces, but it makes working with that really well. In fact, Jim Pavarsky got a grant to expand this to.
I don't remember the number of different disciplines that he's working with, but lots of different areas genomics and things like that have all use cases, and he's adding things like complex numbers and things that weren't originally needed by heavy physicist, but make it widely.
It's an Evangelism like Dev Evangelism type of role.
Right.
Go talk to the other groups and say, hey, we think you should be using this.
What is it missing for you to really love it? Something like that.
Right.
How interesting?
Looking at the awkward array page here says for a similar problem, 2 million times larger than this example given above, which one above is not totally simple. So that's pretty crazy.
It says Awkward array.
The one liner takes 4.6 seconds to run and uses two gigs of memory.
The equivalent Python list and Dictionaries takes over two minutes and uses ten times as much memory.
22 gigs. So yeah, that's a pretty appealing value proposition there.
Yeah. And it supports Numba.
Jim works very closely with the Numba teams and really is one of the experts on the Numba internals.
So it has full number support now, and he's working on adding Dask.
He's working with Anaconda on this grant and then working with adding GPU support.
Very cool.
Maybe not everyone out there knows what Numba is. Maybe give us a quick elevator pitch on number.
I hear it makes Python code fast, right?
Yeah.
It's just in time compiler.
And.
It takes Python. It actually takes the Byte code, and then it basically takes that back to something or it pushes the bytes code and turns it into LLVM.
It works a lot like Julia, except instead of a new language, it's actually reading Python bytecode, which is challenging because the Python bytecode is not something that stays static or supposed to be a public detail.
There's no public promises about consistency of bytecode across versions, because they play with that all the time to try to speed up things and they add byte codes and they try to do little optimizations.
Yes, every Python release breaks number, so they just know the next Python release will not support number, and it usually takes a month or two.
But it's very impressive, though.
The speed up. So you do get full C type speed ups for something that looks just like Python.
It compiles really fast for a small problem, and it's as fast as anything else you can do.
I've tried lots of these various programming problems and you just about can't beat them, but it actually knows what your architecture is, since it's just in time compiling.
Which is an advantage over say, like C, right. It can look exactly at what your platform is and your machine architecture and say, we're going to target.
I see your CPU supports this special vectorized thing or whatever, and it's going to build that in. Right.
And then what sort of Jim does with awkward? We've done with some other things with Vector does this, too.
You can control what Python turns into, what LLVM constructs any Python turns into, because you can control that compile phase.
That's incredibly powerful, because you can say and it doesn't have to be the same thing.
But obviously you want it to behave the same way.
They can say if you see this structure, this is what it turns into LLVM machine code, which then gets compiled machine language, then gets compiled into your native machine language.
Interesting assembly.
So if you have.
Like, a certain data structure that you know, can be well represented or gets packed up in a certain way to be super efficient, you can control that.
Yeah.
You can say that.
Well, this operation on this data structure, this is what it should do.
And then that turned into LlVM, and maybe it can get Vectorized or things like that for you.
Yeah, that's super neat.
Another package in the list that I got to talk about, because just the name and the graphic is fantastic is a gas.
What is aghast? It's got like the scream.
I forgot who was the artist of that. But the scream sort of look as part of the logo is good.
About half of the logos come from Jim, and he did about half and then use other around or from the individual package office.
This is sort of part of the histogramming area, which is sort of the area I work in. So I can help
But Jim actually wrote aghast, and the idea was that it would convert between histogram representations.
I think it came up because Jim got tired of writing histogram libraries. I think he's written at least five.
Yeah.
One of the things I got the sense of by looking through all the Scikit-Hep stuff.
There's a lot of histogram stuff happening over there.
Yes, histogram is sort of the area that I was in, and it ended up coming in several pieces.
But I think one of the important things was actually. And I think aghast may not really matter.
They get archived at some point because instead of sort of translating between different representations of histograms in memory, what you can do is define a static typing protocol, and it can be checked by MyPy that describes what an object needs to be called a histogram.
And so I've defined that as a package called, UHI, universal histogram interface and anything that implements, UHI, it can be fully checked by MyPy will then be able to take any object from any library that implements, UHI.
And so all the libraries we have that produce histogram so uproot when it reads a root histogram or Hist and boost histogram when they produce histograms.
They don't need to depend on each other. They don't even depend on, UHI, that's just a static dependency.
And then they can be plotted in NPL.
Hep or they can be printed to the terminal with just a histo-print.
And there's no dependencies there.
One doesn't need the other.
And that's sort of making aghast somewhat unneeded, because now it really doesn't matter. You don't have to convert between two because they both just work.
They work on the same underlying structure. Basically.
Right.
They work through the same interface, right?
Yeah. So aghast is a way to work with different histogramming libraries.
That kind of is the intermediary of that abstraction layer on that. Okay.
Yeah.
What are some other ones we should kind of give a shout out to. We talked about Goofit, which is an affiliated package.
It's not part of Scikit-HEP, but we developed this idea of an affiliated package for sure, things that didn't need to be moved in, but had at least one Scikit-HEP developer working or working with them. At least that's my definition. I was never able to actually get the rest to agree to exactly that definition. But that's my working definition.
So that's why Pybind 11 gets listed there.
It's an affiliated package because we share a developer with the Pybind11 library, and we sort of have a say in that and how that is developed.
And most importantly, if we have somebody come into Scikit-HEP, we want them to Pybind11 over the other tools because that one we have a lot of experience with.
Very cool.
Another one I thought was interesting.
Is Hep units?
So this idea of representing units like the standard units, they're not enough for us.
We have our own kind of things, like molarity and stuff, but also luminosity and other stuff, right?
Yeah.
Different experience can differ a bit. So there's a sort of a standard that got built up for units.
And so this just sort of puts that together.
And the unit that we sort of decided on this should be the standard unit, that's one and the rest of our different scalers.
It's a very tiny little library.
It was the first one to be fully statically Typed because it was tiny, easy to do because MyPy and first constants, there was like two functions or something. And then it was done.
Yeah.
Probably a lot of floats.
That's sort of what it is. You can use that and ideas that the rest of the libraries will adhere to that system of units.
So then if you use this and then use that values it gives you, then you can have a nice human readable units and be sure of your units.
Yeah.
That's really neat.
Have you heard of Pint?
Are you familiar with this one?
I love pint.
Actually, it takes the types through, and I use Pintum, but it actually gives you a quantity out or a NumPy quantity whereas the happiness just stays out of the way. And it's a way to be more clear in your code, but it's not enforced. Pint is enforced, which I like enforcing, but it also can slow down. You can't.
These are not actual real numbers anymore. So you pay.
Yeah.
So it's going to add a ton of overhead.
Right.
But Pine's interesting, because you can do things like three times meter plus four times centimeter, and you end up with 3.4 meters.
Those are actually real quantities.
They're actually a different object, which is the good thing about it. But it's also the reason that then it's not going to talk to a C library that expects a regular number or something as well.
Sure.
Okay.
Maybe one or two more and then we'll probably be out of time for this.
What else do people maybe pay attention to that? They can generally find useful over here.
Convention vector. It's a little bit newer, but certainly for general physics.
I think it's useful because it's a library for 2D 3D and relativistic vectors, and it's a very common sort of learning example, you see, but there aren't really very many libraries that do this that actually have.
If you want to take the magnitude of a vector in 3D space, there just isn't a nice library for that. So we wrote vector to do that.
And vector is supported by awkward.
It has an awkward back end. It has a numba back end, NumPy back end and then plain object back end.
Eventually we might work on more and it even has a numba awkward. So you can use a vector inside an awkward array inside a number jit compiled loop and still take magnitudes and do stuff like that.
That's really cool, because we have a lot of those statistics.
Sure.
And you can do things like ask if one vector is close to another vector and things like that even in different looks like one in polar coordinates and one in Cartesian or something like that.
It has different unit systems, and it actually stores the vector in that. So you don't have to waste memory or something if that's the representation you have.
That was a feature from Root that we wanted to make sure we got.
And it's also the idea of Momentums too. And stuff for the relativistic stuff.
We end up with a lot of that.
And then maybe just mentioned we mentioned the histogramming stuff and that's the area that's the one that I really work on.
The ones I specifically work on that are general purpose boost. Histogram is a wrapper for the C++ post boost. Histogram library boost is sort of the big C++ library just one step below the standard library.
And right at the time I was starting at Princeton, I met the author of Boostrami, who's from Physics, and he was in the process, I believe, of getting this accepted into Boost and I got accepted after that.
But one of the things that he decided to do is pull out his initial Python bindings that were written in Boost Python, which is actually very similar to Pybind 11 but requires boost instead of not requiring anything.
But the design is intentionally very similar.
And so I proposed I would work on Boost Histogram and write these Python bindings for it inside Scikit-HEP, and that would be sort of the main project I started on when I started in Princeton, and that's what I did this. Histogram is an extremely powerful histogramming library.
So it's a histogram as an object rather than like a NumPy.
There's a histogram function and you give it an array and then it spits a couple of arrays back out at you.
But you now have to manage these. They don't have any special meaning, whereas the histogram really are much more natural than object. Just like a data frame is more natural as an object where you tie that information together.
Histograms really natural that way, where you still have the information about what the data actually was on the axes.
If you have labels, you want to keep those attached to that data and you may need to fill again, which is one of the main things that your physicist really wanted, because we tend to fill histograms and then keep filling them or rebinding them or doing operations on them.
And you can do all those very naturally and boost Histograms C++ wrapper in Pybind 11.
And I actually got involved in Cibuildable because of Boost histogram because one of the things I wanted to to make sure it worked everywhere, and it obviously requires C++ compilation.
And then Hist is a nice wrapper on top of that. That just makes it a lot more friendly to use, because the original Boost scrambled here wants to keep this. Hanstobinsky wants to keep this quite pure and clean.
So Hist is the more natural. And even if you're not in Hep, I think that's still the more natural one to use.
Yeah.
Gold plot plot right.
There's a lot of people who use Histograms across all sorts of disciplines, so that would definitely be one of those that is generally useful.
All right. So I think that brings us to CI build wheel.
Let's talk a bit about that. And I mean, maybe the place to start here is you want our wheels, right.
The first sentence described as Python wheels are great building them across Mac Linux windows and other multiple versions of Python.
Not so much.
That's the description of wheel wheels.
Yeah.
Exactly.
Well, wheels are good.
There's times when there are no wheels and things install slower. They might not install at all.
It's generally a bad thing if you don't have a wheel, but they're not easy to make.
Right.
So tell us what is a wheel. And then let's talk about why maybe building across all these platforms and this cross product along with versions of Python.
And whatnot is a mess when you distribute Python, you have several options, the most common one. And most packages have at least an estist, which is just basically a tarball of the source.
Right.
When you modify slightly, maybe you're missing a few things or adding some things.
Otherwise, it unzips your source and puts it somewhere. Python will find it. And then that's that.
Yeah.
So it runs your build system.
So set up tools traditionally that's become a lot more powerful recently. But it has to run the build system to figure out what do you do with it. This is just a bunch of files, and then it puts it together in a particular structure on your computer.
And so a wheel was a package that was already everything was already in place.
So it's already in a particular structure. It knows the structure, and all Python has to do.
For a pure Python wheel, one that does not have any binary pieces in it.
It just grabs the contents inside and dumps them, following a specific set of rules into places into your site packages.
You have something installed, there's no setup PY in your wheel, there's no pyproject.main
Those sorts of things are not in the wheel. The wheel is already there.
It can't run arbitrary code.
Yeah. Exactly.
That was one of the points I was making.
One of those things that can be scary about installing packages is just by virtue of installing them.
You're running arbitrary code, because often that is, execute Python space set up PY space install or something like that.
Whatever that thing does, that's what happens when you Pip install.
Right.
But not with wheels.
As you said, it comes down in a binary blob and just like, boom, here it is.
Obviously, the thinking is we have this package delivered to a million computers. Why do we need to have every million computer run all the steps?
Why don't we just run it once and then go here and then also, that saves you a ton of time.
Right. Like I just installed Microwhiskey, and it took 30 seconds, 45 seconds to install because it didn't have a wheel. So it's up there and it just grinded away compiling it.
Yeah. So there's two possibilities.
A pure Python package wheel is still superior because of the not running arbitrary code.
Pip will actually go ahead and compile all your PYC files that goes ahead and makes the Byte code for all those. If it's a wheel, if it's a tarball, it doesn't do that.
If it doesn't pass through the wheel stage anyway.
And then every time you open the file, then it's going to the first time. It's going to have to make that byte code. So it'll be a little slower the first time you open it.
There's a variety of reasons I think it's Python wheels.
Com, something like that that describes why you should use wheels.
That's me. That's not it.
But yes, Python wheels. So they have, like, a list of advantages there.
But they also have a little like checklist. It says, how are we doing for the top 360 packages? And apparently 342 of them have wheels, and it shows you for your popular packages which ones like Click does.
But Future doesn't, for example, and so on.
Features been there for a long time.
So wheels are really good, and they actually replaced an older mechanism that was trying to do something somewhat similar called Eggs. But I avoid talking about this understanding.
Let it live in the past.
The wheels also are a great way. If you have compile and compile, that happens.
So if you compile some code as part of your build, then that, of course, is much slower.
If you have the example.
It's like it was doing GCC.
You don't have a compiler. It won't even work.
Right. Exactly.
You have to have some set up, at least a little set up. You have to have a compiler set up at the very moment.
Right.
How many Windows users have seen cannot find vcvars.bat.
Right.
I don't want to be in the environment or you have to have the right script sourced.
Yes.
So Wheels also can contain binary components like SOS and things.
And they have a tag as part of their name.
They have a very special naming scheme for Wheels, and the tag is stored in the wheel, too.
And they can tell you what Python version they are good for, what platform they are supported on.
They have a build number, and then they have the Python is actually in two pieces. There's the Api and the interface.
Python.
Yeah.
You can see there's some huge long name that with a bunch of underscore separating it and basically.
Solid.
Sorry.
Go ahead.
It's also one of the reasons that names are normalized.
There's no difference between a dash and underscore it's because that special wheel name has dashes in it. So the package name at that point in the file name has to be underscores.
Yeah. So basically, when you Pip install it, builds up that name and says, do you have this as a binary?
Give it to me.
Right. Something like this.
Yes.
It knows how to pick out it looks for the right one. If it finds a binary, it will just download it, depending slightly on the system and how new your Pip is.
Right. And this is one of the main innovation, ideas and philosophies behind Conda and Anaconda.
Let's just take that and make sure that we build all of these things in a really clear way and then sort of package up the testing and compilation and distributing all that together.
Right.
Yes. This is very similar to this game. I think. I'm pretty sure it came after Condo, I think, where they were still in Eggs when Condo was invented and then sort of building up wheels was challenging.
Building a wheel was challenging.
CiBuild wheel has really changed that.
If you want a pure Python, it's really easy today you should be using the build tool, which I'm a maintainer of that as well.
But build just builds an estimate for you or it builds a wheel.
So you say something like Python setup.py Bdist or something like that and then boom.
You shouldn't be doing that anymore. Please don't.
Okay.
Yeah.
How would I do it? Tell me the right way.
Well, you could do Python or Pip install build and then Python build, and that will build both an estist and a wheel, and it'll build the wheel from the estist.
If you use Pipex, which I would recommend, then you can just say pipex run build and you don't have to do anything that'll download build into a virtual environment for you.
It'll do it, and then eventually it will throw away the original after a week. Interesting.
Okay, so we could just use the build.
We should be using the build.
You should be using the build tool for estest. There's a big benefit to this, and that is it will use yourpyproject.tobal, and if you say you require NumPy, then it will go like you're using the NumPy headers, the C headers, then it will go.
When it's building Estus, it will make the Pep 517 virtual environment.
It will install Numba anything that's in your requirements in your Pyproject.mo, and then it will run the setup PY inside that environment. So you can now import NumPy directly in there and it'll work even when you're building a estest.
If you do Python Eston set up PY stuff, you can't do that because you're literally running Python giving it set up PY import NumPy. Now it's broken, right?
Nothing triggers that call to the pyproject.
Com to see what you need for a wheel.
The best way to do it is with Pip or the original way to do it was with Pip wheel, because Pip has to be able to build wheels in order to install things that got added to Pip before build existed.
But now the best way to do it would be with build wheel and that's actually doing the right thing. It's actually trying to build the wheel you want, whereas Pip wheel is actually just building a wheelhouse. So if you depend on NumPy and Numpy, does'nt have wheels.
They did better with Python 310, so I'm not going to complain about them for Python 310, but for three nine, they didn't have wheels for a while.
So it'll build the wheels there and it'll build your wheels and it'll dump them all in the wheelhouse, whatever the output is. So you'll be building Numpy wheels, which you definitely don't want to try to upload.
Yeah, definitely not.
All right.
Well, that's really cool. And I definitely learned something. I will start using build instead of doing it.
The other way you can now delete your setup PY too.
Yeah.
That's the big thing, right? You don't have to run that kind of stuff, right?
Yeah.
They're trying to move away from the any commands to set up PY because you don't even need one anymore, and you can't control that environment.
It's very much an internal detail wrapping up this segment of the conversation.
We want to wheel because that's best. It installs without requiring the compiler tools on our system.
It installs faster.
It's built just for our platform.
The challenge is when you become a maintainer, you got to solve this matrix of different Python versions that are supported and different platforms. Like, for example, there's macOS intel, there's macOS M1 Apple Silicon.
There's multiple versions of Windows.
There's different versions of Linux, right. Like Arm, Linux versus AMD 64.
Linux Mulenix versus the other Linux varieties.
Yeah.
So one of the challenges with the wheel is making it distributable.
So if you just go out and you build a wheel and then you try to give it to someone else that may not work.
Certainly on Linux if you try to pretty much. If you do that, it just won't work because the systems are going to be different on macOS.
It'll only work on the version you compiled it on and not anything older.
And you don't even see people trying to compile on Mac OS 10.14 because they want their wheels to work as in many places as you want.
Exactly.
I find the Janky. It's like I've got a Mac Mini from 2009.
We're building on that thing because it will work for most people.
Right.
I think that's how they actually build the official Python binaries.
Interesting.
I'm not sure.
But then Apple went in like last year.
Around this time they threw a big spanner in the works and said, you know what? We're going to completely switch to Arm and our own Silicon, and you got to compile for something different now.
Yeah. And cross compiling has always been a challenge.
And then Windows is actually the easiest of all of them. You're most likely on Windows to be able to compile something that you can give to someone else.
Yeah, that's true. That is one of the things that Microsoft's been really pretty good at is backwards compatibility.
I get holds them back in other ways, but yeah, typically you can run an app from 20 years ago and it'll still run.
Yeah, there are a few caveats, but not many, at least compared to the other systems.
Apple is really good, but you do have to understand how to you do have to set your minimum version, and you have to get a Python that had that minimum version set when it was compiled.
If you do that, it works really well.
So what actually started with Scikit-HEP, I was building boost histogram, which needed to be able to run anywhere. That was something I absolutely wanted. It had to be Pip install this histogram and it just worked no matter what.
And also we had several other compiled packages at the time. Several we had inherited and was compiled and that was quite popular.
We had a couple of specific ones and we had a couple more that ended up being becoming interested in that. In fact, during this sort of period is when Awkward started compiling pieces.
When I started with was building my own system to do this, it was called Azure Wheel Helpers, which was you can guess by the name. Azure was basically set up dev ops scripts.
It was right after Azure had come out and I wrote a series of blog posts on this and described the exact process and sort of the things I found out about how you build a compatible wheel on macOS. You have to make sure you get the most compatible C Python from Python.
Org itself.
You can't use Brew or something like that because those are going to be compiled for whatever system they were targeting.
And on Linux you have to run the mini Linux system and you should run Audit Wheel.
Actually, Mac you should run Wheel that I might be getting him. I think it's a series of things that you have to do.
And I started maintaining this multi hundred line set of scripts to do this, and I was also being limited by Azure at the time. They didn't have all the templates and stuff they have now, so everything had to be managed through Get subtree because it couldn't be a separate repository.
And then when Jim started working Awkward, he went and just rewrote the whole thing because he wanted it to look simpler for him and took a couple of things out that were needed and suddenly made it two separate things. Now I had to help maintain that. So when Python 3.8 or whatever it was came out now I had a completely different set of changes I had to make for that one and it was not working out.
It was not very easy to maintain.
And I was watching CI build Wheel and it was this package. It was a Python package that would do this and it didn't matter what CI system you were on because it was written in Python and it followed nice Python principles for good package design and had unit tests and all that sort of stuff. So it looked really good. There were a couple of things that was missing. I came in, I added, I made PRS for the things that I come up with that it didn't have and they got accepted.
And there was a shared maintainer between Pi Bind11 and CI Build Wheel as well. I think that's one of the reasons that I heard about it was really watching it and I finally decided just to make the switch and I did. At some point a little later I actually became a maintainer of CI built, but I think I started doing the switch before it made it really easy. Once I was a maintainer to say this is a package that we have some control over it's. Okay. Let's just take a choice to depend upon this because we have a say it just took out all that maintenance and now depend about does all the maintenance for us.
Does the pin moves forward to pin and see a build wheel? That's it nice.
So if I want to accomplish if I'm a package developer owner and I want to share that package to everybody, we've already determined we would ideally want to have a wheel.
But getting that wheel is hard. So CI Build Wheel will let you integrate it as the name indicates, into your continuous integration.
And one of those steps of CI could be build the wheel, right?
Almost.
It reduces it down to pretty much that there's a step in your CI that says, run CI Build wheel.
And then CI Build wheel is designed to really integrate nicely with the build matrix. So for a fairly simple package or for many packages, you can really just do Mac, Windows and Linux have the same job, like in GitHub actions. It's easy to do the same job and then call CI Build wheel, and that's about it.
It just goes through all the different versions of Python that are supported.
It just goes through and makes a wheel for each.
And in fact, it even has one feature that was really nice that I struggled with a bit is testing.
So if you give it a test command, it will even take your package. It will install it in a new environment that's not in a different directory that's not related to your build at all and make sure it works and passes whatever test you give it.
We'll do that across the platforms. We'll do, like on each one test and a Windows test.
Yeah.
For each will really just sees the platform it's sitting on because it's inside the build matrix. And so it's run for each and for each one.
It will run that test.
And the simplest test is just Echo, and that will just make sure it installs because I won't try to install your wheel unless there's something in that test command.
Even that's useful, sometimes even that's broken, sometimes because of Numpy not supporting one of those things in that matrix.
Yeah, it can install the dependency.
So that step fails or something.
So it currently supports GitHub Actions Azure pipelines, which I don't know how long those are going to be two separate things. Maybe they'll always be separate. But Microsoft owned GitHub be like they say do stuff in Azure pipelines, and then they're kind of moving like.
I think there's somewhere the runners are the same.
They actually have the same environments.
So I think they'll exist just as two different interfaces, probably.
And Azure is not so tied to GitHub and it has more of an enterprise type.
Yeah, for sure.
Definitely.
It was just a rewrite and a better rewrite. In most cases of it. I got to learn.
Yeah, I think you have actions came second. All right. So then Travis CI, appFair CircleCI and GitLabCI at least all of those.
Right.
At least those are the ones we test on, and then it runs locally.
There are some limitations to running it locally.
If you target Linux and any system that has Docker and target Linux, you can just ask to build Linux.
You can actually run it from my Mac or from Windows, I assume from Windows machine. I tried Windows with Docker and Windows.
It does install to a standard location C colonback, CI buildwheel, but other than that, it's safe to run out there and Mac OS it will install to your macOS system.
It's all system versions of Python, so that's something we haven't solved yet might be able to do some day.
It's not a good idea unless you really are okay with installing every version of Python that ever existed into your system.
Maybe get a CPython.
Org Python.
Yeah, it's somewhat safe.
If you're on Windows, you could use Windows subsystem for Linux to BSL as well.
In addition to Docker, I suspect that Mini Linux has to run.
I'm sure as long as you can launch Docker.
The thing that you have to be able do is launch Docker because you have to use the Mini Linux Docker images or you should use that or derivative of that.
There's lots of rules to exactly what can be in the environment and things like that.
And PyPI maintains that one thing that also helps is that we have the Mini Linux maintainer is also a CI build wheel. Maintainer. That's one reason that those things tend they fit well together.
Features tend to match and come out at the speed like mutual linux, which is a big thing recently.
It's not actually in a released version of CI build yet.
What is mutual Linux so normal? Linux is based on G libc and that's actually what controls it's. One of two things that controls Mini Linux.
So can you download the binary wheel or do you have to build if you have an old version of Pip, they had to teach Pip about each version of Mini length.
That was a mess, so they eventually switched to a standard numbering system that is your Glibc number.
And now Pip the current Pip will be able to install a future mini linux as long as your system.
But that was a big problem. So Pip nine can only install Mini Linux one. It can't install many Linux even if your Glibc is fine for it.
The other thing is the Glibc version and Mini Linux one was based on Centos5 -2010 was send to 6.
Mini Linux 2014 was sent to S seven and then now they switched to DBN because of the send to us sort of switching to the Stream model.
So Mini Linux 224 is G Lipsy 2.24. And that's DBN eight or something like that.
But that's Glibc based.
There are distributions that are not Glibc based, most notably Alpine.
Very used Alpine, this tiny, tiny little Docker image. It's really fun distribution to use if you're on Docker, but it actually sounds fun to install, but I've never tried it without Docker, but it's these five megabyte Docker wheels or Docker.
Docker doesn't do wheels Docker images, but that doesn't use Glipsy. They use his Musil, and so measle Linux will run on Alpine.
Okay.
Got it. So if you're building for the platform Alpine and similar ones, right?
Yeah. You said I can run this locally as well.
I know I would use it in CI because I've got that matrix of all the versions of C, Python and PyPI and then all the platforms. And I want to check as many of those boxes as possible to put wheels in it, right?
Yeah.
Suppose I'm on my Mac and I want to make use of this to fill in, maybe do some testing, at least on some of these columns.
How do I do that? What's the benefit there?
Well, I can tell you the case where it happened.
So we were shipping CMake and the second build organization ran out of Travis credits and they were being built.
We hadn't switched them over to being Emulated builds on GitHub actions yet, and it just ran out.
We couldn't build them, and one of them had been missed, and we also weren't waiting to upload. So we uploaded everything, but we had one set. Or maybe it was all of the Emulated builds. I think it was one set.
It didn't work.
And so we wanted to go ahead and upload those missing wheels.
And I tried, but I couldn't actually get Emulation Docker emulation.
I couldn't get that working on my Mac.
So the Mini Linux maintainer used his Linux machine and he had Q emulation on it, and he built the Emulated images a few hours, but he just built locally and then uploaded filled in the missing wheels.
So if I'm maintaining a package, I got some package I'm putting on PyPI and I want to test it.
Does it make sense to do it locally or does it just make sense to put it on some CI system?
Same builder.
Usually I do some local testing, but I'm also developing same builder, but usually it's probably fine to do this just in your CI and usually don't want to run the full thing every time. Usually you have your regular unit tests.
The CI build is going to be a lot slower because it's going through and it's making each set of wheels launching Docker images and things like that.
And it's installing Python each time for Mac OS and Windows.
Usually if you have fairly quick build I've seen some people just run CI build as part of their test suite, but usually you just run it, say right before release.
Maybe I usually do it once before the release and then on the release.
Right. Exactly.
Okay.
That makes sense because it's a pretty heavyweight type of operation.
So when I look at all these different platforms, I see Mac OS, intel, macOS, Apple Silicon differentnesses of Windows.
And then I think about CI systems.
What CI systems can I use that support all these things? Like does GitHub Actions support both versions of macOS, for example?
Plus, Windows GitHub Actions is by far our most popular platform.
It switched very quickly. It used to be Travis.
Travis was a challenge because they didn't do Windows very similar to Windows very well.
And it's a challenge for us because we actually can't run our macOS tests on them anymore, because once we joined the PIPA, the billing became an issue, and we just basically just lost macOS running for it.
But Circle, I think Azure and GitHub auctions. I think they do all three.
And you can always flip things up, Travis, for the Linux and then appfair for Windows.
You can do it that way.
One of the big things that I have developed for CI build wheel was the type project TML tunnel configuration.
Usually that configuration for CI build wheel.
That way you can get your CI build wheel configuration out of your YAML files.
That way it works locally, which is one of the things I was after, but also you can just do it and then run on several different systems like you might like the fact that Travis is, I think the only one that does the native strange architectures.
You have to emulate it other places, which is a lot slower, five times slower or something.
Yeah. So kind of split that up, get the definition and then create maybe multiple CI jobs.
Really simple.
The example script is just a few lines. It does not take much to do this comparing to take.
Yeah, sure. And I didn't even scroll down here. You've got a nice grid on GitHub.com/cibuildwheel that shows on GitHub Actions, which is supported on Azure pipelines.
What supported CI doesn't do this.
Out there Appfair, Travis, Azure and GitHub Dot.
But we can't test it.
Theoretically, it does.
It got you.
And then I wonder about the M1, the Apple Silicon Arm versions versus the intel versions.
I don't know how well that's permeated into the world yet, but the fact they have Mac at all is kind of impressive.
Nobody has an M1 runner yet.
There are a few places I think now that you can purchase time on one, but no runners.
Last I checked GitHub Actions, you couldn't even run it yourself on m1. One that may have changed.
I don't know.
That was a while back.
Yeah, there are some crazy places out there. I think there's one called Mac Mini Colo.
I think that's what it's called. Let me see.
I think that's it.
You can go to these places like Mac Mini Colo, get a whole bunch of Mac minis and put them into this crazy data center.
But that's not the same as I upload a text file into GitHub that says Run on Azure on Get of Actions, and then that's the end of it. Right. You probably got to set up your whole, like, some whole build system into a set of minis.
And that doesn't sound very practical for most people.
Ideally, what you could do is you just need one mini, and then you set up a GitHub, actions hosted Runner, locally hosted Runner and other systems.
Git Labci was big on that.
You can do anything on GitLab CI. We just haven't tested that because they don't have those publicly. But if you have your own, you can do that.
I know somebody who does this with basically has a Mac mini and runs the M one builds on that.
But you could do that. I have a Mac mini and the lead developer of Cibuildwheel  also has M one.
He has an M one or something. I don't know.
Mine is Mac.
That's what I'm talking to you right now on it's a fantastic little machine.
Yeah, it's very impressive. I love the way that boosts histogram. It was fast.
I have a 16 inch, almost maxed out MacBook and the Mac Mini M one. It was faster and boost histogram than this thing.
Wow.
Yeah, I have a maxed out 15 inches, a little bit older, a couple of years, but I just don't touch that thing unless I literally need it as a laptop because I want to be somewhere else. But I'm definitely not drawn to it.
So you could probably set up one of these Mini's for $700 and then tie it up. But that's again, not as easy as just clicking the public free option that works, but still, it's within the realm of possibility.
Apple has actually helped out several like, I know Homebrew and a few others they've helped out with by giving them the Mac minis or something that they could build with. So I believe Brew actually builds Homebrew actually builds on Realm ones.
I know it does because the bills are super fast. I remember that like it builds root, like, 20 minutes.
The root recipe, because I maintain that.
And the normal one takes about an hour. It's running on multiple cores, but it's like three times faster. It's done in 20 minutes. Just thought something was wrong. When I first saw that.
How could it be done?
Something broke. What broke?
Interesting.
All right, Henry, we're getting really short on time, a little bit over, but it's been a fun conversation. How about you give us a look at the future? Where are things going with all the stuff?
Next thing I'm interested in being involved with is Scikit build, which is a package that currently sort of augments set up tools, but hopefully eventually sort of replace set up tools as the thing that you build with, and it will call out to CMake.
So you basically just basically write a CMake file and this could wrap an existing package.
Or maybe you need some of the other things that Cmake has and this will then let you build that as a regular Python package.
In fact, recently somebody sort of put together CI build wheel psychic build and C make example and built LLVM and pulled out just the claim format tool and made wheels out of that.
And now you can just do Pip and so claim format. It's one to two megabytes. It works on all systems including Apple Silicon and things. I just tried it on Apple Silicon yesterday and it's a Pip install.
Now you can claim format C++code and that's just mindblowing added to pre commit the precommit CI it runs in two. I mean, I've been fighting for about a week to reduce the size of the claim format recipe from 600 megabytes to just under the 250. That was the maximum for freaking at CI.
And then you can now Pip install under about a megabyte for Linux that sort of thing. And I think that would be a really great thing to work on. It's been around since 2014, but it needs some serious work.
And so I'm currently actually working on writing a grant to try to get funded to just work on basically the scikit build system and looking for interesting science use cases that would be interested in adapting or switching an existing build system over or adapting to it or taking something that has never been available from Python and making it available.
And yes, root route might be one.
I'm looking for a wide variety of scikit build package is fundamentally just the glue between set of tools, Python module and CMake.
Yeah. So it's a real way to take some of these things based on CMake and sort of expose them to Python.
Yeah. So you can just have a Cmake package that does all the C make things well, like finding different libraries and that I'm a big Cemic person.
How do you use it very heavily.
Most C++ does. It's about 60%. I think of all build systems or CMake based now get from gateways numbers, but they may seem like, but I think it's very powerful. It can be used for things like that.
And we'll really open up a much easier C++ more natural in C++ and Fortran and things like that in CUDA then is currently available. Set up tools just utilize is going away in Python 3.12.
Setup tools is not really designed to build C++  packages or packages. It was really just a hack on top of distributors which happened to be build. Just Python itself.
Well, Scikit sounds like the perfect tool to apply to the science space because there's so many of these weird compiled things that are challenging to install and deploy and share and so on. So making that easier sounds good.
All right.
Well, I think we're probably going to need to leave it there just for the sake of time, but it's been awesome to talk about all the internals of supporting Scikit-HEP, and people should check out CI Build wheel.
It looks like if you're maintaining a package either publicly or just for internal for your organization, it looks like it would be a big help if it's got binary.
Any sort of binary build in it?
Yes.
Absolutely.
If not, build is fine.
Yeah.
Right.
And I learned about build, which is good to know.
All right.
So before you get out of Henry, let me ask you the two final questions.
You're going to write some code.
Python code. What editor would you use?
Depends on how much it'll either be VI if it's a very small amount.
If it's a really large project that takes several days, then I'll use PyCharm and then I've really started using Vs code quite a bit. And that's sort of expanding to fill in all the middle ground and kind of eating in on both of the other edges.
Yeah.
There's some interesting stuff going there. Good choice.
But all with the VI mode, there are plugins added, of course.
And then notable PyPI package. I mean, we probably talked about 20 already.
If you want to just give a shout out to one of those, that's fine. Or if you got a new idea.
I'm going to go with one that might not get mentioned, but I'm really excited by it. The development of it is I think developers quite new, but what he's actually done as far as the actual package has been nice.
It needs some nice touches.
And that is plot text.
P-L-O-T-T-E-X-T.
And I'm really excited about that because it makes these the actual plot. It makes a really, really nice.
And they're plotted to the terminal and it can integrate with.
And of course, I'm interested in it because I want to integrate it with I want to see it integrated with a textual app that combines this with file browsers and things like that.
With Apple.
Yes.
You could cruise around your files, use your root IO integration, pull these things up here and put the plot right on the screen.
Right. But in the terminal.
Okay.
Yeah. This is really cool. I had no idea. And this is based on Rich. You say it can integrate with Rich. Okay.
Got it. Yeah.
As soon as I saw it, I started trying to make sure the two people were talking to each other will, and as soon as they can this.
Yeah, exactly.
These things work together.
That's very cool.
They seem like they should right. They're in the same general zone.
Yeah, and they do now.
There had to be some communication back and forth as far as what size the plots were in.
This shouldn't work in.
It a good recommendation.
Definitely one I had not learned about, so I'm sure people enjoy that.
All right, Henry, final call to action. People want to do more with wheels.
ci build Wheel or maybe some of the other stuff we talked about. What do you tell them?
Look through.
I think one of the best places to go is the Scikit Hep Developer pages. If you have no interest in Scikit Hep tools or Hep at all and that sort of shows you how these things integrate together really well.
And nice documentation.
Build Wheel itself is nice. And the PyPI a lot of the IPA projects have gotten good documentation as well as packaging Python.
Org.
We've updated that quite a bit look like to reflect some of these things, but I really like the Scikit Developer pages. I mean, I'm biased because I wrote most of them nice.
Yeah, I'll link those together.
I'll try to link to pretty much everything else we spoke to as well, so people can check out the podcast player showing us to find all that stuff. I guess one final thing that we didn't call it that, I think is worth pointing out is CI build Wheel is under the PyPI, the Python Packaging Authority, so it gives it some officialness.
I guess you should say yes.
That happened after I joined one of the first things I wanted to do was I thought this should really be in the PyPI, and I was sort of pushing for that. And the other developers were fine with that.
And so we brought it up and I actually joined the PyPI just before that by becoming a member of Build.
So I got to vote on Build oil coming in. But it was a very enthusiastic vote, even without my vote.
And Pipex joined right at the same time too. So those were fighting time.
Pipex is a great library.
I really like the way Pipex work. It's a great tool.
All right, Henry, thank you for being here. It's been great.
Thanks for all the insight on all these internals around building and installing Python packages.
There's also a lot more on my blog, so I sign numpy.GitLab.IO that links to all those other things, obviously too.
Thank you for being here. Yeah.
See you. Thanks for having me.
You bet. This has been another episode of Talk Python to me.
Our guest on this episode was Henry Schreiner, and it's brought to you by us over at Talk Python training and the transcripts were brought to you by 'AssemblyAI'.
Do you need a great automatic speech to text API?
Get human level accuracy in just a few lines of code?
Visit 'talkpython.fm/AssemblyAI' want to level up your Python?
We have one of the largest catalogs of Python video courses over at Talk Python.
Our content ranges from true beginners to deeply advanced topics like memory and async.
And best of all, there's not a subscription in site.
Check it out for yourself at 'Training.Talkpython .FM be sure to subscribe to the show.
Open your favorite podcast app and search for Python.
We should be right at the top.
You can also find the itunes feed at /itunes, the Google Play feed at /play and the Direct RSS feed at /RSS on Talk Python.FM We're live streaming most of our recordings these days.
If you want to be part of the show and have your comments featured on the air, be sure to subscribe to our YouTube channel at 'TalkPython.FM/youtube'.
This is your host, Michael Kennedy.
Thanks so much for listening. I really appreciate it. Now get out there and write some Python code.
Python.
