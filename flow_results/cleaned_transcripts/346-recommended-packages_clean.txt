Do you enjoy the final two questions I always ask at the end of the show? I think it's a great way to track the currents of the Python community. This episode focuses in on one of those questions. What notable PyPi package have you come across recently?
Not necessarily the most most popular one.
But something that delighted you and people should know about. Our guest, Antonio Andrade put together a GitHub repository cataloging guest response to this question over the past couple of years, so I invited him to come share the packages covered there. We touch on over 40 packages during this episode, so I'm sure you'll learn a few new gems to incorporate into your workflow. This is Talk Python to Me episode 346, recorded November 24, 2021.
Follow me on Twitter.
Where I'm @mkennedy and keep up with the show and listen to past episodes at Talkpython FM and follow the show on Twitter via at Talk Python. We've started streaming most of our episodes live on YouTube, subscribe to our YouTube channel over at 'Talkpython.fm/ YouTube to get notified about upcoming shows and be part of that episode.
This episode is brought to you by Coiled and Toptal. Please check out their products during their segments.
It really helps support the show.
Antonio, welcome to Talk Python to me.
Hey, Michael, thank you for having me.
It's fantastic to have you here. You've done some really cool work to highlight some of the guests and some of the things that they've covered. And so I feel like this is going to be a very meta episode where we reflect back on what has come before and what people have recommended, and we're coming up. It's not quite December yet, but we're coming up on the end of 2021, and so maybe a look back is in order.
Yeah, I think from my point of view, I think it's a way to celebrate the people and celebrate those small packages people are highlighting each of the podcasts. I think it's lovely. I think they deserve to have a place somewhere where everyone can contribute and you can go back to history and remember all these two points to three point and how things have been evolving. It's just amazing, really.
Yeah, I agree. Thank you. People have asked like, hey, is there a way I can see answers to those last couple of questions at the end of the show where I ask people for a notable PyPI package or what editor they're using. And it'd be interesting to see, especially in the editor changing over time stuff like that. But at least on the notable PyPI package, you've put together a really cool GitHub repository highlighting at least going back through 2021. Mostly, I would say what people have covered. So during this episode we're going to dive into and discuss the highlights of the notable packages that the other guests have put out there. So that's going to be great. Yeah. Thank you. That's awesome.
Great. All right.
Before we get into that, though, tell folks how you got into program in Python.
Okay. So try to make it quickly.
I grew up in a really humble family, but we have tons of education and Legos.
So see, the first time I manage to have something I can really call it that was mine and do it was when I entered to the University. I still have it HP, the time was super cool.
Anyway, the point is, I start at the University. I studied electronic engineer. The person who is my wife now she was studying civil engineer.
So they used to use these old Casio calculators, and they used to have a lot of programs running there.
Yeah, they were not computers, but they were almost.
You can download the whole application. And what happened is to calculate a breach building or whatever. They used to use the calculation. So I decided to try to get some love out of this and start translating all these programs from this Casio to this HP helping the other guys in the University. And that helped me a lot to get really deep into. Right. So straight away, start programming in the same University I have done assembly.
Oh, my goodness.
C, C++ the whole thing. Right. So more recently, once I start after graduation, I have tons of experience with other languages like C, Char and recently Python and tons others. I just love this. Really. It's just an amazing way of doing end to end. Whatever you want to do, you can make it super quickly.
Yeah. It's all about empowering people to build things quick.
Yes.
Exactly. Right. Yeah. Fantastic. Well, I can't even imagine programming from the old Casio to the old HPS because they were really interesting to program. They were not super high. Exactly.
But in terms of the for loops and the inputs and the logic. And once you get the stuff, then it's easy to switch between languages. Right. I mean, this has been amazing. And what is funny is the way how I went through Python.
I remember quite clear. I was finishing my master dissertation.
I was doing some deep learning work at the time.
Once I was finishing, one of my colleagues told me Google just released something called TensorFlow.
I went there look at the web page. I couldn't understand the syntax. I was like, what is this? And my colleagues say, no, there's Python TensorFlow. The API is a bit different anyway. So I remember like, two weeks after that, I took a fly from Moscow to Barcelona and on my fly, I installed application to learn Python and the teach. Once I landed, I could do the one to one translation. So after that moment that's it everything back end pushing also front end glueing everything beautiful. Integration. And what I think is the most important is the time you save. That is just amazing if you want to get out an MVP minimum variable product if you want to prove value, I think Python is probably the best way how to do it in a couple of weeks or days, you can get out something out and prove it. It doesn't work. Just fail fast. Don't wait one year to show the value, then you can improve as you go. So it's just amazing.
Yeah. Fantastic. I've been doing a ton of programming lately, rewriting some ecommerce stuff and other things, and yeah, I've been enjoying being deep in the code lately and just appreciate how quick you can move. That's fantastic.
All right.
So are you ready to dive into these things? There's no real format other than just the chronological order that it came out, right. Yeah.
Let's go.
All right. Well, maybe quickly introduce your GitHub repo that you created. That obviously is going to be in the show notes. People. I'm sure you wouldn't mind if other people contributed content back to the repo. Right.
Absolutely.
See, what I'm doing right now is usually I listen the podcast when I'm commuting to work, so I wait to listen everything to understand the context and everything, and then go there and have a branch and do the modification for the new episode. If you guys want to feel free to do a fork at the new episode and contribute straight away, I will be more than happy to get compliments. And if anyone can help me to go back to the years, it's fine. I promise I will put it because most of the tools is automated.
It's all about going back and doing some clean up. Right. So you publish the text, the transcript?
Yeah.
So I'm trying to use a bit of NLP to try to get what's the package.
That's one of the reasons why. Also, I tried to do it right. Try to get it. It's not that right. But if anyone wants to do this cool stuff, why not? Good learning.
Yeah, sure. Actually, the transcripts are all published to GitHub just as text file. So if you want to go out and they don't have to scrape the web or anything, they can literally just fork it and pull them down. Maybe I'll put that in the show notes as well.
Yeah.
So you created this repository and basically for each episode, at least the recent ones you go through and you highlight what was the episode when it was published? It was the guest those kinds of things. But the whole point is to show. Well, what did that guest answer? Those guests? If it's a set of panelists, what are the answer to the notable PyPI package that people should check out?
Exactly.
And then we try to keep a small description on the links for those packages. So great.
Yeah. Let's dive into episode 342 recent one published. We actually recorded some between.
We've recorded them, but not released. Exactly.
So as far as what's on the podcast is concerned, 342 at the time of recording is the most recent one that was GUI talerico, talking about Python architecture and construction.
What did he give a shout out to Pythonics?
I know this is quite famous package. Many people are using it. I didn't know about it. So it's pretty cool. Right. So you want to do an automation for something? Let's say that you have a small Arduino Raspberry. You want to keep something in the house. I don't know if you detect something on your camera, go and turn on the lights or whatever, or if this stock market and these indicators this is happening. Go and sell and buy.
Yeah.
Perfect. It's just amazing. Yeah.
This is really neat. So it's like a graphical designer for running code in a Docker container or on Raspberry Pi.
Yeah. You run it there and then it writes, Does it actually write Python code? I don't know. I haven't tried it.
I haven't tried because I was just listening yesterday. So what I will say that it seems to be visual, you track and drop, seems to be that you drag and drop, mix things and then the whole logic may be there. So we need to explore it. I think this can do pretty cool stuff at home. I don't know. Like Halloween.
Or whatever your Chromecast you're stocking when the kid comes and see what kind of costume it is and pick the right video to play for them. Exactly. Yeah. So Pythonic graphical Python programming for trading and automation. Yeah. I love it. We always need more graphical type of stuff in Python. I think of the places where it could get a little more strength and support and features, building UIs and doing things in a UI oriented way. I'm all for it.
All right.
Yeah. That's an excellent one. Okay.
Yeah. Exactly.
Then the previous one was back. So he was telling us about the, UMAP, uniform manifold approximation and projection. In a nutshell is whatever. We have so much data in so many dimensions. Usually I work with real time, multi dimensional, realtime data and whatever you need to analyze it, whatever you need to understand how they cluster together. This is beautiful.
Just load your data set, run it, and then you can have dimensional reduction on the data set and you can plot it and you can see things you were not able to see before on the data. Also plotting. You don't need to plot whatever millions of records. You will just do the dimension reduction and then it's easy to understand a bit more about the data on the data science. I didn't know about this one either.
Yeah, I didn't know about this one either. This looks fantastic. Uniform manifold approximations and projections.
Yeah.
This is not a world that I actually get a chance to spend a whole lot of time in. But, yeah, it sounds to me like a little bit of the world that you're working in, though.
This is the thing that's relevant, right?
Exactly. Yes.
Yeah. Cool. So you get all these nice visualizations of the data, like how it's grouped and a lot of nice visual aspects, like color plus.
Exactly.
So basically, you can get clusters out of your data from out of there, then it's when you start working with the data.
Right.
So I don't know. You want to detect something out of a lot of noise, so you can really separate noise from the data, for example, or if you want to classify a bunch of text, or you want to do something different and find other ways. How to see this in a smaller data sets in 2D data sets. That's the way. It's just amazing.
Yeah. Very cool. And of course, this is a recommendation from Becks.
He's all into Kaggle and Kaggle competitions. He talks about 25 pandas functions you didn't know existed with probability .8 which I thought was a nice title. Really good title was really good.
Yeah.
So this is a perfect follow on to like, you've got this data on a data frame, and let's try to understand it a little bit, right.
This portion of Talk Python to me is brought to you by Coiled. You already love using Python to build your data science projects, but training models and working with tons of data on your laptop is limiting, to say the least. But that does not mean you need to learn new cloud APIs or buy expensive and hard to acquire hardware. Just use Coiled IO Coil supercharges the tools you already use for scale and performance, so you can use Python for your ambitious problems. In the words of Eric Ma, principal data scientist at Moderna, quote, quite literally burst into the cloud from your laptop. Everything I've been dreaming of since grad school with Coiled, you really can burst into the cloud with a few clicks and stay focused on solving the important problems. Adding Coiled to your project takes less than 1 minute. So what are you waiting for? Get started today? Just visit Talkpython.fm/coiled or click the link in your podcast player shownups.
Number 340. This was Anthony Shaw.
Anthony, we love you, man.
Yeah, man.
Thank you so much for everything. What you guys are doing, it's just amazing.
Yeah. He's doing tons of good work. So what did he talk about?
Great.
So he told us about this package. Three packages. So the first one was Tortoise ORM.
This one is an  Async IO RM.
I try.
The API is really simple and clean, and this is what stand out from the rest of the ORM's, which are currently starting to support Async IO. So it is a good try. Okay.
Yeah, I think so too. It's certainly simple to use, right? If you view Django ORM or if you use SQL Alchemy, it should feel really natural to that exactly. And then whenever you do the work, I guess it's worth pointing out. This looks like an active record design pattern where you operate directly on the documents, as opposed to a unit of work, which is SQL Alchemy, where you create a session, do a bunch of stuff and then save it. So you would go like if you created a tournament object, you could just say tournament save, but because it's async first you say, await tournament save you want to create when you say await tournament create and you pass the data or same thing for the queries and so on. So if you're using any framework like Fast API or Court to make Flask Async or anything, that's basically async first. Right.
Async is almost entirely about scaling the time. You wait, not trying to do stuff in parallel in Python for the moment, at least in databases are where we wait. Right. We wait all day. That's like what a lot of apps just do.
Exactly. I'm more in that example. You know, it's using SQL Lite.
So here you go. Simple, clean, beautiful API ready to go.
It's just pretty neat. Yeah.
Awesome. So Anthony wasn't content to suggest just one.
Let's dive into the next two, but let's just probably quickly on top of this. Why not to use the same idea and apply this for MongoDB? Here you go. Absolutely simple.
I'm not sure how to pronounce Beanie.
Yeah, I think beanie.
Yeah. So that's something I will suggest to the people who are the owners of the repositories tried to put how they want us to.
How about this? A little play button just next to the name where you just hit play. And it's the leader of the project saying the name. I think that would be great because sometimes it's clear, but sometimes it's not clear what part should be an acronym and what part should be tried to say out, like, theoretically, this could be Beanie.
It's not it's Beanie, I believe. But you don't know that all the time if I look at it. Right. So I have another playlist. Yes, I'm off for this. I often criticize places saying if you are anything to do with graphs, UI, whatever, you should have a picture on your site because a lot of them don't. And I think this is another good suggestion. Let's have some.
Yeah, the pictures. Guys, put something, please. It makes so visual. And if you don't have the small logo, I don't know. Maybe a small screenshot of animation of how it works. It helps a lot.
Exactly.
Tony out in the audience. I agree regarding the pronunciation. All right. We already got three votes for this idea. I do think it helps that the icon is a hat like the Beanie hat. So I think that's going to help.
So there will be a challenge for GitHub team. Let's see how quickly they can release such a small enhancement. Let's give it a try. Yeah.
So Beanie is an ODM like an ORM, but when you don't have relations and you have documents, you change the R to a D. It's an Asynchronous Python ODM for MongoDB based on motor, which is MongoDB async Python library and Pydantic. So if you want to talk to MongoDB using Async and await and you want your things, you exchange with it to be Pydantic models. All that sounds great to me.
Beautiful.
Yeah. So it looks really cool. I'm using MongoDB, of course, for talk Python and talk Python training all those things. And I'm using Mongo engine. I would certainly consider using this for it, but I'd already created it five years before it existed. So that's one of the problems. Right.
Exactly. But for someone who is starting Anthony is recommending it for a reason. So I will go and take a look at that.
Yeah. And just sort of foreshadowing in a couple of episodes, I'm going to have Roman Wright, the creator of Beanie on here to talk about Beanie, so we'll dive more into it in a future episode. Yeah. So we'll get into the details. All right.
Exactly.
The last one. So it's pretty good.
Basically SQL of the host scanner. So I'm dictionary attack tool so you can pass a filter of series of passwords and lend and give it a try. Allow it to find vulnerabilities. It's just amazing. These type of tools. You can imagine how useful are in the Enterprise, a ton of them running every single day, every single seconds. Try to hide hundreds of databases.
Hundreds of them set up and who knows who set them up. And if they configured them correctly, it'll just hammer away for known usernames and passwords and defaults and all kinds of stuff. Right. And then list out the ones that it finds, which is good.
Great.
Yeah. Very good. Okay. So that was the three from Anthony shaw. Thank you, Anthony. And then we had the Gido and Mark to talk about time performance.
I'm guessing I'm not sure Gido will really and Mark will suggest any package, but I really love seeing both men joining and sharing the job they're doing. I think it's amazing.
I have a question for them. And also Anthony, how what they are doing.
You will work altogether.
Times will say.
But what Mark, Shannon and Guido are working on is different than Pyjion. And what Anthony is working on, which is different than Sam Gross's work on Cinder and so on. Not Cinder on the no Gill. Sorry. Cinder is done by Dino villain. So there's just all these projects of people doing stuff. It'd be great if they could find some common ground to amplify that.
Exactly. You know, whatever they can do is really welcome and show the community will appreciate it. And each of them have a different use cases and they will hit a limit. So let's see whatever support they need communities here. We need to help.
Yeah, right on. All right. Next, back in Middle October, we had Episode 338 using CI Build wheel to manage the Scikit Hep packages. And I learned a bunch of stuff about just how to properly build Python packages from Henry Shiner, the guest there. That was a lot of fun. What was the thing he recommended? Right.
So plotext guys, if you love CLI like I do go and do everything there on your console, period.
You want to plot time series, you want to plot your stock market, you want the price and you want to do extra things. That's the tool. I didn't know. It's so crazy. So good.
Yeah. 100% Python. And basically it plots directly to your terminal. So if you wanted to do something like map plot Lib, even the syntax it says is similar. If you want like a bar graph or some distribution curves or even a picture, it will literally put that in the terminal.
This is awesome. Do you have some kind of use for this with the projects that you're doing? Where data? Yeah.
Usually even when you're logging things. If you want to do full debugging of something and you want to understand what is going on and you want to show it right there.
This is beautiful. You can understand. I don't know some data, so you don't need to really get out of your application and go to a notebook and play there. You can enable that flag for your debugger and straight away right there. It's just amazing. Really?
Yeah. Over on Python Bytes, we spoke about this thing called here's another one where we need the pronunciation JUT and what it does is this one will let you take the output of basically take a Jupyter notebook and let you put that into basically view the notebook in the terminal, which is pretty awesome.
So this one is like. But you don't really get the graphs and stuff of that, right?
Yes. Exactly.
The cells. Yes, that's good. Yeah, but this one gives you the plot right there.
I wonder, since the syntax is really similar to mat plotlib, I wonder if there could be some add on to you that says if you see a map plot Lib, stub it out with plot text. That'd be awesome.
Time to try.
Time to try. Yes, indeed. Alright, well, thank you for that, Henry. And then we had a panel of Waylon Walker, Yatunta, Dada and Ivan Danov talking about Kedro, which is one of these frameworks for managing data science, almost like pipeline, but a little bit larger than that. Do you do anything like that? Like Kedro or Luigi or Airflow or any of those things?
Not really on job wise, but personal use. Yes, we will go through that one down there. But what is interesting is the two packages they recommended. So one the first one was the FSSpec.
Here's another one that could be fisc.
Okay, here you go.
I think it's file system spec. Yeah.
This is the thing. When you listen to the Postcast, I was like, okay, so I needed to come here and read it like, two times to try to get exactly what is aiming from this one is quite valuable leverage.
Treat all the files. It doesn't matter if it's in your desktop, on the cloud or whatever location. Have a simple API to go and handle the files. It's just amazing.
I work a lot of the pandas data frame, for example, even when it's not data related data science related.
I used to get the help of all the C underline the pandas and the NumPy. If I want to do a high SQL equity, I use Pandas.
I usually don't go through the ORM, and the reason is the speed you go and check and you can do the inserts. You can do things through the pandas pretty quickly.
And these things are all in the back end helping to do that just amazing. Yeah.
It's super cool. If you want to write the file sources that are not actually file sources, then this is a really, really good one for that.
Yeah. So people could look through the docs, but also out there. Let's see. I was hoping somewhere there's, like, a list of all the different things the files they support.
Exactly.
Yeah. But there's things like databases, all those kind of things.
Anything to behave like a file, a simple API that handles everything, whatever has to do with data.
They will do it so simple.
With open syntax, right?
Yeah. Here's a little example of, like, FS spec. Open some URL to some place, give the S3 or whatever, and then you just use it as a file, like as a file object, which is great. And then obviously this one was from that episode with William Walker, who happens to be the audience. Hey, William Wayland.
Sorry.
It says yes. Fs spec does not get enough love. Yes.
Makes it exactly. That's the reason of this repository. We need to keep it there. People should take a look that's it simple.
Yeah. And that's why I started asking that question. Like, all right. I know there's things like this that I've never heard of that I should be hearing of. And then the other one was Dynaconf. And I think we got the FS spec because Dynaconf used it potentially. I believe so.
This one really. I didn't know this.
That's the beauty of Python. There is one library, one package force to do everything. Right.
So this one is an easy way how to do setting loaders.
It doesn't matter if you have a PY Ini JSON other formats, you will handle it, period. Forget about what is out there. Super easy to use. Yes.
And it has support for environments like development versus testing versus production.
The file for the secrets, the file for the settings for the secrets and the settings and the number of settings.
Well signed plugins for Django and Flask talks to HashiCorp Vault for some of the secrets and so on. Yes, this is quite neat and it makes good use of emoji in its output, so I always appreciate a good emoji.
Me too.
I know it's so small, but it just makes me smile when there's a little color, a little pizzazz. So yeah, really good.
This portion of Talk Python to Me is brought to you by Toptal. Are you looking to hire a developer to work on your latest project? Do you need some help with rounding out that app? You just can't seem to get finished. Maybe you're even looking to do a little consulting work of your own. You should give Toptal a try. You may know that we have mobile apps for our courses over at Talk Python on iOS and Android actually used Toptal to hire a solid developer at a fair rate to help create those mobile apps. It was a great experience and I can totally recommend working with them. I met with a specialist who helped figure out my goals and technical skills that were required for the project. Then they did all the work to find just the right person. I had short interviews with two folks. I hired the second one and we released our apps just two months later. If you'd like to do something similar, please visit Talk Python.fm/Toptal and click that Hire Toptal button.
It really helps support the show.
And that takes us onto something that has been getting a ton of attention lately. Is Will McGuigan's work Episode 333 Terminal Magic with Rich and textual rich and textual. Yeah.
Thank you guys.
It's just a piece of great work they have done during the podcast they mentioned about this objexplorer, so quite cool your object and just exploded if you feel like you were in your ID simple numbers.
Yeah. So what I used to do is I would like type print dir of object DIR parenthesis object, and it'll show you basically the dictionary of functions and fields and just all the attributes and whatnot this is way better. Like, imagine something like I don't know if this is actually using Rich. Let me look real quick here. Yes, this is based itself upon Rich. So imagine Rich was used to build like a beautiful UI that you could list out stuff you could search through and arrow through and select things. And yeah, this is fantastic. Right.
And that will be the reason why we have the textual. The other one they were talking about is the same. Right. So using both Rich and textual, you can do these type of things. Yeah.
Rich lets you write really awesome stuff to the terminal, like progress bars and tables and colored syntax highlighted JSON and whatnot and then textual kind of allows you to lay out different parts of the screen so you can have, like, a thing docked to the left and then fill the rest of the terminal with the output as you select the thing on the left. Yeah. Perfect. That's kind of what this is for D-I-R. But way better.
I love it. Exactly.
Awesome. All right.
So on to all the way back to middle of September with Episode 335 Gene editing with Python. And our guest here was David Bourne, and he talked about one that I hadn't heard of, but I'm sure some people could definitely use in the DevOps space.
So AWS, and also the rest of the cloud providers, Google and everyone else. They have such a beautiful APIs to integrate with their systems. And this is one of them, right.
So many things you can do with.
That's it.
I really love the way how all these cloud providers are enabling all these APIs to do absolutely everything.
Yeah. You hear one of the things that makes cloud computing special, like, there used to be the joke. Let me see if I can find that cloud computing is just, like, just someone else's server or something like that. Right. There was that joke. And, oh, man, I'm not finding on the quick search here, but there was a joke that, you know what? It's a cloud. It really is just someone else's server. But one of the real big differences is that you can program against this thing. Like, I remember way back when we were doing some ecommerce stuff and some software stuff, we went to Rackspace and we requested that they provision a server. And, like, several days later, a human had said, yes, Michael, here's your server we made for you. And that was great back then. But with the cloud, it's all about programming against the infrastructure, like, infrastructure as code type of thing. And this cloud development kit that David suggested was all about. Well, here's the Python API to program. Aws, basically right.
Mind blowing.
If you see the implementation, the impact on the enterprise, these type of APIs and the ability to do it through Python, just neat.
Yeah. It's super cool. It's not a thing that I do very much. I do have some APIs that work against our servers for, like, if everything goes right, zero downtime deployment on, like, get push type of things. But not to the degree that the cloud development kit won't do right. You could do way more stuff than what I got going on.
All right.
And then David also suggested Luigi.
Luigi. Okay.
When I listen to this name, Luigi, remember, my wife's family is Italian.
See what this does? It does everything right. It's the biggest baggage, right? It's workflow management tasks, scheduling, dependency resolution. Everything in one place even has a visualizer for all of it.
Like, the dependency graphs and whatnot right.
And this is really good, because, like, Dask style, you can do the whole you define functions, how your workflow will work. And as things are completing, you reach to the end to the completion. They can be quite isolated. They can be near to you far away in the cloud or another providers. And then you can reach your end goal and know when things fail or when things are completed.
I mean application, just awareness to where this particular job is making it through, because you can see what parts finished, what part is still working? What's waiting on? What exactly?
You know, who wants to do again? Home automation, who wants to do enterprise completing your workflows? Here you go. And then you have a pretty nice user interface web interface.
You have only one stop. That's it.
Yeah. And for people out there who are all about Python, which is the audience. Basically everything in movie is Python instead of XML configuration or similar external files like think YAML JSON whatever the dependency graph is specified within Python, which is pretty cool, right?
Yeah.
And I think this one came out of Spotify.
Yes. Exactly.
This is something I really love from the Touch companies.
Their management have understood that they can work together with the open source community.
We help them back to my position as an enterprise.
I can use it. Right. So it's just really a call from every single company have something that can be open source. Go ahead and do it. You are going to get so much out of it.
Yeah.
Worst case, nobody cares. Best case you find other people who are passionate about this thing that you build and then they'll help you improve it without any effort from you. Right.
For a company to have other people help.
Exactly. They find the box for you. They help you with the communication. It's a winwin situation.
Yeah. Exactly. There's so many of these things that companies have to build, not because it's their core value proposition. It's just that we need a thing to schedule some stuff. So we figured that out. But it's not what makes Spotify special, right. So they don't need to hide and protect it. Right. Put it out there. Great. Alright. Next episode going back to September 9. I guess we talked about the Microsoft Planetary computer, which is basically cloud computing for people researching climate change and similar geospatial stuff. That was Rob Emanuel and Tom Augsberger.
Yeah. Rob and Tom, thank you for sharing. I think we need so much of this in those days.
I think it's well deserved this type of contribution.
If any big company can just go ahead. Don't wait.
Yeah, absolutely. So the thing that they recommended, I can't remember. I think it was Tom, but I'm not 100% sure it was Seaborn, which also I saw back when we were talking about the one that Becks recommended, which was is the, UMAP, one that also had a bunch of examples in Seaborn.
Usually in the data science world, Seabourn is reused you can do everything with map block. I don't like how it looks like. I know many people will come back to me and say, no, you haven't tried XY on set. I know.
But out of the shelf, that's it.
Seaborn, look how incredible this joint plot looks like if people go to the Gallery and just kind of scroll through this hexagonal joint plot, some of these not just showing you the data, but it's like, wow, that's publication level beauty right there. Right.
Really nice, really simple. I mean, you get the same that you get out of Mat plot, but we'll say it's like a comparing the old Android with the Apple with the iphone. I'm Android guy. Right, guys. Windows guy as well.
Myself. I use Linux through my Windows for subsistence anyway, but that's a big completion. You can do things pretty good in mat plot, but there's so many things out there which out of the shelf. It looks beautiful. It also has a nice API.
Easy to use. One stop for visualizations.
Yeah, absolutely. Tony in the audience says Seaborn is great. So another vote for that as well. All right.
Back to the perfect threes. Episode 333. I thought this was a really fun episode. The state of data science in 2021 was Stan Seabert from Anaconda.
The NumPy and spicy on GPU. I think it's a great achievement for so many things. We use day to day. I mean, every time you guys are talking to your phones and even when you are not doing anything, the camera is watching you. The whole thing. There is so much happening out there, thanks to the use of the EPS at the time.
Still use allowed to get that array and process through EPU is pretty good. And the beauty of this CuPy is that it's used for so many others that help everything to go next.
Yeah. CuPy So it comes from CUDA and Python. So I'm guessing CuPyi is NumPy Scipy compatible array library for GPU accelerated computing with Python. There's a lot of qualifiers there, but that basically means if you're doing stuff with NumPy, you can throw this at it instead of happening on your CPU. It'll happen on CUDA cores on, say, your Nvidia 30 80, which is an insane amount of computation.
Yeah.
Very cool. Do you guys use GPUs for anything?
Yes. In the industry, mostly it's used for the seismic processing the size of images. That's usually where Linux is in the energy industry.
You have to do all these 3D graphics, all these processing, all these survey data, that all this may be used. Okay.
Yeah. Fantastic. I would love to see things come along that are a little more interchangeable. Like, the CUDA stuff is fantastic. But CUDA is just Nvidia, and we've got AMD with Radeon. We've got the new laptop, got like 16 neural cores or something like that. I can't remember exactly. But we all are getting these systems laying around, and it's very hard to get a hold of the Gforce GPU, so I'd love to see whatever GPU you want to bring or neural engine you want to bring, but I totally understand that that doesn't always work so easily.
All right.
The next episode is a very popular one of the most popular ones we've had recently called Robust Python with Patrick.
He talked about Stevedore managing dynamic plugins for Python apps.
See, when I was listening in this podcast, I was regretting so much time. I wasted my life working on my plugins. This is just so simple that's it and at run time, forget about doing import and your new file and the whole thing and need to go on. No, stop doing this, guys. There is a solution. That's the one.
Yeah. Cool. So basically, if you want to build a plug in system for your code for your app and makes things interchangeable and whatnot Steve door looks really good for that very nice. Back to August Summertime episode 331 with Lucaslinga Lucas.
Thank you so much to everyone. Right. But also to you. I use Black so much. Know, I that all the things you are going on today.
You didn't mention Black, but we decided to add it here in compromising code formatter.
It helps so much with people's relationship. I guess more than beautiful Python. No more fighting. That's it. You just get agreement. Everyone use black. That's a setting by default. Yeah.
It's one of the things where you can just take that whole debate and conversation out of different people's hands. It's not who is the most unmovable in the team or loudest in the team or whatever.
We're just going to agree. The community said Black is close enough. Maybe no one's going to be 100% happy with how things format, but it's just going to happen automatically. And we're not going to worry about code formatting anymore.
And I think that's fantastic.
I will change the name, the description, the uncompromising code for matter by the frictionless frictionless code format. It's just beautiful. Yeah.
And you have people using different tools, some people using PyCharm, some people using Vs code, some people using Emacs or whatever. And if you say, clean up this code what that means to those different systems, especially because you can customize every little detail.
Right.
Like, I want a space here, but not a space there. Those all become merge, not necessarily conflicts, but changes just because somebody cleaned up the code. But there's not a meaningful change on that line. So doing something like Black in a pre commit hook means you're not going to get those little weird changes just because the tooling decided to have a different change Department.
Yeah. Douglas, out in the audience says thumbs up to Black right on.
Exactly.
You started to see it be brought into other things as well. Like, it just got integrated into Jupyter notebooks, I believe.
No, I always get this wrong. It now has support to point it at a Jupyter notebook and have it format. That so very cool.
Okay, that's the way.
Hope I'm pretty sure I may have reversed it twice in my mind, but I think that's how the PR suggested that it's going to work. Okay, so episode 333 this was a fun one. A group of Yarik, Caxel and Leah talking about Apache Airflow, which is another one of these workflow pipeline things in Python.
Did I actually get a chance to ask them a question? This one out of time?
No, that's the reason why sometimes when I managed to get it because my time sound with you guys when I'm there and you're getting to the end, I usually try to get that small coming on the chat of YouTube just to remind people don't miss equation. It's quite important. It was miss here. But anyway, a missing library. Again for data pipelines you have.
Yeah, Apache Air flow looks really nice.
You can do your scheduling and monitor.
I think it's pretty similar to how we described Luigi.
I think there's a lot of similar data focus.
Why use a lot on the data science?
Yeah, absolutely. It has all these integrations, which is nice, right? Like if you want to plug into other data sources, you don't have to necessarily program against. It means grab one of those integrations and run. All right. Episode 329 I had my friend Richard Campbell back on there. We talked about renewable energy. He's always fun to dive into the geek out episodes, but given the topic we were covering, it didn't really make sense to have a question. And we were exactly anyway. Exactly. Thanks, Richard, but no question. Maybe I'll get one from you next time we do something like that.
Talk Python to me is partially supported by our training courses. We have a new course over at Talk Python HTMX plus flask modern Python Web apps hold the JavaScript HTMX is one of the hottest properties in web development today, and for good reason, you might even remember all the stuff we talked about with Carson Gross back on Episode 321 HTMX, along with the libraries and techniques we introduced in our new course, will have you writing the best Python web apps you've ever written. Clean, fast and interactive, all without that front end overhead. If you're a Python web developer that has wanted to build more dynamic interactive apps, but don't want to or can't write a significant portion of your app enrich front end JavaScript frameworks, you'll absolutely love HTMX.
Check it out over at 'TalkPython.fm/HTMX', or just click the link in your podcast player show Notes.
Episode 328 Piccolo another O-R-M. And also one of the Async ones, which is fun, but package. This is Daniel Talent. The package was not Piccolo. That was the topic.
The package is Pydantic. Okay, amazing.
This is one of these really good packages out there data validation.
That's it.
Yeah.
I don't know if it doesn't get enough love or not, but it deserves a lot of love. Let's say that. So it does really beautiful importing and transformation of data. So if you're receiving data from a file or if maybe you're receiving it from an API and the data is not super cleaned up, this thing will do its best to one either automatically clean it up or two. It will tell you precisely what's wrong with it. So, like, suppose you're getting a JSON document back and it has a list of things. And the third thing in the list is not parsible as a date time or something crazy like that. It'll tell you the third thing in the list couldn't be converted to a date time rather than exception in valid format. Right. It's beautiful. Right. So that's one of the things that's lovely. The other thing is it uses type annotations in really meaningful ways. So if you have, like, the example on the website says here's a user with an ID:int that means there's no specified default in the data provided must provide an Int because it's not an optional end. It must provide an ID. There's a name which is equal to John Doe, so you don't have to provide one. There's a default. And because the default is a string name as a string. But there's a sign up that may or may not have a value. So it's an optional date time, and all those things factor into the transformation and the parsing. And whatnot right.
Yeah.
Super nice. And the other thing is that it works with Fast API to define the Open API, the Swagger stuff. So for example, I was like I created a Fast API over at Weather.Talk Python.FM because I had been using some other weather API for a course. And of course they changed. They used to be free, and now they're not free. And so I'm like, Well, if I got to rewrite this course, I'm not going to depend on somebody else's API again. So it'll answer questions like, what is the weather wherever. Right. But you can also go to Docs. Yeah. Just go to Slashdocs and you get like, oh, here's all the data will be exchanged. And here it's going to return the forecast, which has a wind, which has a speed, which is a number and an integer. And all this is automatic from Pydantic being plugged into Fast API. It's beautiful.
It's just amazing.
That's the thing. That's how you glue these libraries, these packages together. What makes the magic? Some of them are really beautiful by itself. When you start using all together, and then you put on top whatever rich if you want to have a beautiful output on the CLI or whatever.
Absolutely brilliant out in the audience says Pydantic is one of those packages that makes my work successful without Flare.
Exactly.
It just makes it easier. We're just going to do that.
All right.
All right. Let's see how we do on time. We got time for a couple more.
There a couple of more we weren't able to finish all, but you guys are getting what we're trying to do here.
Yeah, we're on July now. I think I'm going to predict we can make it to May and then we're going to run out of time. But this episode was really cool. I thought also episode 327, Little Automation Tools, because I think it speaks to so many people who are not necessarily. Oh, I'm like chief senior software architect at Instagram or whatever. Everyone can use these. We had Rivers Cuomo from Weezer, we had J. Miller, we had Kim Van Wick and Rusty Gregory on in the panelists here, and that was super fun.
Amazing. So they introduced PipX.
Have you tried? I didn't try.
I use PipX all the time.
I use version management, but it's so simple. They have this small gif on their GitHub repository.
Go install it and then just do everything against the.
Yes, I heard about PipX when it first came out, and that was Chad Smith, I believe, was told me about it, and it was just an individual project. And now it's part of PyPA, which is the Python packaging authority. So it's become sort of official and people use Homebrew for Mac OS. They use app for Ubuntu and Chocolatey for Windows and that installs all sorts of tools. But if you want something like I need to install a tool that I could run, and it just happens to be based on Python. Well, then Pipx is that equivalent, right. Because there's a lot of programs and tools out there that are awesome that you want from Python, for example, like Black, I want to run Black against a thing, but my program doesn't depend on it, so it doesn't necessarily need to be installed in that virtual environment, but instead I just need it on my system. Right?
Exactly. So go install it and run that application in your isolate environment. Just beautiful. Super smart.
Yeah. Wayland says I use PipX for so many things. Ansible playbooks Kedro, install many personal repos.
One that I use it for is glances, among other things. I'll show you some stuff that can also be used for. That's not as interesting. So this is a fantastic tool. Like if you ever use top to figure out what's going on in your server, the way you spell Top is G-L-A-N-C-E-S glances. That's what you should type. It is so much better, but it's a Python library. So Pipx install glances and it gets its own environment with its own dependencies in there, and it doesn't mess up. Also, there's recently Tiptop, which I believe is also based on Rich.
But if you check this one out, this one also looks like a really interesting one where it's like glances. It gives you a terminal UI about your server, but this one has running graphs. So running graphs of the CPU across the cores, by the way. Like if you got a four core hyper thread core machine, it'll give you eight graphs and then, like, graphs of memory network graphs, plus your process stuff. So all of these things are perfect candidates for installing with Pipx.
Exactly.
But another one is Pyjokes.
If you just need some jokes, you can just pip X, install Pyjokes, and then just type Pyjoke anytime you want, and you get something great to come out.
Yeah, I have tried that there.
Yeah, that's a good one. Anyway. PipX is a very good one.
All right.
So I don't remember who on there recommended that one, but that was a really good one.
All right.
Let's see. We had Mike Driscoll on to talk about building desktop apps with Dev, ex Python. And of course, he does a lot of stuff integrating with things like Excel and with PDFs and stuff. So what was the one he recommended?
So open py Excel. So you need to work with Excel. Pretty nice API.
I usually do it straight away with Pandas.
I make it even simpler for those.
Pandas internally might use OpenpyXL as well.
Exactly.
I didn't check, but most probably.
So go and read and write Excel. You go and select your ranges. What is your book inside the spreadsheet and super neat. Then go read it, put it in the table, do your loops, do your calculations, and then process your data simply.
Yeah, absolutely. And I think you could even do formulas and formatting and other stuff through here.
Yeah. With, like, Pandas, you can put data out pretty easy and stuff. But if you want to say like, I want this one bold stuff like that. I think this is more the level you got to work at, which is cool. All right. Micropython and stricket Python. I don't know if this is a joint episode or a battle. Actually, it turned out to be kind of a joint episode. I talked to Scott and Damien specifically because they had done a ton of work where Circuit, Python and MicroPython had merged. A lot of the differences that they had been working on together back into like, a more uniform code base. So they talked about HttpPy.
I'm going to guess on that name there.
Exactly.
So that one is the Python base for easy request. Okay.
Day to day. I spend 99% of my time on Windows. Sometimes. I don't know, due to my Enterprise policies, I can AC Car. So this is an easy way how to how to achieve that. If you need to do a duplicate command, you're on Windows, for example. That's the way super simple.
Yeah, that's cool. It's based on Python. And one of the things I think is neat about it is it has a specification file. So instead of putting -D.
Here's a key value thing. I want to pass D, here's another and here's the URL and so on. You just create one of these configuration files and then you say make the request that's stored in that file and off it goes. Right.
Exactly.
That's neat. Yeah, that's really neat. Why we're on that another one that I like. I'm not sure I could phonetically distinguish it is http IE pronounced, I believe, HTTPI as well. This one is super neat as well. And one of the things that I really like about it is this the same thing.
Let's go to GitHub, but certainly the Python project. I'll go like this. I'll search for it over here. This is also kind of like Curl, but what's really cool about it is when you make requests, you just type Https or Https and you give it a URL and it'll print out like the headers and the cookies that it got back colorized in your terminal. It'll do pretty printing a JSON and code formatting, even like code highlighting of your HTML that might come back.
Yeah, it's so good.
If you think Curl or Wget like, put it down, go to httpi. And the one I'm recommending is HTTPie, not Httpy, which is also good and it has it. I really love this sort of configuration file as well. So I see super value in both of them.
Neat. Very good recommendation.
Let's see Gatorade powered Python API.
This is such an interesting one because Rob Sandra, they worked on this project called the GX Sweat Patch from Gatorade, which is like a thing you put on your arm and then you work out and then you analyze it with Python. It's incredible.
Really nice.
So coming back around, he suggested Rich Rich.
Here you go. So one of the I think probably favorites of 2021. Yeah.
Really amazing library.
I really love just to go from reaching Port print and that's it.
You get straight away at different Phil and look working with the CLI.
Yeah. Absolutely.
All right. Let's see.
I'm going to say we have time for one more. It's probably time to wrap it up.
So how far we made it to the middle of June 2021.
This is what?
Yeah, not bad. This is Itamar. Turner Trowering.
I had him on to talk about best practices for Docker and production, and I think in quotes for Python developers, and that was fun. And he talked about a lot of things, but his package was PyO3. Tell us about  No PyO3
Hold on.
Alright.
There we go. Rust binding for the Python interpreter. What do we got going on here.
For this one?
If using Python from Rust, I remember one time I was looking at some source code where they were in C Char, embedding assembly or embedding another programming language and running that on site and doing the whole thing similar I didn't know at this moment. It's obvious, right? But I didn't realize that you can do this binding for Python, so I don't know. I haven't used Rust, but I'm guessing they supposed to be most probably one of these type of rappers in biding for so many other languages I'm not aware of.
I haven't really used Rest either. But if I had to go back to a low level language like C, I would prefer to not go back to C, which I used to do. I would rather go to something like Rust, like a modern C level language, I guess is probably the way.
Yeah.
So PyO3 will let you write a native Python module in Rust. So if you need to make a certain part of your Python code, go really fast and be more native. I guess that's an option. Or in reverse, you can embed Python into a Rust binary. And I guess from there run Python code within your Rust app.
So for everyone out there, once you listen to the podcast, if you know about similar library to bindings for other languages, just please share it.
So nice.
It makes things so good. We need to start now. Probably just jumping and grabbing up because of the time, I guess. Right.
That's right. There are so many more good ones.
Rich, again, fast, API, Flash, SQL, Alchemy, and on and on and on.
Exactly. Wow. So, guys, it's there. Just go and take a look. I promise. Now, in December, I will take some leave. I will take two or three days to go back to the previous years and try to put everything out there. Please take a look at this one. Please contribute. If you see something wrong, go ahead. Super. Welcome to see if contributions there. Yeah.
Thank you. That's awesome. Yeah. People can definitely add to the work that you put here. This is great. Thank you for doing that. That's really neat. Now, of course, before you get out of here, you've got to face the two questions right.
There you go.
If you're going to write some Python code these days.
Okay. Editor are you using day to day is VS code.
However, I found super easy to use Google Collab, so I'm kind of divided, right? So I don't need to sometimes just get into this code to do VS code something small and check and plot is not usable now. So I'm divided right? So when I'm working with projects small or large, straight away through VS code love, the integration with GitHub with containers, everything, everything in a single user interface, and we don't have to do a small web scraping or do a small data manipulation or whatever. I straight away. Go to the Google Collab notebooks and do it right there. I have a link. I can share it with colleagues or friends, and it makes my life quite easy.
All the online notebooks world.
There's so many, all of them. Absolutely.
All of them so many. Are you familiar with the dot command on both vs?
It's just amazing you're on GitHub repos.
And you just literally press code Dev basically.
Exactly if they managed to do this.
So if they managed to do this, I'm sure there will be this small enhancement or the pronunciation of the packages won't be a big deal on GitHub, I guess.
But this one is just amazing. Press dots and open your bills code, right. With all your settings.
Absolutely.
I try to not be logged into the browser I'm sharing on the stream. I don't want it to influence whatever shows up.
Oh yeah.
And then notable PyPI package. Let's put something onto your repo from you about the repo.
That'd be very good presently.
My daughter. She wants to be YouTuber when she grow up. She's still too young. But anyway, I wanted to help her and do some optimization from creating the videos all the way to posting this to YouTube, and it takes time for editing and everything. So I wanted to get some help. So I was trying to see if there was any way using NLP to get a summary of any big web page. I don't know. You want to do a small video, you want to do small research, that's it. Or you want to digest some news. So you install this library called Sumi S-U-M-I.
You basically put the URL of the web page of the PDF. Want to summarize how many paragraphs, how many lines you want to get out of this and 95 98% of the job is amazing. I will say 100% of the time.
It's really good.
Simple library and command line utility for extracting summary from HTML pages in plain text, for example.
Right. So you go to your transcript of the podcast and you say, okay, give me the most relevant 50 lines out of the transcript of Talk Python to Me podcast, and that's it. You can print it out and get in a quick way and extract some useful information.
And the next one is related to the same.
Right.
So I think this is not using the official way. I hope they don't get penalized for me.
So it's called GTTS Google Text to speech. Okay.
Yeah. Google Text speech.
Okay.
This one is again the interface with the Google Translate API, and then you get the MP3. So something I was using these two together. Right. So go get the summary. Okay. Obviously summary will help you to get the context. You would like to do the proper referencing and citation and everything. And then for each paragraph, you can get the MP3 and put this on top of the video and then go back and having tools like these workflows tools like Luigi kick everything and then upload it to YouTube in one. Go fully automated. It's just beautiful. You know how everything can be done. Everything can be glued together anyway. For those out there who want to try these two are pretty neat.
Yeah, that is really cool. Awesome. That sounds like a lot of fun stuff to play with. I love the automation. I love the summarizing.
I really like that one. That's great. So cool. Good recommendations on both of these. And we now have a new thing to put into that GitHub repo.
That's good.
All right. Well, Tonya, thank you so much for being here. The final call to action. People want to check out this project you've created. What do they do?
Please just click down there on the podcast to the link go to obviously.
I'll link to that.
It's the main tribute.
If you like it, don't forget to give us a start. Contribute. If you see anything wrong, please welcome. Suggestions are welcome. And if I miss anything, any of the packages for those who are in the podcast also as well, just go through and give us a bit of contribution there. So I promised to finalize all of them from episode number one by the end of this year. And after that, we'll try to do few cool stuff there so data could be retrieved as a JSON. Try to make it more accessible for the people.
Yeah.
And next, probably we can do how over the time. If we can record which was the notable favorite editor and the Times and see how things change over the time. Have a really nice graph of how these codes start coming up.
And as well, there's a lot of ways to gather all this up and turn it into computer legible data and do all sorts of fun stuff.
Exactly.
Second one production is everyone celebrating Thanksgiving for those who are still alive listening the live streaming wish you a really beautiful holiday for those listening to podcasts. I hope you really have a good time with some friends. If you want to freak me out. As usual, I'm on Twitter. I try to be nice on Twitter.
I used to put everything on linking most of my technical parts there, but anyway, I'm unreachable if we didn't have time to talk about IIoT. If there is anyone out there who have pretty cool applications, hardware where you can go and deploy containers all the way to the edge, I will be super interested to hear from those individuals and companies and packages and everything out there that's kind of day to day job.
So please, you know, sounds fine.
Reach out right on.
I'll be sure to put all your contact info in the show notes. So thank you so much for being here. Thank you for creating this GitHub repo. And thanks for the look back to kind of highlighting the last half year of what people talked about. It's been a lot of fun.
Great. Thank you for having me, Michael. Thanks.
Bye bye.
This has been another episode of Talk Python to me. Thank you to our sponsors. Be sure to check out what they're offering.
It really helps support the show.
Coiled supercharges the tools you already use for scale and performance so you can use Python for ambitious problems. Add Coil to your project in less than 1 minute. Get started today at Doc with Toptal, you get quality talent without the whole hiring process. Start 80% closer to success by working with Toptal. Just visit Talkpython.FM/toptal to get started when we level up your Python, we have one of the largest catalogs of Python video courses over at TalkPython. Our content ranges from true beginners to deeply advanced topics like memory and async and best of all, there's not a subscription in site. Check it out for yourself at 'Training.TalkPython.FM'. Be sure to subscribe to the show. Open your favorite podcast app and search for Python. We should be right at the top. You can also find the itunes feed at /itunes, the GooglePlay Feed at /play and the Direct rss feed at /rss ontalkython FM.
We're live streaming most of our recordings these days. If you want to be part of the show and have your comments featured on the air, be sure to subscribe to our YouTube channel at 'Talkpython.fm/youtube'. This is your host, Michael Kennedy. Thanks so much for listening.
I really appreciate it.
Now get out there and write some Python code.
