Imagine a world with free and unlimited clean energy.
That's the musings of a great science fiction story, isn't it?
But nuclear fusion, the kind that powers the sun, has always been close at hand.
We see the sun every day, and yet impossibly far away as a technology.
However, we took a major step towards this becoming a reality when the folks at the Lawrence Livermore National Laboratory in the US achieved ignition, where they got significantly more energy out than they put in.
and Python played a major role in this research and experiment.
We have Jay Salmonson here to give us a look at the science and the Python code of this discovery.
Also, I've linked a five minute YouTube video explaining the details and showing this massive machine that they used.
It's worth watching before you listen further.
This is "Talk Python to Me," episode 403, recorded February 1st, 2023.
(upbeat music)
Welcome to TalkPython to Me, a weekly podcast on Python.
This is your host, Michael Kennedy.
Follow me on Mastodon, where I'm @mkennedy, and follow the podcast using @talkpython, both on fosstodon.org.
Be careful with impersonating accounts on other instances.
There are many.
Keep up with the show and listen to over seven years of past episodes at talkpython.fm.
We've started streaming most of our episodes live on YouTube.
Subscribe to our YouTube channel over at talkpython.fm/youtube to get notified about upcoming shows and be part of that episode.
This episode is brought to you by Taipy.
Taipy is here to take on the challenge of rapidly transforming a bare algorithm in Python into a full-fledged decision support system for end users.
Check them out at talkpython.fm/taipy, T-A-I-P-Y.
And it's also brought to you by User Interviews.
Earn extra income for sharing your software developer opinion.
Head over to talkpython.fm/userinterviews to participate today.
Jay, welcome to Talk Python to Me.
- Thanks for having me, Michael.
Pleasure to be here.
- It's a pleasure to have you.
Congratulations.
- Thanks, thanks.
And of course, I would be remiss if I didn't totally qualify that this, and he congrats have to be accepted on behalf of hundreds of people at the NIF, at the laboratory and laboratories and industry around, and indeed extending back six decades of research that went into this.
My part is insignificant but not negligible.
>> I'm having a couple of my mental models broken recently.
For me, fusion has always been one of those things that's always 30 years out.
It's like, we know it's possible, but it's just, we're really barely scratching the surface.
And the other mental model is AI is always 30 years out as well.
And this year of ChatGPT and stable diffusion and all those things.
- Things are changing.
- Yeah, and this huge breakthrough that you all had.
I'm sure there's still work to be done.
You're not there yet, right?
We're not all driving around little tiny, you know, water powered cars and stuff, but it shows that it's possible, right?
And that it's a massive deal.
- Yeah, no, you're absolutely right.
there are a couple of big changes here in the last months even, right?
So I'm still processing both of those actually.
So yeah, it's going to be an interesting world.
I think as far as ignition, it is still a long path forward towards utilization. We can talk about that.
>> Yeah, we will. But it's so exciting because with renewables, that's great.
But there's always a cost to that in terms of like, well, just think solar panels, the mountains of e-waste of those things as they deteriorate over time or just getting them all produced.
But I think this is different and I'm super excited to be diving into it with you.
I'm also really interested to hear how Python played an interesting role in it.
>> Yeah, I think that's a fun story and so I'm happy to have a chance to share it.
>> Yeah, and you've been central to it, which is fantastic.
Now, before we get into all that, let's get into your story.
How'd you get into, I guess, physics as well as Python?
>> Yeah. I always wanted to be a scientist growing up.
As a little kid, it was always space and dinosaurs and dinosaurs and space and all.
That's how it started.
Then I remembered, it's actually just about this time, about 40 years ago or so, my dad brought home a Commodore 64.
This would have been the after Christmas buzz of learning basic and stuff, my sister and I. That really started my computational journey.
And then fast forwarding to I got a degree in physics from Montana State University, did a cosmology with Bill Hiscock there, and then moved to California, took some time off.
I worked at Chevron in the geophysics staff for a couple years, met my wife there, worked at NASA Ames Research Center in Mountain View for a year.
Then I decided to go back to school, which is what I always wanted to do.
I looked around, I didn't really wanna move very much.
I was in the East Bay and San Francisco Bay Area.
- It's nice there.
- It is nice there.
- You have a family as well, right?
Which makes it, that can also always be a tricky balance.
- Yeah, exactly, exactly.
That's always a constraint.
And ultimately, that's a fairly stupid reason to make decisions, but it actually worked out very well 'cause it made me look around, and it turned out there was this amazing graduate program at this place called Lawrence Livermore National Laboratory, run through the UC Davis, University of California Davis, called the Department of Applied Science.
And so I ended up going there for five years for a PhD and studied gamma ray bursts, the largest explosions in the universe that come across the universe.
They send their high energy radiation from these giant relativistic mysterious explosions.
It's very exciting.
I worked on modeling, doing numerical modeling of neutron stars in their last few orbits and few milliseconds before they coalesce as the default model for gamma ray bursts at the time.
But it was a great experience programming in C++ and doing general relativity and such.
Then I did a postdoc after that and I got involved with another code at the lab that's actually people who are interested in numerical astrophysics might look into.
It's called Cosmos++ with Peter Aninos and Chris Fregeel at College of Charleston.
Again C++ doing more gamma ray burst research and such.
That's what I did until about 20 years ago when I took a job at Ignition with the ICF campaign, the inertial confinement fusion campaign.
That's where I've basically been ever since.
When things sort of switched gears, I basically kind of, I still worked with Cosmos++ for a few years part-time, but really I kind of retired my compiled efforts and went more towards the interpreted world and got more involved in that.
Because then in ICF, the whole point was NIF was being built.
It was still a hole in the ground at the time.
And there are these big multi-physics codes.
That's what we use at the lab to kind of research our ideas, to run them in simulations, see what they'll do.
And we use interpreted languages to interface with those, either to run the code to help steer it, if you will, but also to post-process.
And so I got really involved with a few languages.
And Python didn't actually come to the fore at first.
I was introduced with Python a little bit in the '90s.
I wrote a little cron job that went to the weather service and put a weather map of my background every hour, which I thought was pretty nifty.
And so I saw that it had potential.
But one of the languages that I was first introduced to was Yorick, which was actually written by a physicist at Livermore, Dave Monroe, and so it's fairly extensively used at the lab.
And it actually is, it has a causal connection to particularly the NumPy library in Python.
I also actually got pretty involved in Perl at the time.
Something about it sort of appealed to me.
I sort of liked its lexical structure.
Larry Wall is a linguist and all.
But definitely for the last 10 years or so, the weak couplings that are appealing about Python just kept coming back.
So I've since bitten down on that hook and drank Kool-Aid pretty readily.
So for the last 10 years or so, it's been all Python all the time.
>> Nice.
>> Yeah.
>> Now you just got to tattoo the Python logo and it's no going back.
>> Exactly.
>> Got it.
>> You have one, right?
>> That's right. I keep my whole back.
>> Yeah. Right.
>> One thing that stands out with that story, which is really interesting, I think it seems to me like there's quite a move in the sciences in general to move more towards open source and more towards sharing in terms of, "Hey, if you use this library and we use that library, then maybe we can both have a better library type of sharing." >> Yeah.
>> Than they traditionally been.
>> Absolutely. That's something that I've been fortunate enough to watch happen over the course of these years.
I think what we see that it's non-linear, it's just exploding.
I think one of the appeals of Python has been PyPI and just this proliferation of packages.
I mean, shout out your Python Bytes podcast.
I find that to be quite fun and almost overwhelming the new things that are coming out all the time.
You got to keep up and pick and choose, but there's all sorts of new things.
The paradigm has shifted for me and I think a lot of people, where I have this thing to do, I better start doing that or crack a book or whatever.
But no, it's like, let's find the package that already does that.
And that's just a fundamental shift.
And it's actually a lot of fun, I think.
And you can contribute to it as well.
Yeah, absolutely.
I feel like when I went to school, I just took one or two, just maybe one or two.
I certainly one maybe two computer science type classes.
And it was all about algorithms and, and how can you evaluate, oh, this bubble sort versus that, or this data structure versus that.
And it seems a lot less, not that that's relevant, but it seems way more important now to, oh, I can evaluate these libraries and pick this library.
And it probably does something great inside, but I don't need to worry about it.
Right.
It's more building with Lego blocks that it is, you know, building with wiring kits, I don't know, like, you know, it's more big pieces that you just put together.
And, you know, kind of just to tie in, you know, the very first inklings of what chat GPT and, and, uh, you know, and copilot and stuff can bring.
I mean, you know, I think Andrej Karpathy made the comment that the new interpreted language is English, right?
And it's almost getting to that point where we can just almost dictate what we want, you know, which is sort of the next level of abstraction, you know, I think that's just going to happen now, right?
Yeah.
It's we're past the 30 years, I guess.
And it's starting to get crazy.
So I think this is really a positive move for the sciences in general, that so many of these libraries are available and now you have thousands or millions of people working on it and using it, not just a single research lab.
>> Yeah. It's nice to actually see, I think from my little vantage point, I'm not always aware of it, but the lab Livermore, for instance, and I think all the labs participate, they release a wealth of open-source software as well.
It tends to be fairly focused on high-performance computing.
It has a niche, but it's definitely, we're trying to give back and be part of that conversation.
>> This portion of Talk Python to me is brought to you by Taipy. Taipy is the next generation open source Python application builder. With Taipy, you can turn data and AI algorithms into full web apps in no time. Here's how it works.
You start with a bare algorithm written in Python. You then use Taipy's innovative tool set that enables Python developers to build interactive end user applications quickly.
There's a visual designer to develop highly interactive GUIs ready for production. And for inbound data streams, you can program against the TaiPy core layer as well.
Taipy core provides intelligent pipeline management, data caching, and scenario and cycle management facilities.
That's it.
You'll have transformed a bare algorithm into a full-fledged decision support system for end users.
TaiPy is pure Python and open source, and you install it with a simple pip install taipy.
For large organizations that need fine-grained control and authorization around their data, there is a paid TaiPy Enterprise Edition.
the TaiPy core and GUI described above is completely free to use. Learn more and get started by visiting talkpython.fm/taipy. That's T-A-I-P-Y. The links in your show notes. Thank you to TaiPy for sponsoring the show.
Well, let's start our conversation and our exploration here with some science and then we'll get back down to the Python inside of it. Yeah. Let's talk about just all the stuff this led up to fusion in general and then the science and the attempts that have led up to this great breakthrough?
Yeah, so like I mentioned, actually, you know, laser-induced fusion has been a research area for six decades at the lab.
When the first ideas were starting, when the first lasers were around and the first people started thinking about that as a driver for fusion.
And again, this concept of fusion is inertial confinement fusion.
sort of based on the concept of taking some hydrogen, hydrogen isotopes, we tend to use deuterium and tritium, those are the heavier versions of hydrogen because they have a higher cross-section for fusion reacting. And we implode them, so yes, you have a diagram here that you're showing. So we have a capsule, rather than that distinct from magnetic fusion, which is sort of the other camp where it's a little bit more like the fluorescent bulb model for fusion where you're running plasma through a torus or some sort of a manifold like that, making it very hot but at low density and maybe something a little more akin to the corona of the sun, say, and fusion will happen there in those schemes.
And then here we're actually taking all of the fuel and putting it inside of one little capsule and then we're compressing that capsule, getting it to very dense as opposed to fusion or magnetic fusion, which is low density, very dense and hot conditions where fusion can transpire. It's actually sort of analogous, I think, to an internal combustion engine in that regard. So we're actually, you know, driving fusion. It happens and it blows itself apart.
Okay. The graphics that I had seen largely were those big Taurus-like structures. Was it? There's a name for that, the T.
Well, there's Tokamaks and Spherimaks. Yeah, there's several concepts out there.
Right. That's the one. So those I think is probably, yeah, that's probably what a lot of people are familiar with.
And this project is focused on aiming a bunch of lasers at a really small point and just really compressing it and heating it all all at once.
Right.
Exactly.
So, you know, just to kind of, I guess, give the outline is just like you said.
So the NIF is a big, big stadium size facility at the Northeast corner of Lawrence Livermore National Laboratory.
And in it, it is filled with 192 gigantic beams.
each one of them is basically one of the largest laser facilities in the world, and there are 192 of them. They each basically work in concert to shine a pulse of just a few nanoseconds long, and this pulse goes down, and kind of as the graphic you showed, they all are basically trying to converge at a point. But rather than just a point, what we put at the center of this convergence of all these 192 beams is a little tiny gold can, and so the can is about a centimeter high and maybe half a centimeter wide.
And on the top and bottom, you put these two little holes and the no enclosure, the laser entrance holes that LEH is so, and so it's rather amazing, these 192 beams of, of, you know, gigantic lasers and when they're, when they're being amplified, they're actually several feet across.
So the beams are spread out.
They're huge, but they all get focused down to the point where they can all go through just a couple of millimeter sized hole, both at the top and the bottom of this gold can and they shine into the can and they shine on the inside wall of the can and their goal is then to heat the can, right?
So you start with this laser light and then you want to heat this can and this can we, we refer to it as a whole room.
That's a German word that refers roughly, translates roughly to hollow room.
And that's just simply because it's something that holds, you know, holds the heat and all rooms are actually.
Everywhere in our life, right?
Our ovens are a whole room, whole ovens, heat up to temperatures of our infrared temperatures, right?
We can sort of feel that heat.
We can't see it, but we can feel it.
You know, if you get up, we heat these little hole rooms up to actually x-ray temperatures so that they're so hot, they're beyond visual, they're beyond ultraviolet, but into the x-rays, and it's actually a fraction of the temperature at the center of the sun, in fact.
And so we're actually bathing this little tiny gold can within this superheated x-ray environment.
And then we inserted inside of that horn beforehand, a hapless little capsule.
And this capsule is about exactly, you know, you kind of feel sorry for it.
Yeah.
Anthropomorphize it a little bit, but, and, and this capsule is, is made of, it's a very, very thin shell, just a couple hundred microns or a hundred or so microns, uh, thick.
And, uh, right now that these shots are being actually there, they're used a nano, nano crystalline diamond.
So they're like pure carbon.
shelves and so they're very dense.
And so it's, it's kind of funny.
We have a gold whole on the whole room is made out of gold and the capsule is made out of diamond, right?
And so could you have picked more prosaic ingredients, but these are the ones that work.
And so the point of this capsule is really just, it's, it acts like a rocket fuel.
And so what happens is the laser energy is absorbed into that diamond and it explodes.
It's just does pretty much exactly what you'd kind of think.
It just, it heats and explodes.
And then, you know, going back to your Newton's third law, right?
So if you have an action for a reaction, there has to be an equal and opposite reaction.
If you have this little capsule exploding outward, right in this bath of x-rays, whatever you put inside of that capsule has to go inward.
And happily we were really, uh, we actually put in a little bit of deuterium and tritium and we actually froze it into an ice layer around the inside of that capsule.
So that becomes our payload.
So it's the spirit.
Spherical rocket analogy is actually very apt.
So you're actually, you're having this fuel blowing outward and causing thrust that pushes the payload inward, and you try to compress it into a tiny little pellet, again, trying to achieve very, very high densities, hundreds of grams per cubic centimeter and tens of kilovolts.
That's no enclature, we can talk more about that.
But to get to the point where you're actually at fusion conditions, and what you're looking for and the goal, the reason why we're talking right now is you're always, the goal was always to achieve an ignition.
So for a very long time, people have been demonstrated that you can get neutrons out of this.
You can actually get a few of the billions or well, billions of billions of hydrogen atoms in there to fuse.
But what we're trying to do is get to the point where they bootstrap, where one fusion can cause another fusion or several more fusions, which will cause more fusions.
And you get what's called an ignition and it's ignition wave where actually the fusions will cause more fusions and they'll actually cause a burn propagating from the tiny center of that little assembled piece of fuel, move outward and actually, you know, propagate and burn fuel as it goes out.
And that way you can actually, you know, that's that way you, you get a macroscopic amount of the fuel to burn, to convert to helium and release fusion energy, release neutrons.
And that's, that's what we finally achieved.
It's extremely difficult because basically everything has to work perfectly.
in 192 lasers and probably a chaotic dynamic reaction of some form of explosion and interaction there.
It's not super easy to control and there's some interesting Python planning, some of those experiments and stuff.
But it sounds to me that it's, even though it's in a sense very much the opposite of fission, traditional nuclear reactions that we already leverage, the way that it kind of propagates and once you get it going, it sounds actually oddly similar.
Yeah, I mean, fission, the good thing about it is, or the nice thing about it is that it's passive, right? But it does operate on that same idea. If you put fission products really close together and one goes off, then it might cause others to go off and you can get that chain reaction. And exactly, we're trying to get that to happen with fusion.
But the thing is that, you know, fusion, these particles are so light and they're all like charges, right? So they're all trying to push each other away. And as soon as you start putting heat into it, the product of fusion, the thing you wanted to get out of it, it immediately blows itself apart and turns itself off.
Unlike fission, that's really kind of always the trick.
That's the hard part.
Yeah.
Yeah, exactly.
You have to really carefully balance the lasers to, to keep the confinement happening and keep the pressure there until it takes off, right?
The lasers are short shrift.
Unfortunately, there's, they're just amazing technological achievements, frankly.
And I'm, I'm only just, you know, I know a little bit about them.
I know enough about them to simulate them.
But they're amazing technological achievements that you can get all of these to run together.
What they do is actually they give this blast, they heat the whole room and they actually heat it, not just like turn it 450 like you're having.
They actually heat it in these very precise stages that are time all over the course of this few nanoseconds.
You're actually trying to ablate this rocket fuel in steps.
You're not just trying to just blam.
And doing that, you do that very precisely.
So you're actually blowing a first step, and then you do another step, and then you actually hit it harder and really give it a good hard drive to really implode it.
And all of that is happening by basically the lasers over the course of these few nanoseconds, just sort of pulsing in a sense, if you will, to heat this whole room in these stages.
So all of that has to be just perfect.
It has to be very uniform.
And then that ends up driving this capsule.
And the capsule doesn't want to actually implode.
And that's another big thing is it's unstable.
You never, nature doesn't want to take nature.
They always say nature hates a vacuum.
Nature also hates when you take every, all the rooms, I got Adams in a room and try to move them into one corner, right?
It doesn't let you do that easily.
Right.
And that's basically kind of what we're trying to do.
We're trying to take all of these fusion, these hydrogens and, and put them all together into a tiny, tiny space.
And kind of like you'd imagine just trying to press a balloon together.
We're trying to load this capsule by a factor of 30 in linear scale, 20 to 30.
And, uh, you know, if you tried to take a balloon and do that, right, you can imagine you push it in and it pops out where your, your fingers don't, you know, where your fingers aren't.
So you bring in a friend and they, you push together and you're all pushing together and pretty soon the balloon is finding tiny little places to squeeze out, but, but it's going to find them.
Right.
And so you have to just basically iteratively, you know, make everything as perfect as possible.
And, uh, so the other hero of this achievement, not just the lasers, the lasers have been just going through these rather miraculous increments beyond their original design specs to the point where they're, they're delivering more energy than they were originally promised and with, with unprecedented smoothness and precision, but also the capsule and its smoothness and perfection is amazing.
So like this capsule, these capsules, if you just sort of think of out of roundness, They're about 200 nanometers, maybe out of round, out of a millimeter.
And, you know, the earth is roughly 20 kilometers out of, out of round, out of 6,000.
So these are, if you do those ratios, this, this is actually about 10 times rounder than the earth, you know, and it's just a tiny little, you know, millim, two millimeters across a capsule.
Right.
So they're, they're very, very smooth and that's something that's, that's been progressing.
And I would say those two achievements are kind of the things that had to be incrementally improved to the point where you're trying to realize the ideal.
Our codes are good at simulating ideals, and we do a lot of work to try to actually simulate the imperfections as well, and capture as many of those imperfections as possible.
But we've always been able to do the ideal and say, "Yeah, the ideal works." The whole spherical cow ideal.
>> It's exactly high around this ideal circle, and of course, it's going to work like this, and there you go.
- Exactly, and it's like, oh, that works really well.
And that's been the issue.
And really what's happening is these large teams of experimentalists have been able to make the laser better and continue to and make these targets better.
And they're actually getting closer and closer to ideals that even just a few years ago were like ridiculous.
So it's really a testament to that hard work.
- Yeah, really amazing.
So what we're all learning is to collapse this balloon, you need 192 friends or 191 friends, if you don't count yourself right.
>> Right. The fact that we're doing a can like this whole room is very important.
We're not actually shining the lasers on the capsule.
That's something that's called direct drive and indeed that is a field of study.
That provides its own challenge because indeed, each laser is like a little fingertip trying to push on the capsule.
This is so-called indirect drive because we're driving the capsule by the heating bath of the lasers.
The lasers are heating this, this whole room and that's driving the capsule.
So it's the actual, it's more of the shell that is playing the important role of, of doing the compression and you need to provide just enough controlled and even heating to make it go.
Right.
Yeah.
You want to make that, that, but you still need to make that heating as controlled and even as you can.
And it's still not even enough really when you, so there's been, you have to do a lot of work with, you know, making sure that heating, you know, where you put the beams, where the spots are, which are kind of like the elements in your oven, right? You know, if you turn on the broil elements, you'll burn your toast, right?
And so you have to know where to put those elements, where do those spots hit the inside of the plurum to heat as uniformly as possible.
Yeah. And people might be thinking, well, compressing something 30 times, it's not that crazy. We do that with air all the time. You look at combustion engines and other stuff, but you're also heating it.
Well, it's 30 times linearly.
You're also heating it to the near the temperature of the sun. It wants to get a lot bigger really It doesn't want to even stay where it is, right?
- Absolutely, yes.
You're heating it up to actually temperatures in excess of the center of the sun.
So yeah, it doesn't want to be there.
(laughing)
- It wants to get moving.
All right, fantastic.
Let's just talk one more science side thing, then we'll dive into the software side.
This is the first time this has been done, and it's a huge accomplishment.
How do you all see this very quick and small reaction potentially turning into actual energy sources.
Where do we go from here to do something productive with this?
>> It's important to note that the National Ignition Facility itself is a demonstration facility.
It's a research facility.
It's not meant to become an energy facility.
Indeed, there are other startups out there, I think there are probably going to be more, that are exploring ways to commoditize this.
It's interesting to think about the energy a little bit if I can.
So just to kind of add a scale to this, you know, like a human eats about 2,000 calories of food a day, right, an adult, right?
And those are actually kilocalories, nutritional calories.
So that's two million calories, which is, you know, two megacalories.
And it turns out that a calorie, it's kind of convenient, is four joules, another scientific measure of energy that we use all the time.
So that two kilocalories we eat every day is basically two million calories, which is eight megajoules, eight million joules.
So just multiply by that four.
So eight megajoules you eat every day, right?
So this laser is producing two megajoules, sort of like your breakfast, right, of energy.
So it's actually not an unachievable amount of energy, but it does it in just a few nanoseconds, right?
And I don't know how to describe a nanosecond all that well except to know that the speed of light is a good measure, right, the speed of light.
So at the speed of light, a light wave can go around the Earth seven and a half times in a second.
But in a nanosecond, light only goes 30 centimeters, so about a foot.
And so I think that gives you an idea of just how quick that is.
And so that's the key.
- Yeah, it gives you a sense of how insane, how insanely precise those lasers have to be.
- Exactly, yeah.
- They've got that 30 centimeters.
- Right, the entire, yeah, that's the cosmic speed limit.
No information can go faster than that.
and so everything has to be within this really small envelope.
It's quite amazing.
Then the reason why we're talking about this particular achievement is that it actually yielded a little over three megajoules, so maybe breakfast plus lunch in fusion yield.
Again, that happened instantaneously effectively that was released.
It's more about the release that makes it amazing.
But the thing is that the energies aren't all that large at this point.
And it occurred to me that, you know, well, if you think about it, it's kind of interesting to think about like, so going back to the food analogy, so you eat, make eight megajoules per day.
A day is 24 hours times 60 minutes times 60 seconds.
So 24 times 3,600, it's 80 or 90,000 seconds, right?
So eight megajoules divided by say 80,000 seconds, that works out to a hundred joules per second or a hundred Watts.
So you as a human, you know, burn a hundred Watts, right?
which is a very, we use that term all the time.
You can imagine taking a mannequin and putting a 100 watt incandescent bulb inside and it would heat up to our skin temperatures.
We're going at a much, much higher wattage because we're doing it very quickly.
You can actually think of a unit of measure that we often use in electricity and stuff is the kilowatt hour, 1,000 watts times an hour, which is again, just 3,600.
So a kilowatt hour is just 3.6 megajoules then, so 3,600 times 1,000 watts.
So 3.6 megajoules is a kilowatt hour.
- This portion of Talk Python to Me is brought to you by User Interviews.
As a developer, how often do you find yourself talking back to products and services that you use?
Sometimes it may be frustration over how it's working poorly, and if they just did such and such, it would work better, and it's easy to do.
Other times it might be delight.
Wow, they auto-filled that section for me.
How did they even do that?
Wonderful, thanks.
While this verbalization might be great to get the thoughts out of your head, did you know that you can earn money for your feedback on real products?
User interviews connects researchers with professionals that want to participate in research studies.
There is a high demand for developers to share their opinions on products being created for developers.
Aside from the extra cash, you'll talk to people building products in your space.
You will not only learn about new tools being created, but you'll also shape the future of the products that we all use.
It's completely free to sign up and you can apply to your first study in under five minutes.
The average study pays over $60.
However, many studies specifically interested in developers pay several hundreds of dollars for a one-on-one interview.
Are you ready to earn extra income from sharing your expert opinion?
Head over to talkpython.fm/userinterviews to participate today.
The link is in your podcast player show notes.
Thank you to user interviews for supporting the show.
And not to put you on the spot, Michael, but do you know how much you pay for kilowatt hour for your electricity in your home?
I think 17 cents.
Oh, that's awesome.
I'm so impressed.
I'm pretty sure.
I'm pretty sure as long as I have the units, right.
Because yeah, no, that's about right.
I have an electric car.
I have little stuff that'll show me like, here's how much you charge and how much it pays into your price here to get your, like, so I'm pretty sure.
I'm pretty sure it's 17.
It might have gone up just a tiny bit.
>> Okay. Yeah. I pay about 25 off peak and like 45 cents per kilowatt hour on peak.
I have an EV and I'm aware of all that as well.
Again, this shot produced about a little over three megajoules when a kilowatt hour is 3.6, which is, as you said, you can buy one for 17 cents.
I can pretty much say with certainty that this experiment cost more than 17 cents.
Even if you scale it up somewhat, it's going to be more than 17 cents.
Yeah.
Yeah.
This one experiment for my one, one kilowatt hour I got out of, or a little less than a kilowatt hour I got out of it.
That's, and nevermind that there was a certain amount put in, I had to put two megajoules in and there's inefficiencies as well, but so I think that just sort of outlines the challenge of scale.
Right.
I mean, so, you know, I have to make a capsule that's way, way cheaper than 17 cents to make money.
I have to, you know, probably I want to get more than a kilowatt hour per shot.
I'll probably want to 10 or a hundred kilowatt hours per per shot.
And then I'm going to have to have a lot of high rep rate because ultimately to power your home and my home and a town's home, you know, you need lots of kilowatt hours.
And so, you know, scaling it up is a challenge.
I think that's just sort of a nice way to illustrate, you know, um, where you have to go to get there.
Yeah.
You got to start somewhere though.
The first transistors, I'm sure were expensive.
You know, the first, Oh, exactly.
100 kilobytes of hard drive storage seemed just insane.
If you told somebody, well, we're going to need a terabyte on everybody's computer, like, no, we can't do that.
>> Exactly. Yeah. Absolutely.
>> On an SD card, nothing.
>> Exactly. There's a lot to do.
There's a lot of growth there that needs to happen.
>> It's early stage for sure.
>> Right.
>> Awesome. Let's talk about some of the software side.
I know that you guys have over at the LLNL, Lawrence Livermore National Laboratory, you have a software portal.
We have a bunch of different applications and things that you're sharing, which are really great.
And so I know that you've got a lot of neat things happening on the software side.
Your area has been largely around designing and simulating the experiments.
And then once someone runs them to go, "Okay, I got some data. How'd that work? How do we adjust?" Maybe talk to us about some of the software side of what you're doing there.
Yeah, right. Like we were saying, our kind of design cycle is that we have these quite impressive multi physics codes that can simulate these experiments, right, that actually mock up the whole room and the capsule inside and, and actually fake lasers in and run the how they would interact with the gold atoms and actually run the entire simulation.
But, you know, usually don't want to just push the button and just have it come out.
Usually you're asking questions about it, you're instrumenting it up, if you will, you're test, you're checking things.
So you're kind of steering these simulations.
And so one of the big facets of software that we've been working on for the last few years is to improve that steering in Python.
We can talk a little bit more about that.
But then also we have, so then you get out your simulations result, right?
You say, "Oh, well, this result did such and such," right?
But now you want to actually compare it to data.
So you have to go over to a web page or talk to somebody who ran an experiment on NIF and talk to them and get that data.
So that's another area that we've been working really hard on over the last five or six years I've been to try to improve that ability to so that basically we're kind of bringing all the parties together so that the making the simulations easier to run easier to work with and also having the data and tools proximate to that so that we can all sit in one place and actually ask all the questions and get all the answers in that one spot. So historically that's kind of been the design cycle and it's been fairly organic right where people will write tools that work for them to steer code or to do some post-processing, and then they'll share them with people, and then somebody else will share it, and they'll tweak it, and eventually somebody will quit asking just friends and they'll put it in a directory somewhere, make it readable.
That had been the way we'd done business for a while, and we're trying to actually improve that.
About five or six years ago, I was designing some experiments for the NIF, and I was running one of these tools that were sort of an organically grown thing, and I was trying to do something that was a little bit challenging for it, and a little bit out of its strengths.
I basically kind of had an existential crisis.
I just thought, "I can't do this anymore.
These tools aren't cutting it." The code underneath is great, but I'm just beating my head against the wall to talk to it and to get things out of it.
You can really burn a lot of human time doing that, which is very expensive.
So I basically just stopped running those tools.
It was just like the whole office space thing, where the guy post hypnotic suggestion.
I don't think I want to go to work today.
Exactly.
>> I don't think I want to do that either.
I just got it done.
>> It was kind of like that.
I just felt like I can't do that anymore.
and I think my time would be better spent trying to improve the model, improve the ecosystem.
Again, so I am drinking the Python Kool-Aid all the time, learning more and more about the ecosystem, also learning just about Git and continuous integration, just things that are out there that I'd been entirely naive about myself, and realizing that, oh, there's actually things to do.
In all fairness, of course, other people are thinking things like this as well as per the page you've got up here.
The lab has tons of people who are doing this stuff in spades.
But there are a little corner of ignition land that wasn't happening as much as I wanted.
I basically looked around and I found a couple things that other people had just been starting.
One of them is basically a Python wrapper of one of our codes.
We have one of our multi-physics codes, we call it Hydra.
The developer physicist, Joe Koning, did the hard work of actually installing Python.
and a Python interpreter into that.
So it actually talks to this big multiphysics parallel code.
>> Interesting. So it's actually hosting the Python runtime, not the other way around where Python is trying to wrap it CAPI?
>> Right. No, the code itself is running and Python is just bolted on top of it.
>> Okay.
>> Yeah. So the code is still in control.
It's actually very challenging and Joe did a great job of doing that after the fact.
But now you have the ability to actually, you know, to initialize the problem and tell it its run state purely in Python.
And he was starting to build an infrastructure to develop our problems, our ignition problems, these whole arms and capsules and such.
And I just jumped in on that. I thought this is what we have to do.
It was a tremendous amount of effort to build that up to make it something that actually worked.
But I think that it's actually one of the easier tools out there, most robust and user-friendly tools we have now.
And so that's sort of the one half of the puzzle is just making a Python interface, a purely Python interface to run these tools.
And again, so this tool we call HyPy for the Hydra Python deck, and again, Joe Koenig initiated it, and I've been really involved, and Chris Young has gotten involved since then, helping a lot.
And so we basically just tried to build the entire ecosystem of how do you initialize the horum, and the capsule, and the laser, and all of those things, so that you can tell this hydrocode to run and give you some results.
That's been a big push that I've been championing and proselytizing on.
The other half of it, and this goes back to Dave Monroe and Yorick, like I was mentioning earlier, a lot of people use Yorick.
It's a very, very useful tool for data analysis.
Again, it's an interactive tool with a very, very nice array syntax.
Think of it like interpreted C, if C syntax was just interpreted with a really nice array syntax built on.
So it's still quite widely used, but I think to Dave's credit, Dave Monroe's credit as he was near retirement a couple of years ago, he decided that Python was the way to go.
He decided that the future was going with leveraging what's out there and just going with Python.
>> When you're the one who created your thing and you're like, "You know what? I love my baby, but it's time to think beyond." Absolutely. I don't think he gets enough credit for that.
I have immense respect for that because, I mean, I don't know if I was to do that.
A lot of people become very protective of their babies, but no, it's what's best.
Before, the thing that's nice, one of the nice things about Yorick is a lot like Matlab or Mathematica.
When you type Yorick and open a shell, everything you get is right there.
It's a single environment.
>> Like it or not, Python is a little more heterogeneous and diverse than that.
It's a feature in a bug.
One of the things he wanted to do as a parting gift to us, is he created this tool called IDesign that is basically, at its core, it's a Python virtual environment that just pip installs all of the packages that we like to do.
There's a lot of them that we've been building to create this Python ecosystem that will then talk to this Hypeide Hydra simulation layer.
Basically, then everybody can just type Python, and they'll get that environment.
By itself, that's not all that big a deal, but it does actually have a certain amount of nice features that we've been able to build it into our GitLab continuous integration environment.
We built an awful lot on it since he did retire.
You can take snapshots of those environment state and some other things.
People have told us we need to open source that I've sort of balked at it, but I think I've made the decision that we're going to.
So, IDesign will eventually be on that page you were showing earlier.
So, you know, hopefully in a year or whatever, we're going to do that.
But another key component, I think one of the things I get excited about, and it's one of the things that's exciting about Python in general, is the fact that, you know, that you can have these, it's an enabling technology, right?
And so now that you have an IDesign environment, everybody can come into a uniform Python environment, and everybody speaks the same languages, has the same tools at their disposal.
Well, now you can actually build in tools to go grab data from the NIF databases, where they're running shots and they're compiling all of this data.
It's not always as easily accessible as you would like for maybe a non-expert in that particular diagnostic or whatever.
What we've been doing is another big campaign, a part of this iDesign ecosystem is that we've been building what's called a shot data pipeline.
And again, this runs in the GitLab continuous integration environment.
Every night we go off to a bunch of databases and just harvest a whole bunch of data, bring it in and rebuild this IDesign environment with physical data, again, the tools, and then the ability to actually run the code, all in Python, right? All in one environment.
Yeah, probably before when people run the experiments, I don't know what before is, maybe way far back, but when you get started, you know, you're like, "Okay, I got to get the data here, and then we got to maybe process it and then convert it to this other form, and then filter this down and then finally we can get it so we can import it over here and process it.
Right?
So you're talking about, well, what if you had a CI pipeline that could do a bunch of these sort of steps, right?
Is that the idea?
Basically.
So experimental physicists who know their diagnostics extremely well, and so they actually will take that raw data and distill it to something useful.
We're really just doing the more prosaic step of going and getting it and bringing it so that it's proximate to the designer.
That's one of those things it's like, well, yeah, just go get it.
But it's a huge task and it wastes an awful lot of designer time when you have to chase down data for shots.
>> How much data are you talking in?
>> It's not a lot of data really, but per shot, you might only be dealing with few numbers, few scalers, and then it can go up to images.
You can ask for a lot of, you can get more detailed pictures, but even you might just be looking for just a few numbers.
But the thing is, if you have to go ask for those few numbers every time, it's not like it always has to happen.
It's just there wasn't a process in place to just try to, that was the culture.
When you want something, you just go ask somebody.
That's fine, but we've been trying to make the culture a little bit more like, let's provide it and let's automatically rate it.
I think that's been really an exciting.
This whole Python framework has been the enabling technology to allow that to happen.
We're just at the point now over the last year or so that, in fact, a lot of this stuff is still coming to fruition right now.
You'd still consider it Alpha and Beta, but it's actually finally coming together, which I think is really exciting.
That starts maybe slowly changing the culture, where people start expecting, "Hey, it's actually easy for me if I just put my data in a spot and those shot data pipeline guys, we're going to just going to harvest every night.
I don't have to worry about it. I don't have to feel email.
- Once the foundation of the automation is there and people start to realize they can trust it, then you start to get creative and put more things on there and leverage it more and it just makes a lot of--
- Exactly. - A lot of stuff take off.
- It's PyPI, right?
It's small.
- It is, it is.
- And another part of that is that the design community, which again, I talked about how a lot of things, people will develop tools and then they'll just share them when asked, maybe put it in a directory somewhere.
Well, now we have a place where you can actually have your own repository.
And maybe a physicist isn't all that interested in learning what a Git repository is, but we can help with that.
You know, I mean, it can become a place where you can have your tools and they're available and they're deployed because we also have the issue that we have systems that are air-gapped, right?
And so we need to have this whole distribution mirrored over here with a physical pass-off, right?
And so we try to do that now regularly rather than just piecemeal.
And, you know, hey, if you create a little tool or whatever it is, it's just everywhere all of a sudden.
That's really new and I think that's again, very empowering for the designers who are creating these new experiment.
>> I think people who haven't experienced it, these organizations, these research labs and other similar places, they basically become software companies.
At least they have a software team that is functioning really at a pretty high level in them.
I worked at a research place that had six or seven PhDs and a bunch of grad students, and me and another software developer, and we were writing software full-time, and it just, it kept getting better and better, and what actually the grad students would say to me is, if you keep doing this, we're gonna be out of a job.
All the software you're writing, this is what we do.
And like, no, what you're gonna do is you're gonna do actual science and actually better stuff, and every time they'd be like, well, this was my job, and here it is a button now.
And nobody was fired from that.
They just did more interesting stuff and took on more ambitious projects.
It's pretty cool to see.
>> Exactly. I've been accused of that before.
You're going to put us all out of the job.
But it's like, no, no.
Your job is so much more interesting now, and my job is more interesting.
I spend a lot of time developing now.
I've made this my passion.
I have a smaller fraction of my time doing designing experiments, not zero, but smaller.
But I actually feel like it's much, much more efficient than it ever was.
>> Yeah. You might have a bigger impact though, even though it's less time.
>> Yeah, exactly.
It's just a lot more efficient and it's fun to show younger people who are coming in how to do this and that it doesn't have to be what I consider a painful cycle.
I mean, maybe some people enjoy it.
Yeah. I like to say that I feel like I'm building the tools that I wish I had when I started.
I think it's happening.
Again, we have a really great team of folks that we're working with, I work with, you know, computer scientists, Ryan Tran and Jimmy Smith, who helped me build this stuff out.
And it's, it's just been, uh, it's been really great.
Sounds fantastic.
How many people are on the team?
So it's just a small and a certain amount of it is, you know, people who, who want to help.
So it's just a few of us, you know, again, Joe coding and Chris Young and Dave Strozzi, uh, and such.
So, and again, but then there, there are a lot of people who are starting to become contributors.
That's where the leverage starts.
Sort of a stone soup thing.
>> Yeah. On the NIF more broadly, how many people are involved?
>> NIF? Hundreds. Jeremy on the call here might be able to give an actual number, but it's hundreds of scientists.
For scale, you have to keep in mind that the Lawrence Livermore Lab has thousands of scientists.
Even though the NIF is a big program, it's actually fairly small as a part of the greater lab portfolio.
I guess I want to emphasize that I'm speaking for the design corner.
there's the experimental corner, the people who actually work with the hardware of the NIF and stuff.
We talked to them particularly with vis-a-vis the ShotData pipeline.
There are a lot of places that have their own architectures.
You can see that with the open source page and stuff.
So there's a tremendous amount and a lot of those things are doing really great their own great infrastructures.
But this is really speaking towards the needs of the NIF ignition community.
>> Yeah. You talked about the specific libraries that you are really focused on the work there, but I'm sure you used a bunch of standard Python libraries, packages that people are familiar with.
Maybe give us a sense of some of the tools and things that were at play that you're taking advantage of.
>> Oh, yeah. Well, of course, we're using all the NumPy, SciPy stuff.
That's a given.
We also, in Dye Design, we have PlasmaPy and X-Ray, DB, and some of these.
Again, these really nice physical data packages that people have developed in the open source community that now we just sort of bring in so that it's always there and maintained for designers at your fingertips.
Certain number of us also do, yeah, there you go, the page there you brought up.
>> pip install PlasmaPy.
>> Or conda if you prefer.
>> There you go, yeah.
A lot of us, including myself, are getting involved in machine learning as well.
Of course, that's an important part of the emerging technology people are excited to take advantage of.
And so I install PyTorch into IDesign and try to make sure that's...
Which is a bit of a challenge, right?
Because we have really large, different architectures, and taking advantage of their different GPUs.
It's not necessarily just a pip install.
I might have to compile it.
And so there are challenges there.
but we try to just make that available for the design community, which is cool because again, I mean, not to harp on the enabling technology thing, but we can now and I do, again, as a research thing, I can import PyTorch into my HyPy that runs my big Hydra multi-physics simulation and have it do inference on some part of the simulation, and maybe even offload part of that.
So there have been other, there are other efforts at the lab as looking at those kinds of things as well.
But again, I don't know how you would do that without these tools that we've been building, frankly, at least in our corner of the world.
- Yeah, you gotta keep building that foundation until everything is ready to click it together.
Yeah. - Yeah, yeah, exactly.
- While it's fun to imagine what would happen if you ask chatGTP to say, imagine chatGTP you had the most precise lasers in the world, how would you design a fusion experiment?
I'm sure that's not gonna result in much.
Where do you actually see real constructive AI applied to this or machine learning?
Do you have anything that you see on the radar there?
- There are several things that it's being applied to.
And in fact, maybe you can find some links here that there have been some, there's a group that sort of predicted, they gave some confidence whether this shot was going to achieve ignition, right?
where they're trying to learn from the experience of past shots and try to get some idea of predicting how a future shot will perform.
Those are new things that are happening.
I think the two sides of it are probably those kinds of high-level things where you're trying to ask big questions about what would happen if I do this.
But there's the other level of using it to offload some of the big numerical heavy lifting that we do all the time.
We run a lot of, the simulations run massive calculations trying to do the physics of these lasers shining into these whole rooms and such.
Some of those calculations could be learned by an inference engine and just maybe a simplified version provided over and over.
There are several efforts being applied to that.
We're trying to basically train an agent to just learn some part of how the simulation, what physical data the simulation should provide.
I've worked on some of those things.
there's more of that going on.
There's more details to that as well.
I mean, the way we do our simulations, we divide, you can think of our simulations or multi-physics simulations like an image.
To make an image, you divide it up into a whole bunch of little tiny pixels and each pixel has a red, green, blue value and that's what makes your image.
We do that with our simulations.
If you want to simulate a whole room with a capsule inside, you basically divide it up into a whole bunch of little tiny pixels.
we call them nodes and we interconnect them with their nearest neighbors.
So they create that links into a mesh.
Rather than having red, green, blue, we have physics attributes.
We tell it what it's made of.
That node is what it's made of, how hot it is, things like that.
It's ionization state.
Then we run the laws of physics on all of these nodes as they talk to each other and then that unfolds.
But as you can imagine, if you have a mesh of all these nodes, they can tangle up and they can get all messed up.
One of the things that we do is we have a certain amount of algorithms to try to keep that tangling from happening too much and crashing simulations.
That's an inside baseball thing, but that's one of the things, then I'm one of the side projects I have, for instance, of actually using reinforcement learning to try to figure out, just by giving it a whole bunch of trials, what's the best policy for relaxing these nodes so that they don't crash a simulation.
These things just make simulations easier again, and all of this, so you can ask questions and explore more quickly and easily.
>> We all know how tricky even three-body problems are in an orbiting system where they can become chaotic.
Well, imagine this thing you're describing is the interactions are insane.
>> Oh, yeah.
>> If you could get something to predict, you just say, here's a million different examples of what happened, how it started, how it started, how's it going, sort of examples.
>> Exactly. You got it.
>> It started, we're thinking here, how's it going to go, right?
>> Right. Of course, that's an experience in itself.
I mean, to actually take these forays into data science and large-scale datasets and training in multiple GPUs and stuff like that, it's been fun.
I mean, I know people do that all the time, but it's interesting to have that experience.
>> Yeah, for sure. There are some interesting articles of actually the CogSim team at LLNL and some of the work being done there.
So I'll link to those articles in the show notes.
People can check that out.
- That is the team I'm kind of referring to, that there is this effort to bring machine learning to bear on some of these problems.
So that's good work that they're doing.
- Yeah, of course.
We're getting short on time here, but let's wrap this up with one other aspect.
You talked about having air-gapped systems and not everything necessarily should be online or is online.
you want it to be all kind of isolated and stable.
So, and then you've got a lot of computation you gotta be doing.
Tell us just a bit about the computing environment.
Do you have like interesting clusters or grid computing or what's the story for actually running all this stuff?
- Yeah, yeah, good question.
Yeah, there's, for the context.
So basically we have a bunch of very, very large computer clusters at the lab.
And some of them, you know, are like near the biggest computers in the world or were at one time.
I don't keep track of that, but those are all on lists and there are new ones on the horizon that will take that crown again.
What we do is basically submit our jobs, carving out some chunk of the machine to run these multi-physics simulations for so many hours or days.
We're doing that. We do a certain amount of that on the open side, but then we also have a lot of resources on these air gap systems.
We do a lot of our running there.
That's sort of the exigency of moving our data, physical data from the NIF and our tools over there.
So we always have up-to-date tools to run there.
These are made by different vendors.
It's interesting, they're evolving where there's larger GPU components than there used to be, and the codes are learning to adapt to that.
So it's a fairly dynamic environment.
That's kind of, I guess, the general run environment we have, that we're running on a bunch of clusters.
How's quantum computing looking?
Are there any quantum applicable problems here?
>> Not directly from my experience.
I know there are some people working on quantum computing at the lab, closely attached to that.
>> Yeah.
>> I'm specifically thinking if you had a quantum computer, would this allow you, not necessarily trying to invent quantum computing, but somebody happens to.
>> Probably not. Maybe somebody else would know something.
But yeah, I mean, really, we're just trying to kind of, you know, integrate these differential equations that describe the physical system.
And, you know, maybe there's a way to diagonalize a matrix with quantum computing that's way, way better than an explicit method, you know, that we use.
But, yeah, I'm not, I'm not aware of it at this point.
I definitely don't know enough about quantum computing to even suggest that.
Well, I guess we're due now, if we, if these, these barriers are falling, right?
Yeah, exactly.
We need to try and be ready to do things.
Be careful what you wish for though, right?
I mean, having been able to crack any password, I don't know if that's a good thing.
Exactly.
I'd love faster computers.
Wait, baking doesn't work anymore.
Oh no.
Right.
Back to rubbing sticks together and sleeping on the wood.
I've got my money clip that I keep everything on my person.
Exactly.
I'll, I'll do that.
on my person.
(laughs)
- Exactly.
I'll mail you some cash in physical mail.
Get this.
- Right, right.
- You write careful what we wish for.
(laughs)
And we won't have much cash 'cause chatGTP will be writing our software that we used to write though.
It'll be fine.
- Well, this is true.
This is true.
(laughs)
- No, honestly, I'm very optimistic about the future in a lot of these things and especially this.
So, awesome work.
Now, before you get out of here, let me ask you the final two questions.
If you're gonna work on some of these Python projects, what editor are you using?
I've gone through the litany of editors in my evolution.
I started with VI and went to Emacs, went and used Emacs for a very long time.
Then probably five or so years ago, I decided I need to make a change and I went to Atom.
I can use Emacs binding so I didn't have to rewire my muscle memory.
Really enjoyed that until of course, last summer when they killed it.
I had to look around.
It was funny because I had a summer student who I just told how to use Atom and I was like, "Oh, this is great." and then I had to tell him literally a week later, forget that.
>> The thing you really love, they canceled it. I'm sorry.
>> Yeah. Just don't. He liked it too.
I looked around and I think I did what a lot of people are doing with VS Code.
I love it. My goodness, it's really mature and good.
Co-pilot, again, I'm still learning how to use it effectively, but it's amazing, it's a state changer.
>> It is absolutely amazing.
because we are working on clusters, a lot of things are remote.
The fact that you can do remote SSH and you can have your software here and your notebook here and then a terminal below it, and it's all just in your VS Code window, it's pretty sweet.
>> Yeah. You connect to it, have your editor running locally, but connected to that area.
>> There's no delay with typing and all, but you are running on the heavy iron somewhere, the big iron somewhere.
Indeed, I feel like VS Code is maybe the natural successor to people who did Sublime and Atom.
Those are the, I see that kind of that flow there.
All right, and then a notable PyPI package?
Right off the bat, you put up at the beginning, you know, llnl.github.io is, I think, you know, a really good resource for just sort of seeing the open source packages that are being developed at the lab.
And again, they have a bent towards high performance computing and such.
And like I said, eventually, I design will be up there.
We'll open source that.
I will mention one that Dave Monroe, again, and is sort of trying to take care of us before he retired.
He wrote a nice little package called QND, which is on this for quick and dirty QND, and that's now being maintained by Dave Strozzi.
And it's a nice little package, but what it does is actually unifies an interface for several different binary formats, in particular, HDF5, NetCDF, and a lab internal format called PDB.
It's one of those things that passes the test in my mind where I've actually reached for it in my own just little projects, where if I need to just store some data, NumPy has its own storage thing, but it doesn't do really good if you have a hierarchical data or if you want to do records and have things stored over time.
But this is actually a simple enough and uniform enough interface that it's like, wow, this really works.
So anytime you actually reach for it when you just need that tool, I think that it's past some threshold of usability.
Again, it's open source and I think for people who do things like that, work with binary data, I think this might be something that other people might want to look at.
>> One of those Lego building blocks.
>> Yeah, exactly.
>> One other question, people out there who are really interested in what you're talking about, and maybe they previously thought of LL and LL is just a place for a physicist, And maybe you're starting to think, maybe it's a place for software people and data scientists.
Are you guys hiring?
We are actually.
Absolutely, actually, right now, strangely, you know, I think there might be some tailwinds after the success. That's above my pay grade, but I think that, you know, there's something that should be happening. There should be a lot more good stuff going on. But right now, even there's a lot of hiring going on. And so if you find some of this, you know, interesting Python chops, you know, check us out, definitely.
Jay, thanks for being here.
Congratulations once again.
It's really amazing work, and I know it's early days, but we'll look back on it, I'm sure.
Yeah, thank you, Michael.
Yeah, it's been a lot of fun.
It's fun to be a part of it and look back on the road.
It's still a long road ahead.
It is, but I'll be tracking it.
It'll be exciting to see where it goes.
Thanks.
This has been another episode of Talk Python to Me.
Thank you to our sponsors.
Be sure to check out what they're offering.
It really helps support the show.
Taipy is here to take on the challenge of rapidly transforming a bare algorithm in Python into a full-fledged decision support system for end users.
Get started with Taipy Core and GUI for free at talkpython.fm/taipy.
Earn extra income from sharing your software development opinion at user interviews.
Head over to talkpython.fm/userinterviews to participate today.
Want to level up your Python?
We have one of the largest catalogs of Python video courses over at TalkPython.
Our content ranges from true beginners to deeply advanced topics like memory and async.
And best of all, there's not a subscription in sight.
Check it out for yourself at training.talkpython.fm.
Be sure to subscribe to the show, open your favorite podcast app, and search for Python.
We should be right at the top.
You can also find the iTunes feed at /iTunes, the Google Play feed at /play, and the Direct rss feed at /rss on talkpython.fm. We're live streaming most of our recordings these days.
If you want to be part of the show and have your comments featured on the air, be sure to subscribe to our YouTube channel at talkpython.fm/youtube. This is your host, Michael Kennedy. Thanks so much for listening. I really appreciate it. Now get out there and and write some Python code.
(upbeat music)
[Music]
(upbeat music)
